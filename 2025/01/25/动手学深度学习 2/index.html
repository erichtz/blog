<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>动手学深度学习 2 | eric_zht</title><meta name="author" content="eric_zht"><meta name="copyright" content="eric_zht"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="一、卷积卷积有什么用？ 通过卷积核的不同设置，使得每个输出通道可以识别特定的模式，比如识别边缘、锐化、模糊等操作。 核的参数怎么得到的？ 学出来的，不是自己设置的。 卷积尺寸公式： 输出尺寸*&#x3D;*[输入尺寸-kernel-size+2*padding+stride]&#x2F;stride 填充在输入周围添加行&#x2F;列，来控制输出形状的减少量 步幅每次滑动kernal窗口时的行&#x2F;列的步长，可">
<meta property="og:type" content="article">
<meta property="og:title" content="动手学深度学习 2">
<meta property="og:url" content="http://example.com/2025/01/25/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%202/index.html">
<meta property="og:site_name" content="eric_zht">
<meta property="og:description" content="一、卷积卷积有什么用？ 通过卷积核的不同设置，使得每个输出通道可以识别特定的模式，比如识别边缘、锐化、模糊等操作。 核的参数怎么得到的？ 学出来的，不是自己设置的。 卷积尺寸公式： 输出尺寸*&#x3D;*[输入尺寸-kernel-size+2*padding+stride]&#x2F;stride 填充在输入周围添加行&#x2F;列，来控制输出形状的减少量 步幅每次滑动kernal窗口时的行&#x2F;列的步长，可">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/image/icon.png">
<meta property="article:published_time" content="2025-01-24T16:00:00.000Z">
<meta property="article:modified_time" content="2025-02-17T12:59:54.288Z">
<meta property="article:author" content="eric_zht">
<meta property="article:tag" content="李沐">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/image/icon.png"><link rel="shortcut icon" href="/image/favicon.png"><link rel="canonical" href="http://example.com/2025/01/25/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%202/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '动手学深度学习 2',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  isShuoshuo: false
}</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/image/icon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">eric_zht</span></a><a class="nav-page-title" href="/"><span class="site-name">动手学深度学习 2</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">动手学深度学习 2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-01-24T16:00:00.000Z" title="发表于 2025-01-25 00:00:00">2025-01-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-17T12:59:54.288Z" title="更新于 2025-02-17 20:59:54">2025-02-17</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">3.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="一、卷积"><a href="#一、卷积" class="headerlink" title="一、卷积"></a>一、卷积</h1><p><em><strong>卷积有什么用？</strong></em></p>
<p>通过卷积核的不同设置，使得每个输出通道可以识别特定的模式，比如识别边缘、锐化、模糊等操作。</p>
<p><em><strong>核的参数怎么得到的？</strong></em></p>
<p>学出来的，不是自己设置的。</p>
<p><em><strong>卷积尺寸公式：</strong></em></p>
<p><code>输出尺寸*=*[输入尺寸-kernel-size+2*padding+stride]/stride</code></p>
<h2 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h2><p>在输入周围添加行&#x2F;列，来控制输出形状的减少量</p>
<h2 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h2><p>每次滑动kernal窗口时的行&#x2F;列的步长，可以成倍的减少输出形状</p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250125203559067.png" alt="image-20250125203559067"></p>
<p><strong>注意：</strong></p>
<p><strong>1、第一个公式里的ph是要上下都加了行，所以要乘以二！！！</strong></p>
<p><strong>2、padding通常设置为k-1 （核-1）</strong></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>1、为什么通常用3x3或者5x5的卷积核呢？他们的视野不是很小吗？（更常用3x3，计算量更小）</p>
<p>多加几层卷积层，最后的到的层会涵盖初始层中很大范围的内容。</p>
<img src="https://pic.ericzht.space/PicGo/image-20250125210159175.png" alt="image-20250125210159175"  />



<h3 id="多输入通道"><a href="#多输入通道" class="headerlink" title="多输入通道"></a>多输入通道</h3><p><img src="https://pic.ericzht.space/PicGo/image-20250126204241191.png" alt="image-20250126204241191"></p>
<p>这样只能得到单输出的通道</p>
<h3 id="如何得到多输出通道？"><a href="#如何得到多输出通道？" class="headerlink" title="如何得到多输出通道？"></a><strong>如何得到多输出通道？</strong></h3><p>输入的三通道数据和多个卷积核进行卷积，得到多通道的输出。</p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250126204931218.png" alt="image-20250126204931218"></p>
<p>co表示卷积核的个数，ci表示卷积核的维度，第0维的卷积层和第0维的输入进行计算，第1维的卷积层和第1维的输入进行计算…，然后将同一位置不同层的计算结果相加，得到这一块的输出内容，再按此方法进行卷积操作得到第一维度的输出。使用<strong>其他的卷积核</strong>进行相同操作，最后得到多输出通道。</p>
<h2 id="1x1-卷积层"><a href="#1x1-卷积层" class="headerlink" title="1x1 卷积层"></a>1x1 卷积层</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250126210139909.png" alt="image-20250126210139909"></p>
<p>用于不同通道使用不同权重进行融合。</p>
<h1 id="二、最大-平均池化"><a href="#二、最大-平均池化" class="headerlink" title="二、最大&#x2F;平均池化"></a>二、最大&#x2F;平均池化</h1><p>返回滑动窗口中的最大值&#x2F;平均值</p>
<p>缓解卷积层对于位置的敏感性，通常放在卷积层之后。</p>
<p><strong>pytorch中，如果不设置默认：池化窗口&#x3D;步幅，就是保证窗口不重叠</strong></p>
<p>为什么现在池化用的少了？</p>
<p>现在通常用一个卷积层+stride减少输出</p>
<h1 id="三、LeNet"><a href="#三、LeNet" class="headerlink" title="三、LeNet"></a>三、LeNet</h1><p><img src="https://pic.ericzht.space/PicGo/image-20250202195341765.png" alt="image-20250202195341765"></p>
<h2 id="如何检验层的尺寸有没有搭错："><a href="#如何检验层的尺寸有没有搭错：" class="headerlink" title="如何检验层的尺寸有没有搭错："></a>如何检验层的尺寸有没有搭错：</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250202200046443.png" alt="image-20250202200046443"></p>
<h1 id="四、AlexNet"><a href="#四、AlexNet" class="headerlink" title="四、AlexNet"></a>四、AlexNet</h1><p>在LetNet基础上添加了一些层，效果更好</p>
<h1 id="五、VGG块"><a href="#五、VGG块" class="headerlink" title="五、VGG块"></a>五、VGG块</h1><p>将AlexNet中的多个卷积层封装成一个块，使用多个VGG块构建深度卷积神经网络，效果更好。</p>
<p>不同的卷积块个数和超参数可以得到不同复杂度的变种。</p>
<p>注：在VGG中，内部卷积层的个数n，通道m是超参数。</p>
<h1 id="六、NiN"><a href="#六、NiN" class="headerlink" title="六、NiN"></a>六、NiN</h1><p>全连接层的问题：</p>
<p>卷积层后的得到第一个全连接层时的<strong>计算量会非常大</strong>且<strong>容易过拟合</strong></p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250203204835160.png" alt="image-20250203204835160"></p>
<h2 id="NiN块"><a href="#NiN块" class="headerlink" title="NiN块"></a>NiN块</h2><p>一个卷积层后跟两个全连接层</p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250203204956898.png" alt="image-20250203204956898"></p>
<p>为什么用的是两个1x1的卷积层？他们其实相当于<strong>没有将输入拍扁的全连接层</strong>。</p>
<h2 id="NiN架构"><a href="#NiN架构" class="headerlink" title="NiN架构"></a>NiN架构</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250203205310762.png" alt="image-20250203205310762"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Nin块使用卷积层加两个1x1卷积层，后者对每个像素增加了非线性性。</p>
<p>Nin用全局平均池化层来替代VGG和AlexNet中的全连接层——不容易过拟合，更少的参数个数。</p>
<h1 id="七、批量归一化-Batch-Normalization"><a href="#七、批量归一化-Batch-Normalization" class="headerlink" title="七、批量归一化 Batch Normalization"></a>七、批量归一化 Batch Normalization</h1><h1 id="——加速收敛、网络训练速度"><a href="#——加速收敛、网络训练速度" class="headerlink" title="——加速收敛、网络训练速度"></a>——加速收敛、网络训练速度</h1><p><img src="https://pic.ericzht.space/PicGo/image-20250204164534195.png" alt="image-20250204164534195"></p>
<p><strong>BN层一般用于深层神经网络，浅层的效果不好。</strong></p>
<h2 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h2><p>由于学习过程中会调整每个层的超参数，当调整前面的层时，会导致后面的层需要重新进行学习，进而导致最后得到的层很难收敛。所以学习率不能设置太高。</p>
<p>批量归一化将每一层的输出进行归一化，使对下一层的输出相似但不完全相同，这样后面的层就不需要改动太大。因此可以选择较大的学习率，加快了网络的训练。 </p>
<p><em><strong>后有论文指出它可能就是通过在每个小批量里加入噪音来控制模型的复杂度。</strong></em></p>
<p><strong>因此没必要跟丢弃法混合使用。</strong></p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250204165011101.png" alt="image-20250204165011101"></p>
<p><strong>分布归一化放在非线性激活前面！</strong></p>
<p>需要训练的参数增加了γ和β，原来的偏置是定好的不需要学习。所以现在有三个参数需要学习。</p>
<h2 id="调包实现"><a href="#调包实现" class="headerlink" title="调包实现"></a>调包实现</h2><p>nn.BatchNorm2d(输入的通道数)</p>
<p>nn.BatchNorm1d(输入的通道数)</p>
<h1 id="八、ResNet"><a href="#八、ResNet" class="headerlink" title="八、ResNet"></a>八、ResNet</h1><p><img src="https://pic.ericzht.space/PicGo/image-20250204200225258.png" alt="image-20250204200225258"></p>
<p><em><strong>不断添加层数，得到的模型一定最优吗？</strong></em></p>
<p>不一定。反而可能会越来越偏离最优函数。</p>
<h2 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250204200355148.png" alt="image-20250204200355148"></p>
<p>f(x)&#x3D;x+g(x)</p>
<p>使得新的模型必须包含之前的模型，因此精度不可能变差。</p>
<ul>
<li>如果g(x)没什么用，那么系统后面给它的梯度会很小，它对最后的结果影响就很小了。</li>
</ul>
<p><strong>同时，残差块使得很深的网络更加容易训练。</strong></p>
<p>这样加法的操作使得反向传播计算梯度时，即使g(x)的偏导很小，由于是加法，也可以求出x的偏导，那么f(x)得到的梯度就不至于消失。</p>
<p><em>解决了深层网络底层比较难以训练的问题。</em>——底层拿到的梯度一般比较小。</p>
<h1 id="九、数据增强"><a href="#九、数据增强" class="headerlink" title="九、数据增强"></a>九、数据增强</h1><p>增加一个已有的数据集，使其有更多的多样性。</p>
<ul>
<li>​	增加不同的背景噪音</li>
<li>​	改变图片的颜色和形状</li>
</ul>
<h2 id="常见增强方法"><a href="#常见增强方法" class="headerlink" title="常见增强方法"></a>常见增强方法</h2><h3 id="翻转"><a href="#翻转" class="headerlink" title="翻转"></a>翻转</h3><p>左右、上下翻转</p>
<p>但不是总是可行。比如建筑之类的翻转不太符合实际。但树叶什么的翻转没关系。</p>
<h3 id="切割"><a href="#切割" class="headerlink" title="切割"></a>切割</h3><p>从图片中切割一块，然后变形到固定形状</p>
<ul>
<li>随机高宽比（eg.[3&#x2F;4,4&#x2F;3]）</li>
<li>随机大小（eg.[8%,100%]）</li>
<li>随机位置</li>
</ul>
<h3 id="颜色"><a href="#颜色" class="headerlink" title="颜色"></a>颜色</h3><p>改变色调，饱和度，明亮度（当前的情况减少50%或增加50%的范围内）</p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><a target="_blank" rel="noopener" href="https://github.com/aleju/imgaug">https://github.com/aleju/imgaug</a></p>
<h1 id="十、微调-fine-tune"><a href="#十、微调-fine-tune" class="headerlink" title="十、微调 fine-tune"></a>十、微调 fine-tune</h1><h2 id="微调中的权重初始化"><a href="#微调中的权重初始化" class="headerlink" title="微调中的权重初始化"></a>微调中的权重初始化</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250206203248814.png" alt="image-20250206203248814"></p>
<p>源数据集远复杂于目标数据，通常微调的效果更好（速度更快、精度越高）。</p>
<ul>
<li><p>使用更小的学习率</p>
</li>
<li><p>使用更少的数据迭代</p>
</li>
</ul>
<h2 id="1、重用分类器权重"><a href="#1、重用分类器权重" class="headerlink" title="1、重用分类器权重"></a>1、重用分类器权重</h2><p>源数据集可能也有目标数据中的部分标号，可以使用预训练好的模型分类器中对应标号对应的向量来做初始化。</p>
<h2 id="2、固定一些层"><a href="#2、固定一些层" class="headerlink" title="2、固定一些层"></a>2、固定一些层</h2><ul>
<li>神经网络通常学习有层次的特征：<ul>
<li>低层次的特征更加通用</li>
<li>高层次的特征更加与数据集有关</li>
</ul>
</li>
<li>可以固定底部一些层的参数，不参与更新。</li>
</ul>
<h1 id="十一、锚框"><a href="#十一、锚框" class="headerlink" title="十一、锚框"></a>十一、锚框</h1><p>一类目标检测算法是基于锚框的</p>
<ul>
<li>提出多个被称为锚框的区域</li>
<li>预测每个锚框里是否含有关注的物体</li>
<li>如果是，预测从这个锚框到真实边缘框的偏移</li>
</ul>
<h2 id="IoU-交并比"><a href="#IoU-交并比" class="headerlink" title="IoU 交并比"></a>IoU 交并比</h2><img src="https://pic.ericzht.space/PicGo/image-20250208160454237.png" alt="image-20250208160454237" style="zoom:67%;" />

<img src="https://pic.ericzht.space/PicGo/image-20250208160523457.png" alt="image-20250208160523457" style="zoom:67%;" />

<h2 id="赋予锚框标号"><a href="#赋予锚框标号" class="headerlink" title="赋予锚框标号"></a>赋予锚框标号</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250209105249553.png" alt="image-20250209105249553"></p>
<p>第一步的意思就是使用锚框2去预测边缘框3。</p>
<p><strong>一张图有多少个边缘框，就对应有多少个训练样本。</strong></p>
<h2 id="使用非极大值抑制（NMS）输出"><a href="#使用非极大值抑制（NMS）输出" class="headerlink" title="使用非极大值抑制（NMS）输出"></a>使用非极大值抑制（NMS）输出</h2><ul>
<li>每个锚框预测一个边缘框</li>
<li>NMS可以合并相似的预测<ul>
<li>选中是非背景类的最大预测值</li>
<li>去掉其他和它IoU值大于θ的预测</li>
<li>重复上述过程知道所有预测要么被选中，要么被去掉</li>
</ul>
</li>
</ul>
<img src="https://pic.ericzht.space/PicGo/image-20250209105958709.png" alt="image-20250209105958709" style="zoom: 50%;" />

<h1 id="十二、物体检测算法-R-CNN"><a href="#十二、物体检测算法-R-CNN" class="headerlink" title="十二、物体检测算法 R-CNN"></a>十二、物体检测算法 R-CNN</h1><h2 id="兴趣区域（RoI）池化层"><a href="#兴趣区域（RoI）池化层" class="headerlink" title="兴趣区域（RoI）池化层"></a>兴趣区域（RoI）池化层</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250209163934488.png" alt="image-20250209163934488"></p>
<p>给定一个锚框，均匀分割成n×m块，输出每块里的最大值</p>
<p>不管锚框多大，总是输出nm个值</p>
<p><strong>强行将图像变成大小一样的。</strong></p>
<h2 id="Fast-RCNN"><a href="#Fast-RCNN" class="headerlink" title="Fast RCNN"></a>Fast RCNN</h2><ul>
<li>使用CNN对图片抽取特征</li>
<li>再使用RoI池化层对每个锚框生成固定长度特征</li>
</ul>
<p><strong>在原始图片上搜索到锚框后，把锚框按照比例映射到经过CNN层的特征层。</strong></p>
<img src="https://pic.ericzht.space/PicGo/image-20250209165216146.png" alt="image-20250209165216146" style="zoom:50%;" />

<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250209165440613.png" alt="image-20250209165440613"></p>
<h2 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h2><p>如果有像素级别的标号，使用FCN来利用这些信息。</p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250209170559072.png" alt="image-20250209170559072"></p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250209171622411.png" alt="image-20250209171622411"></p>
<h1 id="十三、单发多框检测-SSD"><a href="#十三、单发多框检测-SSD" class="headerlink" title="十三、单发多框检测 SSD"></a>十三、单发多框检测 SSD</h1><h2 id="生成锚框"><a href="#生成锚框" class="headerlink" title="生成锚框"></a>生成锚框</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250209172045212.png" alt="image-20250209172045212"></p>
<h2 id="SSD模型"><a href="#SSD模型" class="headerlink" title="SSD模型"></a>SSD模型</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250209172314880.png" alt="image-20250209172314880"></p>
<h1 id="十四、YOLO-you-only-look-once"><a href="#十四、YOLO-you-only-look-once" class="headerlink" title="十四、YOLO: you only look once"></a>十四、YOLO: you only look once</h1><p><strong>在SSD的基础上进行改进，避免大量SSD重叠。</strong></p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250209173141837.png" alt="image-20250209173141837"></p>
<h1 id="十五、语义分割"><a href="#十五、语义分割" class="headerlink" title="十五、语义分割"></a>十五、语义分割</h1><p>语义分割可以识别并理解图像中每一个像素的内容：其语义区域的标注和预测是像素级的。</p>
<p>即每一个像素都有其对应的类别。</p>
<h2 id="列举RGB值和类名"><a href="#列举RGB值和类名" class="headerlink" title="列举RGB值和类名"></a>列举RGB值和类名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line">VOC_COLORMAP = [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">128</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">128</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">128</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">0</span>, <span class="number">128</span>, <span class="number">128</span>], [<span class="number">128</span>, <span class="number">128</span>, <span class="number">128</span>],</span><br><span class="line">                [<span class="number">64</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">192</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">64</span>, <span class="number">128</span>, <span class="number">0</span>], [<span class="number">192</span>, <span class="number">128</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">64</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">192</span>, <span class="number">0</span>, <span class="number">128</span>], [<span class="number">64</span>, <span class="number">128</span>, <span class="number">128</span>], [<span class="number">192</span>, <span class="number">128</span>, <span class="number">128</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">64</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">64</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">192</span>, <span class="number">0</span>], [<span class="number">128</span>, <span class="number">192</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">64</span>, <span class="number">128</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment">#@save</span></span><br><span class="line">VOC_CLASSES = [<span class="string">&#x27;background&#x27;</span>, <span class="string">&#x27;aeroplane&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;diningtable&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;motorbike&#x27;</span>, <span class="string">&#x27;person&#x27;</span>,</span><br><span class="line">               <span class="string">&#x27;potted plant&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;sofa&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;tv/monitor&#x27;</span>]</span><br></pre></td></tr></table></figure>



<h2 id="构建从RGB到VOC类别索引的映射"><a href="#构建从RGB到VOC类别索引的映射" class="headerlink" title="构建从RGB到VOC类别索引的映射"></a>构建从RGB到VOC类别索引的映射</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">voc_colormap2label</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;构建从RGB到VOC类别索引的映射&quot;&quot;&quot;</span></span><br><span class="line">    colormap2label = torch.zeros(<span class="number">256</span> ** <span class="number">3</span>, dtype=torch.long)</span><br><span class="line">    <span class="keyword">for</span> i, colormap <span class="keyword">in</span> <span class="built_in">enumerate</span>(VOC_COLORMAP):</span><br><span class="line">        colormap2label[</span><br><span class="line">            (colormap[<span class="number">0</span>] * <span class="number">256</span> + colormap[<span class="number">1</span>]) * <span class="number">256</span> + colormap[<span class="number">2</span>]] = i</span><br><span class="line">        <span class="comment"># 把RGB三通道的数值当做256进制的数（因为像素最多从0-255）每个像素值算出对应10进制数存入tensor 这样可以对应到每个像素所属类别。</span></span><br><span class="line">        <span class="comment"># i表示这个颜色对应类别的序号</span></span><br><span class="line">    <span class="keyword">return</span> colormap2label</span><br><span class="line"></span><br><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">voc_label_indices</span>(<span class="params">colormap, colormap2label</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;将VOC标签中的RGB值映射到它们的类别索引&quot;&quot;&quot;</span></span><br><span class="line">    colormap = colormap.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).numpy().astype(<span class="string">&#x27;int32&#x27;</span>) </span><br><span class="line">    <span class="comment"># 将输入的彩色标签图像的维度从（通道，高度，宽度）重排为（高度，宽度，通道），然后将其转换为NumPy数组，并将数据类型转换为32位整数，以便进行后续计算。</span></span><br><span class="line">    idx = ((colormap[:, :, <span class="number">0</span>] * <span class="number">256</span> + colormap[:, :, <span class="number">1</span>]) * <span class="number">256</span></span><br><span class="line">           + colormap[:, :, <span class="number">2</span>]) <span class="comment"># 计算RGB值对应的类别的索引</span></span><br><span class="line">    <span class="keyword">return</span> colormap2label[idx] <span class="comment">#返回对应类别的序号</span></span><br></pre></td></tr></table></figure>



<h1 id="十六、转置卷积"><a href="#十六、转置卷积" class="headerlink" title="十六、转置卷积"></a>十六、转置卷积</h1><p>卷积不会增大输入的高宽，通常要么不变、要么减半。</p>
<p>而转置卷积则可以用来增大输入的高宽。</p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250210202817711.png" alt="image-20250210202817711"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">X = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]])</span><br><span class="line">K = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]])</span><br><span class="line">trans_conv(X, K)</span><br><span class="line">X, K = X.reshape(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>), K.reshape(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment">#调用api实现转置卷积</span></span><br><span class="line">tconv = nn.ConvTranspose2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">2</span>, bias=<span class="literal">False</span>) <span class="comment">#输入通道数，输出通道数，核的大小，是否有偏移</span></span><br><span class="line">tconv.weight.data = K</span><br><span class="line">tconv(X)</span><br></pre></td></tr></table></figure>

<h2 id="填充、步幅和多通道"><a href="#填充、步幅和多通道" class="headerlink" title="填充、步幅和多通道"></a>填充、步幅和多通道</h2><p>转置卷积的填充（padding）是加在<strong>输出</strong>上的。</p>
<p>如上图的转置卷积过程，如果padding&#x3D;1，则最后的结果为4。（删除第一和最后的行和列）</p>
<img src="https://pic.ericzht.space/PicGo/image-20250210211025587.png" alt="image-20250210211025587"  />

<p><strong>对于多个输入和输出通道，转置卷积与常规卷积以相同方式运作。</strong><br>假设输入有$c_i$个通道，且转置卷积为每个输入通道分配了一个$k_h\times k_w$的卷积核张量。<br>当指定多个输出通道时，每个输出通道将有一个$c_i\times k_h\times k_w$的卷积核。</p>
<p>如果我们将$\mathsf{X}$代入卷积层$f$来输出$\mathsf{Y}&#x3D;f(\mathsf{X})$，并创建一个与$f$具有相同的超参数、但输出通道数量是$\mathsf{X}$中通道数的转置卷积层$g$，那么$g(Y)$的形状将与$\mathsf{X}$相同。</p>
<h2 id="转置卷积与卷积的转换"><a href="#转置卷积与卷积的转换" class="headerlink" title="转置卷积与卷积的转换"></a>转置卷积与卷积的转换</h2><img src="C:\Users\19355\AppData\Roaming\Typora\typora-user-images\image-20250211172618374.png" alt="image-20250211172618374" style="zoom:50%;" />

<img src="https://pic.ericzht.space/PicGo/image-20250211173143405.png" alt="image-20250211173143405" style="zoom:50%;" />

<h1 id="十七、全连接卷积神经网络-FCN"><a href="#十七、全连接卷积神经网络-FCN" class="headerlink" title="十七、全连接卷积神经网络 FCN"></a>十七、全连接卷积神经网络 FCN</h1><p>用转置卷积层来替换CNN最后的全连接层，从而实现每个像素的预测</p>
<img src="https://pic.ericzht.space/PicGo/image-20250211173942625.png" alt="image-20250211173942625" style="zoom:50%;" />

<p>最后的通道数 &#x3D; 类别数</p>
<h1 id="十八、序列模型"><a href="#十八、序列模型" class="headerlink" title="十八、序列模型"></a>十八、序列模型</h1><p>时序模型中，当前数据和之间观察到的数据相关。</p>
<h2 id="常见的两种方案"><a href="#常见的两种方案" class="headerlink" title="常见的两种方案"></a>常见的两种方案</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250211211819095.png" alt="image-20250211211819095"></p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250211212120318.png" alt="image-20250211212120318"></p>
<h1 id="十九、注意力机制"><a href="#十九、注意力机制" class="headerlink" title="十九、注意力机制"></a>十九、注意力机制</h1><p>卷积、全连接、池化层都只考虑不随意线索。</p>
<p>注意力机制则考虑随意线索</p>
<ul>
<li>随意线索被称之为查询（query）</li>
<li>每个输入是一个值（value）和不随意线索（key）的对</li>
<li>通过注意力池化层来有偏向性的选择某些输入</li>
</ul>
<p><strong>注意力机制的本质</strong>：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1dt4y1J7ov/?share_source=copy_web&spm_id_from=333.788.comment.all.click&vd_source=c675206b339487e9755eec554de241a9">https://www.bilibili.com/video/BV1dt4y1J7ov/?share_source=copy_web&amp;spm_id_from=333.788.comment.all.click&amp;vd_source=c675206b339487e9755eec554de241a9</a></p>
<img src="https://pic.ericzht.space/PicGo/image-20250214104442014.png" alt="image-20250214104442014" style="zoom:50%;" />

<h2 id="非参的注意力池化层"><a href="#非参的注意力池化层" class="headerlink" title="非参的注意力池化层"></a>非参的注意力池化层</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250214104642886.png" alt="image-20250214104642886"></p>
<h3 id="1、一般情况"><a href="#1、一般情况" class="headerlink" title="1、一般情况"></a>1、一般情况</h3><p><img src="https://pic.ericzht.space/PicGo/image-20250214105230900.png" alt="image-20250214105230900"></p>
<h3 id="2、Nadaraya-Watson-核回归"><a href="#2、Nadaraya-Watson-核回归" class="headerlink" title="2、Nadaraya-Watson 核回归"></a>2、Nadaraya-Watson 核回归</h3><p><img src="https://pic.ericzht.space/PicGo/image-20250214104915705.png" alt="image-20250214104915705"></p>
<h2 id="参数化的注意力机制"><a href="#参数化的注意力机制" class="headerlink" title="参数化的注意力机制"></a>参数化的注意力机制</h2><p>在之前的基础上引入可以学习的w</p>
<img src="https://pic.ericzht.space/PicGo/image-20250214105030923.png" alt="image-20250214105030923" style="zoom: 67%;" />

<h2 id="注意力分数"><a href="#注意力分数" class="headerlink" title="注意力分数"></a>注意力分数</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250214111827479.png" alt="image-20250214111827479"></p>
<h2 id="加性注意力-additive-attention"><a href="#加性注意力-additive-attention" class="headerlink" title="加性注意力 additive attention"></a>加性注意力 additive attention</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AdditiveAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加性注意力&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, key_size, query_size, num_hiddens, dropout, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(AdditiveAttention, <span class="variable language_">self</span>).__init__(**kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.W_k = nn.Linear(key_size, num_hiddens, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.W_q = nn.Linear(query_size, num_hiddens, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.w_v = nn.Linear(num_hiddens, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, queries, keys, values, valid_lens</span>):</span><br><span class="line">        queries, keys = <span class="variable language_">self</span>.W_q(queries), <span class="variable language_">self</span>.W_k(keys)</span><br><span class="line">        <span class="comment"># 在维度扩展后，</span></span><br><span class="line">        <span class="comment"># queries的形状：(batch_size，查询的个数，1，num_hidden)</span></span><br><span class="line">        <span class="comment"># key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)</span></span><br><span class="line">        <span class="comment"># 使用广播方式进行求和 —— 广播规则：维度大小为1的轴会自动扩展以匹配另一张量的形状。</span></span><br><span class="line">        <span class="comment"># 18行feature的形状：(batch_size，查询的个数，“键－值”对的个数，num_hiddens)</span></span><br><span class="line">        features = queries.unsqueeze(<span class="number">2</span>) + keys.unsqueeze(<span class="number">1</span>) </span><br><span class="line">        features = torch.tanh(features)</span><br><span class="line">        <span class="comment"># self.w_v仅有一个输出，因此从形状中移除最后那个维度。</span></span><br><span class="line">        <span class="comment"># scores的形状：(batch_size，查询的个数，“键-值”对的个数)</span></span><br><span class="line">        scores = <span class="variable language_">self</span>.w_v(features).squeeze(-<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.attention_weights = masked_softmax(scores, valid_lens) <span class="comment"># 注意力权重</span></span><br><span class="line">        <span class="comment"># values的形状：(batch_size，“键－值”对的个数，值的维度)</span></span><br><span class="line">        <span class="keyword">return</span> torch.bmm(<span class="variable language_">self</span>.dropout(<span class="variable language_">self</span>.attention_weights), values) <span class="comment"># 将注意力权重与值进行矩阵乘法</span></span><br></pre></td></tr></table></figure>

<h3 id="为什么要采用广播机制？"><a href="#为什么要采用广播机制？" class="headerlink" title="为什么要采用广播机制？"></a>为什么要采用广播机制？</h3><p>通过广播机制，一次性生成所有 <code>(query, key)</code> 对的组合特征，避免逐对计算的低效循环。</p>
<h4 id="示例说明"><a href="#示例说明" class="headerlink" title="示例说明"></a>示例说明</h4><p>假设：</p>
<ul>
<li>批量大小 <code>batch_size=2</code></li>
<li>查询数量 <code>num_queries=3</code></li>
<li>键值对数量 <code>num_kv_pairs=4</code></li>
<li>隐藏维度 <code>num_hiddens=5</code></li>
</ul>
<p>经过 <code>unsqueeze</code> 和广播后：</p>
<ul>
<li><code>queries</code> 形状：<code>(2, 3, 1, 5)</code></li>
<li><code>keys</code> 形状：<code>(2, 1, 4, 5)</code></li>
<li>相加结果 <code>features</code> 形状：<code>(2, 3, 4, 5)</code></li>
</ul>
<p>这表示：</p>
<ul>
<li>对于批量中的每个样本（2个样本），</li>
<li>每个查询（3个查询）与每个键（4个键）都进行了逐元素相加，</li>
<li>最终得到 <code>3×4=12</code> 个查询-键对的交互特征。</li>
</ul>
<h3 id="为什么要用masked-softmax？"><a href="#为什么要用masked-softmax？" class="headerlink" title="为什么要用masked_softmax？"></a>为什么要用masked_softmax？</h3><p>在处理文本数据集时，为了提高计算效率，可能会采用<strong>填充</strong>的方式使每个文本序列具有相同的长度，便于以相同形状的小批量进行加载，因此可能会存在一些文本序列被填充了没有意义的特殊词源（比如<strong>“<pad>”</strong>词元）。</p>
<p>使用masked_softmax可以过滤掉超出指定范围的位置，不让填充的无意义内容影响结果。</p>
<h2 id="缩放点积注意力"><a href="#缩放点积注意力" class="headerlink" title="缩放点积注意力"></a>缩放点积注意力</h2><p>见书P290</p>
<h2 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h2><p>完全并行、最长序列为1、但对长序列计算复杂度高</p>
<p><em>李宏毅：</em><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1v3411r78R?spm_id_from=333.788.videopod.episodes&vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd&p=2">https://www.bilibili.com/video/BV1v3411r78R?spm_id_from=333.788.videopod.episodes&amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd&amp;p=2</a></p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250216210649488.png" alt="image-20250216210649488"></p>
<h3 id="一、如何得到b1"><a href="#一、如何得到b1" class="headerlink" title="一、如何得到b1"></a>一、如何得到b1</h3><p><img src="https://pic.ericzht.space/PicGo/image-20250216210602641.png" alt="image-20250216210602641"></p>
<h3 id="二、矩阵表示"><a href="#二、矩阵表示" class="headerlink" title="二、矩阵表示"></a>二、矩阵表示</h3><h4 id="1整体理解"><a href="#1整体理解" class="headerlink" title="1整体理解"></a>1整体理解</h4><p><img src="https://pic.ericzht.space/PicGo/image-20250216212359480.png" alt="image-20250216212359480"></p>
<h4 id="2具体表示"><a href="#2具体表示" class="headerlink" title="2具体表示"></a>2具体表示</h4><p><img src="https://pic.ericzht.space/PicGo/image-20250216211942646.png" alt="image-20250216211942646"></p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250216212118247.png" alt="image-20250216212118247"></p>
<h3 id="三、位置编码"><a href="#三、位置编码" class="headerlink" title="三、位置编码"></a>三、位置编码</h3><p>在输入中加入位置信息</p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250216214949465.png" alt="image-20250216214949465"></p>
<h1 id="二十、编码器-解码器"><a href="#二十、编码器-解码器" class="headerlink" title="二十、编码器-解码器"></a>二十、编码器-解码器</h1><p>编码器处理输入，解码器生成输出（其实就是把功能集成到一起，然后起了个新名字）</p>
<p><img src="https://pic.ericzht.space/PicGo/image-20250217200853436.png" alt="image-20250217200853436"></p>
<h1 id="二十一、Transformer"><a href="#二十一、Transformer" class="headerlink" title="二十一、Transformer"></a>二十一、Transformer</h1><p><img src="https://pic.ericzht.space/PicGo/image-20250217201023952.png" alt="image-20250217201023952"></p>
<h2 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250217201206994.png" alt="image-20250217201206994"></p>
<p>每个注意力池化层都是不同的weight</p>
<h2 id="有掩码的多头注意力"><a href="#有掩码的多头注意力" class="headerlink" title="有掩码的多头注意力"></a>有掩码的多头注意力</h2><p>解码器对序列中一个元素输出时，不应该考虑该元素之后的元素。</p>
<p>通过掩码实现</p>
<ul>
<li>计算xi的输出时，假装当前序列长度为i</li>
</ul>
<img src="C:\Users\19355\AppData\Roaming\Typora\typora-user-images\image-20250217201502438.png" alt="image-20250217201502438" style="zoom: 67%;" />

<h2 id="基于位置的前馈网络"><a href="#基于位置的前馈网络" class="headerlink" title="基于位置的前馈网络"></a>基于位置的前馈网络</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250217201606217.png" alt="image-20250217201606217"></p>
<p>n是序列的长度，不同数据n会变，不能作为特征处理，即n的变化不能影响模型。</p>
<h2 id="层归一化"><a href="#层归一化" class="headerlink" title="层归一化"></a>层归一化</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250217201854048.png" alt="image-20250217201854048"></p>
<h2 id="信息传递"><a href="#信息传递" class="headerlink" title="信息传递"></a>信息传递</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250217202324024.png" alt="image-20250217202324024"></p>
<h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p><img src="https://pic.ericzht.space/PicGo/image-20250217202600944.png" alt="image-20250217202600944"></p>
<h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><ul>
<li>Transformer是一个纯使用注意力的编码-阶码器</li>
<li>编码器和解码器都有n个transformer块</li>
<li>每个块里使用多头（自）注意力、基于位置的前馈网络、 层归一化</li>
</ul>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9D%8E%E6%B2%90/">李沐</a><a class="post-meta__tags" href="/tags/pytorch/">pytorch</a></div><div class="post-share"><div class="social-share" data-image="/image/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/02/28/Swin-Unet-%E5%A4%8D%E7%8E%B0%E8%AE%B0%E5%BD%95%EF%BC%88%E8%AE%B0%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%A4%8D%E7%8E%B0%E6%88%90%E5%8A%9F%EF%BC%89/" title="Swin-Unet 复现记录（记第一次复现成功）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Swin-Unet 复现记录（记第一次复现成功）</div></div><div class="info-2"><div class="info-item-1">一、train中遇到的问题（一）python、pytorch、cuda版本不对应swin-unet官方仓库上写的使用的是python3.7运行的代码，所以我一开始把环境全部朝python3.7去配置。却一直报错。 经过一番搜索后，发现python3.7对应的环境无法在4060laptop上运行。 在多次尝试不同的环境，并结合b站复现别的论文的视频，选择将python版本改为3.8。 1、新建独立环境12conda create -n py.8 python=3.8  # 明确指定Python 3.8conda activate py.8  2、使用pip绕过conda依赖限制1pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url...</div></div></div></a><a class="pagination-related" href="/2024/12/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%201/" title="动手学深度学习 1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">动手学深度学习 1</div></div><div class="info-2"><div class="info-item-1">一、数据操作+预处理N维数组N维数组是机器学习和神经网络的主要数据结构 0-d 标量：一个数字 1-d 向量：一个特征向量 2-d 矩阵：一个样本-特征矩阵 3-d RGB图片（宽×高×通道） 4-d 一个RGB图片的批量（批量大小batch×宽×高×通道） 创建数组需要：  形状  每个元素的数据类型  每个元素的值   访问元素 左下角子区域：1:3表示[1,3) 第二个子区域： ::3表示行是每3行一跳 ​                           ::2表示列是每两列一跳 关于内存x +&#x3D; y   就是直接在原来的x上加上y，与加法的形式不一样 x &#x3D; x + y ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2024/12/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%201/" title="动手学深度学习 1"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-03</div><div class="info-item-2">动手学深度学习 1</div></div><div class="info-2"><div class="info-item-1">一、数据操作+预处理N维数组N维数组是机器学习和神经网络的主要数据结构 0-d 标量：一个数字 1-d 向量：一个特征向量 2-d 矩阵：一个样本-特征矩阵 3-d RGB图片（宽×高×通道） 4-d 一个RGB图片的批量（批量大小batch×宽×高×通道） 创建数组需要：  形状  每个元素的数据类型  每个元素的值   访问元素 左下角子区域：1:3表示[1,3) 第二个子区域： ::3表示行是每3行一跳 ​                           ::2表示列是每两列一跳 关于内存x +&#x3D; y   就是直接在原来的x上加上y，与加法的形式不一样 x &#x3D; x + y ...</div></div></div></a><a class="pagination-related" href="/2024/11/27/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%20%E7%AC%AC%E4%B8%89%E5%A4%A9/" title="小土堆pytorch 第三天"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-27</div><div class="info-item-2">小土堆pytorch 第三天</div></div><div class="info-2"><div class="info-item-1">一、最大池化的使用池化——压缩特征 最大池化——取当前池化核中的最大的数  12345678910111213141516171819202122232425import torchfrom torch import nnfrom torch.nn import MaxPool2dinput = torch.tensor([[1, 2, 0, 3, 1],                      [0, 1, 2, 3, 1],                      [1, 2, 1, 0, 0],                      [5, 2, 3, 1, 1],                      [2, 1, 0, 1, 1]])input = torch.reshape(input, (-1, 1, 5, 5))class Test(nn.Module):    def __init__(self):        super(Test,self).__init__()        self.maxpool1 =...</div></div></div></a><a class="pagination-related" href="/2024/11/27/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%20%E7%AC%AC%E5%9B%9B%E5%A4%A9/" title="小土堆pytorch 第四天"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-27</div><div class="info-item-2">小土堆pytorch 第四天</div></div><div class="info-2"><div class="info-item-1">一、现有模型的加载、修改、添加123456789101112131415import torchvisionfrom torch import nnvgg16_false = torchvision.models.vgg16(pretrained=False)vgg16_true = torchvision.models.vgg16(pretrained=True)print(vgg16_true)train_data = torchvision.datasets.CIFAR10(&quot;dataset&quot;, train=True, transform=torchvision.transforms.ToTensor(),download=True)vgg16_true.classifier.add_module(&#x27;add_linear&#x27;, nn.Linear(1000, 10)) # 添加 层print(vgg16_true)print(vgg16_false)vgg16_false.classifier[6] = nn.Linear(4096,...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/image/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">eric_zht</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.</span> <span class="toc-text">一、卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A1%AB%E5%85%85"><span class="toc-number">1.1.</span> <span class="toc-text">填充</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A5%E5%B9%85"><span class="toc-number">1.2.</span> <span class="toc-text">步幅</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.</span> <span class="toc-text">问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E9%80%9A%E9%81%93"><span class="toc-number">1.3.1.</span> <span class="toc-text">多输入通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%BE%97%E5%88%B0%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93%EF%BC%9F"><span class="toc-number">1.3.2.</span> <span class="toc-text">如何得到多输出通道？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1x1-%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">1.4.</span> <span class="toc-text">1x1 卷积层</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%9C%80%E5%A4%A7-%E5%B9%B3%E5%9D%87%E6%B1%A0%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">二、最大&#x2F;平均池化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81LeNet"><span class="toc-number">3.</span> <span class="toc-text">三、LeNet</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%A3%80%E9%AA%8C%E5%B1%82%E7%9A%84%E5%B0%BA%E5%AF%B8%E6%9C%89%E6%B2%A1%E6%9C%89%E6%90%AD%E9%94%99%EF%BC%9A"><span class="toc-number">3.1.</span> <span class="toc-text">如何检验层的尺寸有没有搭错：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B%E3%80%81AlexNet"><span class="toc-number">4.</span> <span class="toc-text">四、AlexNet</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94%E3%80%81VGG%E5%9D%97"><span class="toc-number">5.</span> <span class="toc-text">五、VGG块</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD%E3%80%81NiN"><span class="toc-number">6.</span> <span class="toc-text">六、NiN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NiN%E5%9D%97"><span class="toc-number">6.1.</span> <span class="toc-text">NiN块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NiN%E6%9E%B6%E6%9E%84"><span class="toc-number">6.2.</span> <span class="toc-text">NiN架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.3.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96-Batch-Normalization"><span class="toc-number">7.</span> <span class="toc-text">七、批量归一化 Batch Normalization</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%80%94%E2%80%94%E5%8A%A0%E9%80%9F%E6%94%B6%E6%95%9B%E3%80%81%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E9%80%9F%E5%BA%A6"><span class="toc-number">8.</span> <span class="toc-text">——加速收敛、网络训练速度</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A"><span class="toc-number">8.1.</span> <span class="toc-text">解释</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%83%E5%8C%85%E5%AE%9E%E7%8E%B0"><span class="toc-number">8.2.</span> <span class="toc-text">调包实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AB%E3%80%81ResNet"><span class="toc-number">9.</span> <span class="toc-text">八、ResNet</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E5%9D%97"><span class="toc-number">9.1.</span> <span class="toc-text">残差块</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">10.</span> <span class="toc-text">九、数据增强</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95"><span class="toc-number">10.1.</span> <span class="toc-text">常见增强方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BF%BB%E8%BD%AC"><span class="toc-number">10.1.1.</span> <span class="toc-text">翻转</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E5%89%B2"><span class="toc-number">10.1.2.</span> <span class="toc-text">切割</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%9C%E8%89%B2"><span class="toc-number">10.1.3.</span> <span class="toc-text">颜色</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96"><span class="toc-number">10.1.4.</span> <span class="toc-text">其他</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E3%80%81%E5%BE%AE%E8%B0%83-fine-tune"><span class="toc-number">11.</span> <span class="toc-text">十、微调 fine-tune</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E4%B8%AD%E7%9A%84%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">11.1.</span> <span class="toc-text">微调中的权重初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E9%87%8D%E7%94%A8%E5%88%86%E7%B1%BB%E5%99%A8%E6%9D%83%E9%87%8D"><span class="toc-number">11.2.</span> <span class="toc-text">1、重用分类器权重</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E5%9B%BA%E5%AE%9A%E4%B8%80%E4%BA%9B%E5%B1%82"><span class="toc-number">11.3.</span> <span class="toc-text">2、固定一些层</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B8%80%E3%80%81%E9%94%9A%E6%A1%86"><span class="toc-number">12.</span> <span class="toc-text">十一、锚框</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#IoU-%E4%BA%A4%E5%B9%B6%E6%AF%94"><span class="toc-number">12.1.</span> <span class="toc-text">IoU 交并比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B5%8B%E4%BA%88%E9%94%9A%E6%A1%86%E6%A0%87%E5%8F%B7"><span class="toc-number">12.2.</span> <span class="toc-text">赋予锚框标号</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6%EF%BC%88NMS%EF%BC%89%E8%BE%93%E5%87%BA"><span class="toc-number">12.3.</span> <span class="toc-text">使用非极大值抑制（NMS）输出</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%BA%8C%E3%80%81%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95-R-CNN"><span class="toc-number">13.</span> <span class="toc-text">十二、物体检测算法 R-CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B4%E8%B6%A3%E5%8C%BA%E5%9F%9F%EF%BC%88RoI%EF%BC%89%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="toc-number">13.1.</span> <span class="toc-text">兴趣区域（RoI）池化层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fast-RCNN"><span class="toc-number">13.2.</span> <span class="toc-text">Fast RCNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Faster-R-CNN"><span class="toc-number">13.3.</span> <span class="toc-text">Faster R-CNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mask-R-CNN"><span class="toc-number">13.4.</span> <span class="toc-text">Mask R-CNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-1"><span class="toc-number">13.5.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B8%89%E3%80%81%E5%8D%95%E5%8F%91%E5%A4%9A%E6%A1%86%E6%A3%80%E6%B5%8B-SSD"><span class="toc-number">14.</span> <span class="toc-text">十三、单发多框检测 SSD</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E9%94%9A%E6%A1%86"><span class="toc-number">14.1.</span> <span class="toc-text">生成锚框</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SSD%E6%A8%A1%E5%9E%8B"><span class="toc-number">14.2.</span> <span class="toc-text">SSD模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E5%9B%9B%E3%80%81YOLO-you-only-look-once"><span class="toc-number">15.</span> <span class="toc-text">十四、YOLO: you only look once</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%BA%94%E3%80%81%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-number">16.</span> <span class="toc-text">十五、语义分割</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%97%E4%B8%BERGB%E5%80%BC%E5%92%8C%E7%B1%BB%E5%90%8D"><span class="toc-number">16.1.</span> <span class="toc-text">列举RGB值和类名</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E4%BB%8ERGB%E5%88%B0VOC%E7%B1%BB%E5%88%AB%E7%B4%A2%E5%BC%95%E7%9A%84%E6%98%A0%E5%B0%84"><span class="toc-number">16.2.</span> <span class="toc-text">构建从RGB到VOC类别索引的映射</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E5%85%AD%E3%80%81%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF"><span class="toc-number">17.</span> <span class="toc-text">十六、转置卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A1%AB%E5%85%85%E3%80%81%E6%AD%A5%E5%B9%85%E5%92%8C%E5%A4%9A%E9%80%9A%E9%81%93"><span class="toc-number">17.1.</span> <span class="toc-text">填充、步幅和多通道</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E4%B8%8E%E5%8D%B7%E7%A7%AF%E7%9A%84%E8%BD%AC%E6%8D%A2"><span class="toc-number">17.2.</span> <span class="toc-text">转置卷积与卷积的转换</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B8%83%E3%80%81%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-FCN"><span class="toc-number">18.</span> <span class="toc-text">十七、全连接卷积神经网络 FCN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E5%85%AB%E3%80%81%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B"><span class="toc-number">19.</span> <span class="toc-text">十八、序列模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%A1%88"><span class="toc-number">19.1.</span> <span class="toc-text">常见的两种方案</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%81%E4%B9%9D%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">20.</span> <span class="toc-text">十九、注意力机制</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E5%8F%82%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="toc-number">20.1.</span> <span class="toc-text">非参的注意力池化层</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E4%B8%80%E8%88%AC%E6%83%85%E5%86%B5"><span class="toc-number">20.1.1.</span> <span class="toc-text">1、一般情况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81Nadaraya-Watson-%E6%A0%B8%E5%9B%9E%E5%BD%92"><span class="toc-number">20.1.2.</span> <span class="toc-text">2、Nadaraya-Watson 核回归</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E5%8C%96%E7%9A%84%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="toc-number">20.2.</span> <span class="toc-text">参数化的注意力机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%88%86%E6%95%B0"><span class="toc-number">20.3.</span> <span class="toc-text">注意力分数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E6%80%A7%E6%B3%A8%E6%84%8F%E5%8A%9B-additive-attention"><span class="toc-number">20.4.</span> <span class="toc-text">加性注意力 additive attention</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E9%87%87%E7%94%A8%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6%EF%BC%9F"><span class="toc-number">20.4.1.</span> <span class="toc-text">为什么要采用广播机制？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B%E8%AF%B4%E6%98%8E"><span class="toc-number">20.4.1.1.</span> <span class="toc-text">示例说明</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8masked-softmax%EF%BC%9F"><span class="toc-number">20.4.2.</span> <span class="toc-text">为什么要用masked_softmax？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">20.5.</span> <span class="toc-text">缩放点积注意力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">20.6.</span> <span class="toc-text">自注意力</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%A6%82%E4%BD%95%E5%BE%97%E5%88%B0b1"><span class="toc-number">20.6.1.</span> <span class="toc-text">一、如何得到b1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA"><span class="toc-number">20.6.2.</span> <span class="toc-text">二、矩阵表示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E6%95%B4%E4%BD%93%E7%90%86%E8%A7%A3"><span class="toc-number">20.6.2.1.</span> <span class="toc-text">1整体理解</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E5%85%B7%E4%BD%93%E8%A1%A8%E7%A4%BA"><span class="toc-number">20.6.2.2.</span> <span class="toc-text">2具体表示</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="toc-number">20.6.3.</span> <span class="toc-text">三、位置编码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E5%8D%81%E3%80%81%E7%BC%96%E7%A0%81%E5%99%A8-%E8%A7%A3%E7%A0%81%E5%99%A8"><span class="toc-number">21.</span> <span class="toc-text">二十、编码器-解码器</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E5%8D%81%E4%B8%80%E3%80%81Transformer"><span class="toc-number">22.</span> <span class="toc-text">二十一、Transformer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">22.1.</span> <span class="toc-text">多头注意力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%89%E6%8E%A9%E7%A0%81%E7%9A%84%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">22.2.</span> <span class="toc-text">有掩码的多头注意力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%BD%8D%E7%BD%AE%E7%9A%84%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C"><span class="toc-number">22.3.</span> <span class="toc-text">基于位置的前馈网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B1%82%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">22.4.</span> <span class="toc-text">层归一化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E4%BC%A0%E9%80%92"><span class="toc-number">22.5.</span> <span class="toc-text">信息传递</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B"><span class="toc-number">22.6.</span> <span class="toc-text">预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-2"><span class="toc-number">22.7.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/02/28/Swin-Unet-%E5%A4%8D%E7%8E%B0%E8%AE%B0%E5%BD%95%EF%BC%88%E8%AE%B0%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%A4%8D%E7%8E%B0%E6%88%90%E5%8A%9F%EF%BC%89/" title="Swin-Unet 复现记录（记第一次复现成功）">Swin-Unet 复现记录（记第一次复现成功）</a><time datetime="2025-02-28T06:44:00.000Z" title="发表于 2025-02-28 14:44:00">2025-02-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/25/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%202/" title="动手学深度学习 2">动手学深度学习 2</a><time datetime="2025-01-24T16:00:00.000Z" title="发表于 2025-01-25 00:00:00">2025-01-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%201/" title="动手学深度学习 1">动手学深度学习 1</a><time datetime="2024-12-02T16:00:00.000Z" title="发表于 2024-12-03 00:00:00">2024-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/11/27/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%20%E7%AC%AC%E4%B8%89%E5%A4%A9/" title="小土堆pytorch 第三天">小土堆pytorch 第三天</a><time datetime="2024-11-26T16:00:00.000Z" title="发表于 2024-11-27 00:00:00">2024-11-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/11/27/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%20%E7%AC%AC%E5%9B%9B%E5%A4%A9/" title="小土堆pytorch 第四天">小土堆pytorch 第四天</a><time datetime="2024-11-26T16:00:00.000Z" title="发表于 2024-11-27 00:00:00">2024-11-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By eric_zht</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>