{"meta":{"title":"eric_zht","subtitle":"","description":"","author":"eric_zht","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2025-06-22T03:29:46.001Z","updated":"2025-06-22T03:29:46.001Z","comments":true,"path":"CSS/custom.css","permalink":"http://example.com/CSS/custom.css","excerpt":"","text":"/* 修改标题样式 */ #page-header #site-title, #page-header #site-subtitle{ text-align: left !important; padding-left: 36px; } @media screen and (max-width: 768px) { #page-header #site-title, #page-header #site-subtitle { padding-left: 16px; } } /* 修改头像显示样式 */ .avatar-img img:hover { -webkit-transform: none; -moz-transform: none; -o-transform: none; -ms-transform: none; transform: none; }"}],"posts":[{"title":"移动软件开发 实验1：第一个微信小程序","slug":"app_class_2025_sum/exp1","date":"2025-08-24T16:00:00.000Z","updated":"2025-08-25T11:55:18.735Z","comments":true,"path":"2025/08/25/app_class_2025_sum/exp1/","permalink":"http://example.com/2025/08/25/app_class_2025_sum/exp1/","excerpt":"","text":"一、实验目标1、学习使用快速启动模板创建小程序的方法； 2、学习不使用模板手动创建小程序的方法。 二、实验步骤列出实验的关键步骤、代码解析、截图。 （一）使用快速启动模版新建小程序，目前不需要后端服务，选择不使用云服务。模版中选择JS-基础模板。 （二）不用模板手动创建选择JS基础模板后在文件夹中将所有文件删除，重头开始编写。 1、创建页面文件 全局需要三个文件：app.js，app.json，app.wxss 并且名字不可修改 创建用于存储页面的pages文件夹，创建用于展示封面的文件夹index，右键新建page，命名为index，会自动生成所需要的四个文件。 js：页面逻辑实现 json：负责标题栏和状态栏 wxml：管理页面中的元素 wxss：页面排版 2、创建元素 &lt;image&gt;&lt;/image&gt;:图片 &lt;text&gt;&lt;/text&gt;:文字 &lt;button&gt;&lt;/button&gt;:按钮 3、修改元素样式在wxss中进行修改。 1、为元素添加class属性后，在wxss中使用.class名来对对应的元素进行调整。 2、也可以直接使用元素名来直接进行调整 如： 123456image&#123; width:300rpx;&#125;text&#123; color: #014099;&#125; 4、修改头部样式 5、逻辑实现index.wxml: 12345&lt;view class=&quot;container&quot;&gt; &lt;image src=&#x27;&#123;&#123;src&#125;&#125;&#x27;&gt;&lt;/image&gt; &lt;text&gt;&#123;&#123;name&#125;&#125;&lt;/text&gt; &lt;button bindtap=&quot;getProfile&quot;&gt;点击获取头像和昵称&lt;/button&gt;&lt;/view&gt; index.js: 123456789101112131415//获取用户信息getProfile: function(e) &#123; //推荐使用wx.getuserProfile获取用户信息，开发者每次通过该接口获取用户个人信息均需用户确认， // 开发者妥善保管用户快速填写的头像昵称，避免重复弹窗 wx.getUserProfile(&#123; desc: &#x27;展示用户信息&#x27;, // 声明获取用户个人信息后的用途，后续会展示在弹窗中 success: (res) =&gt; &#123; console.log(res) this.setData(&#123; src: res.userInfo.avatarUrl, name:res.userInfo.nickName, &#125;) &#125; &#125;)&#125; , 三、程序运行结果（一）使用快速启动模板创建 （二）不用模板手动创建 四、问题总结与体会遇到的问题： 由于微信接口改变，getUserInfo已无法获取用户信息。于是按照官方说明进行修改，用户需要点击头像和昵称分别进行确认才可使用用户信息。 （在本地设置中切换调用基础库版本，调整到较老的版本可以在开发工具中测试getUserProfile函数，但是无法在用户手机中使用。） 体会： 这是初次尝试微信小程序，通过获取用户信息的这个功能的实现，学习了微信小程序的代码结构，以及css,html,js等语言的语法，体会到了前端的乐趣。","categories":[],"tags":[{"name":"大学课程","slug":"大学课程","permalink":"http://example.com/tags/%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B/"}]},{"title":"Redis","slug":"Redis","date":"2025-07-23T16:00:00.000Z","updated":"2025-08-09T13:58:30.718Z","comments":true,"path":"2025/07/24/Redis/","permalink":"http://example.com/2025/07/24/Redis/","excerpt":"","text":"初识RedisNoSQL SQL用于持久存储的数据，NoSQL一般用作缓存。 Redis介绍 关于数据持久化：Redis支持一段时间后将内存中的数据迁移到磁盘中，使数据能够断电不消失。 Redis命令Redis数据结构 通用命令 KEYS：查看符合模板的所有key，不建议在生产环境设备上使用，效率很低 DEL：删除一个指定的key EXISTS：判断key是否存在 EXPIRE：给一个key设置有效期，有效期到期时该key会被自动删除 TTL：查看一个KEY的剩余有效期 可通过help [command] 可以查看一个命令的具体用法 String类型是Redis中最简单的存储类型。 其value是字符串，不过根据字符串的格式不同，又可以分为3类： string：普通字符串 int：整数类型，可以做自增、自减操作 float：浮点类型，可以做自增、自减操作 不管是哪种格式，底层都是字节数组形式存储，只不过是编码方式不同。字符串类型的最大空间不能超过512m 常见命令 SET：添加或者修改已经存在的一个String类型的键值对 GET：根据key获取String类型的value MSET：批量添加多个String类型的键值对 MGET：根据多个key获取多个String类型的value INCR：让一个整型的key自增1 INCRBY:让一个整型的key自增并指定步长，例如：incrby num 2 让num值自增2 INCRBYFLOAT：让一个浮点类型的数字自增并指定步长 SETNX：添加一个String类型的键值对，前提是这个key不存在，否则不执行 SETEX：添加一个String类型的键值对，并且指定有效期 Key结构多个单词形成层级结构，单词之间用’:’隔开，格式如下： 1项目名:业务名:类型:id 这个格式并非固定，也可以根据自己的需求来删除或添加词条。这样以来，我们就可以把不同类型的数据区分开了。从而避免了key的冲突问题。 例如我们的项目名称叫 heima，有user和product两种不同类型的数据，我们可以这样定义key： user相关的key：heima:user:1 product相关的key：heima:product:1 如果Value是一个Java对象，例如一个User对象，则可以将对象序列化为JSON字符串后存储： KEY VALUE heima:user:1 {“id”:1, “name”: “Jack”, “age”: 21} heima:product:1 {“id”:1, “name”: “小米11”, “price”: 4999} 并且，在Redis的桌面客户端中，还会以相同前缀作为层级结构，让数据看起来层次分明，关系清晰： Hash类型Hash类型，也叫散列，其value是一个无序字典，类似于Java中的HashMap结构。 String结构是将对象序列化为JSON字符串后存储，当需要修改对象某个字段时很不方便： Hash结构可以将对象中的每个字段独立存储，可以针对单个字段做CRUD： Hash的常见命令有： HSET key field value：添加或者修改hash类型key的field的值 HGET key field：获取一个hash类型key的field的值 HMSET：批量添加多个hash类型key的field的值（redis4.0后被启用，建议使用HSET） HMGET：批量获取多个hash类型key的field的值 HGETALL：获取一个hash类型的key中的所有的field和value HKEYS：获取一个hash类型的key中的所有的field HINCRBY:让一个hash类型key的字段值自增并指定步长 HSETNX：添加一个hash类型的key的field值，前提是这个field不存在，否则不执行 List类型Redis中的List类型与Java中的LinkedList类似，可以看做是一个双向链表结构。既可以支持正向检索和也可以支持反向检索。 特征也与LinkedList类似： 有序 元素可以重复 插入和删除快 查询速度一般 常用来存储一个有序数据，例如：朋友圈点赞列表，评论列表等。 List的常见命令有： LPUSH key element … ：向列表左侧插入一个或多个元素 LPOP key number：移除并返回列表左侧的第一个元素，没有则返回nil RPUSH key element … ：向列表右侧插入一个或多个元素 RPOP key：移除并返回列表右侧的第一个元素 LRANGE key star end：返回一段角标范围内的所有元素 BLPOP key number time和BRPOP：与LPOP和RPOP类似，只不过在没有元素时等待指定时间，而不是直接返回nil Set类型Redis的Set结构与Java中的HashSet类似，可以看做是一个value为null的HashMap。因为也是一个hash表，因此具备与HashSet类似的特征： 无序 元素不可重复 查找快 支持交集、并集、差集等功能 Set的常见命令有： SADD key member … ：向set中添加一个或多个元素 SREM key member … : 移除set中的指定元素 SCARD key： 返回set中元素的个数 SISMEMBER key member：判断一个元素是否存在于set中 SMEMBERS：获取set中的所有元素 SINTER key1 key2 … ：求key1与key2的交集 例如两个集合：s1和s2: 求交集：SINTER s1 s2 求s1与s2的不同：SDIFF s1 s2 SortedSet类型Redis的SortedSet是一个可排序的set集合，与Java中的TreeSet有些类似，但底层数据结构却差别很大。SortedSet中的每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表（SkipList）加 hash表。 SortedSet具备下列特性： 可排序 元素不重复 查询速度快 因为SortedSet的可排序特性，经常被用来实现排行榜这样的功能。 SortedSet的常见命令有： ZADD key score member：添加一个或多个元素到sorted set ，如果已经存在则更新其score值 ZREM key member：删除sorted set中的一个指定元素 ZSCORE key member : 获取sorted set中的指定元素的score值 ZRANK key member：获取sorted set 中的指定元素的排名 ZCARD key：获取sorted set中的元素个数 ZCOUNT key min max：统计score值在给定范围内的所有元素的个数 ZINCRBY key increment member：让sorted set中的指定元素自增，步长为指定的increment值 ZRANGE key min max：按照score排序后，获取指定排名范围内的元素 ZRANGEBYSCORE key min max：按照score排序后，获取指定score范围内的元素 ZDIFF、ZINTER、ZUNION：求差集、交集、并集 注意：所有的排名默认都是升序，如果要降序则在命令的Z后面添加REV即可，例如： 升序获取sorted set 中的指定元素的排名：ZRANK key member 降序获取sorted set 中的指定元素的排名：ZREVRANK key memeber Redis的Java客户端在Redis官网中提供了各种语言的客户端，地址：https://redis.io/docs/clients/ 其中Java客户端也包含很多： 标记为*的就是推荐使用的java客户端，包括： Jedis和Lettuce：这两个主要是提供了Redis命令对应的API，方便我们操作Redis，而SpringDataRedis又对这两种做了抽象和封装，因此我们后期会直接以SpringDataRedis来学习。 Redisson：是在Redis基础上实现了分布式的可伸缩的java数据结构，例如Map、Queue等，而且支持跨进程的同步机制：Lock、Semaphore等待，比较适合用来实现特殊的功能需求。 Jedis客户端Jedis的官网地址： https://github.com/redis/jedis 快速入门我们先来个快速入门： 1）引入依赖： 12345678910111213&lt;!--jedis--&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--单元测试--&gt;&lt;dependency&gt; &lt;groupId&gt;org.junit.jupiter&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt; &lt;version&gt;5.7.0&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 2）建立连接 新建一个单元测试类，内容如下： 123456789101112private Jedis jedis;@BeforeEachvoid setUp() &#123; // 1.建立连接 // jedis = new Jedis(&quot;192.168.150.101&quot;, 6379); jedis = JedisConnectionFactory.getJedis(); // 2.设置密码 jedis.auth(&quot;123321&quot;); // 3.选择库 jedis.select(0);&#125; 3）测试： 1234567891011121314151617181920@Testvoid testString() &#123; // 存入数据 String result = jedis.set(&quot;name&quot;, &quot;虎哥&quot;); System.out.println(&quot;result = &quot; + result); // 获取数据 String name = jedis.get(&quot;name&quot;); System.out.println(&quot;name = &quot; + name);&#125;@Testvoid testHash() &#123; // 插入hash数据 jedis.hset(&quot;user:1&quot;, &quot;name&quot;, &quot;Jack&quot;); jedis.hset(&quot;user:1&quot;, &quot;age&quot;, &quot;21&quot;); // 获取 Map&lt;String, String&gt; map = jedis.hgetAll(&quot;user:1&quot;); System.out.println(map);&#125; 4）释放资源 123456@AfterEachvoid tearDown() &#123; if (jedis != null) &#123; jedis.close(); &#125;&#125; 连接池Jedis本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此我们推荐大家使用Jedis连接池代替Jedis的直连方式。 123456789101112131415161718192021222324package com.heima.jedis.util;import redis.clients.jedis.*;public class JedisConnectionFactory &#123; private static JedisPool jedisPool; static &#123; // 配置连接池 JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(8); poolConfig.setMaxIdle(8); poolConfig.setMinIdle(0); // poolConfig.setMaxWaitMillis(1000); redis新版已弃用 poolConfig.setMaxWait(Duration.ofSeconds(200)); // 新版用这个 // 创建连接池对象，参数：连接池配置、服务端ip、服务端端口、超时时间、密码 jedisPool = new JedisPool(poolConfig, &quot;192.168.150.101&quot;, 6379, 1000, &quot;123321&quot;); &#125; public static Jedis getJedis()&#123; return jedisPool.getResource(); &#125;&#125; SpringDataRedis客户端对jedis和lettuce进行了抽象和封装。 SpringData是Spring中数据操作的模块，包含对各种数据库的集成，其中对Redis的集成模块就叫做SpringDataRedis，官网地址：https://spring.io/projects/spring-data-redis 提供了对不同Redis客户端的整合（Lettuce和Jedis） 提供了RedisTemplate统一API来操作Redis 支持Redis的发布订阅模型 支持Redis哨兵和Redis集群 支持基于Lettuce的响应式编程 支持基于JDK、JSON、字符串、Spring对象的数据序列化及反序列化 支持基于Redis的JDKCollection实现 SpringDataRedis中提供了RedisTemplate工具类，其中封装了各种对Redis的操作。并且将不同数据类型的操作API封装到了不同的类型中： 快速入门SpringBoot已经提供了对SpringDataRedis的支持，使用非常简单。 首先，新建一个maven项目，然后按照下面步骤执行： 引入依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.7&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.heima&lt;/groupId&gt; &lt;artifactId&gt;redis-demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;redis-demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--redis依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--common-pool--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Jackson依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 配置Redis1234567891011spring: redis: host: 192.168.150.101 port: 6379 password: 123321 lettuce: pool: max-active: 8 max-idle: 8 min-idle: 0 max-wait: 100ms 注入RedisTemplate因为有了SpringBoot的自动装配，我们可以拿来就用： 123456@SpringBootTestclass RedisStringTests &#123; @Autowired private RedisTemplate redisTemplate;&#125; 编写测试123456789101112131415@SpringBootTestclass RedisStringTests &#123; @Autowired private RedisTemplate edisTemplate; @Test void testString() &#123; // 写入一条String数据 redisTemplate.opsForValue().set(&quot;name&quot;, &quot;虎哥&quot;); // 获取string数据 Object name = stringRedisTemplate.opsForValue().get(&quot;name&quot;); System.out.println(&quot;name = &quot; + name); &#125;&#125; 自动序列化RedisTemplate可以接收任意Object作为值写入Redis： 只不过写入前会把Object序列化为字节形式，默认是采用JDK序列化，得到的结果是这样的： 缺点： 可读性差 内存占用较大 我们可以自定义RedisTemplate的序列化方式，代码如下： 12345678910111213141516171819202122@Configurationpublic class RedisConfig &#123; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory connectionFactory)&#123; // 创建RedisTemplate对象 RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); // 设置连接工厂 template.setConnectionFactory(connectionFactory); // 创建JSON序列化工具 GenericJackson2JsonRedisSerializer jsonRedisSerializer = new GenericJackson2JsonRedisSerializer(); // 设置Key的序列化 template.setKeySerializer(RedisSerializer.string()); template.setHashKeySerializer(RedisSerializer.string()); // 设置Value的序列化 template.setValueSerializer(jsonRedisSerializer); template.setHashValueSerializer(jsonRedisSerializer); // 返回 return template; &#125;&#125; 这里采用了JSON序列化来代替默认的JDK序列化方式。最终结果如图： 整体可读性有了很大提升，并且能将Java对象自动的序列化为JSON字符串，并且查询时能自动把JSON反序列化为Java对象。不过，其中记录了序列化时对应的class名称，目的是为了查询时实现自动反序列化。这会带来额外的内存开销。 手动序列化 StringRedisTemplate为了节省内存空间，我们可以不使用JSON序列化器来处理value，而是统一使用String序列化器，要求只能存储String类型的key和value。当需要存储Java对象时，手动完成对象的序列化和反序列化。 因为存入和读取时的序列化及反序列化都是我们自己实现的，SpringDataRedis就不会将class信息写入Redis了。 这种用法比较普遍，因此SpringDataRedis就提供了RedisTemplate的子类：StringRedisTemplate，它的key和value的序列化方式默认就是String方式。 省去了我们自定义RedisTemplate的序列化方式的步骤，而是直接使用： 123456789101112131415161718192021@Autowiredprivate StringRedisTemplate stringRedisTemplate;// JSON序列化工具private static final ObjectMapper mapper = new ObjectMapper();@Testvoid testSaveUser() throws JsonProcessingException &#123; // 创建对象 User user = new User(&quot;虎哥&quot;, 21); // 手动序列化 String json = mapper.writeValueAsString(user); // 写入数据 stringRedisTemplate.opsForValue().set(&quot;user:200&quot;, json); // 获取数据 String jsonUser = stringRedisTemplate.opsForValue().get(&quot;user:200&quot;); // 手动反序列化 User user1 = mapper.readValue(jsonUser, User.class); System.out.println(&quot;user1 = &quot; + user1);&#125; MVC 模式Model-View-Controller（模型-视图-控制器） 模式。 模型（Model）：负责数据和业务逻辑，通常包含数据存储、检索和业务规则。 视图（View）：负责显示数据（模型）的用户界面，不包含业务逻辑。 控制器（Controller）：接收用户的输入，调用模型和视图去完成用户的请求。 与三层架构模式的区别： 三层架构是基于业务逻辑来分的，而MVC是基于页面来分的 实战——黑马点评发送验证码1、如果需要在log中使用{}来表示变量，需要使用@Slf4j注解 2、controller中接收到手机号后，立刻调用service接口中实现的函数。这样可以通过接口代码文件快速看出这个接口有哪些函数，可以干什么。 验证码登录&#x2F;注册登录校验拦截器1、拦截器要去实现 HandlerInterceptor接口 preHandle、postHandle、afterCompletion： https://blog.csdn.net/qq_34246965/article/details/122943699 2、由于User中包含密码、手机号等敏感信息，如果直接把User存到session中，会导致敏感信息泄露。因此在存放到session时，需要将其转为UerDTO类型（仅包含部分信息） 使用BeanUtil的一个工具类copyProperties： 1session.setAttribute(&quot;user&quot;, BeanUtil.copyProperties(user, UserDTO.class));","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"JDBC","slug":"JavaWeb","date":"2025-06-03T16:00:00.000Z","updated":"2025-07-23T08:19:30.058Z","comments":true,"path":"2025/06/04/JavaWeb/","permalink":"http://example.com/2025/06/04/JavaWeb/","excerpt":"","text":"一、JSON 基础语法 二、Ajax - Axios发起异步请求Ajax作用： 数据交换：通过Ajax可以给服务器发送请求，并获取服务器响应的数据。 异步交互：可以在不重新加载整个页面的情况下，与服务器交换数据并更新部分网页，如：搜索联想、用户名是否可用的校验等。 AxiosAxios对原生的Ajax进行了封装，简化书写，快速开发。 使用步骤： 简化写法 Maven一款用于管理和构建java项目的工具。 依赖管理：方便的管理项目依赖的资源，避免版本冲突问题 统一项目结构：提供标准、统一的项目结构 项目构建：标准跨平台的自动化项目构建方式 仓库： 创建 groupId：定义当前Maven项目隶属的组织名称（通常是域名反写，如space.ericzht） artifactId：定义当前Maven项目名称 version：定义当前项目版本号 生命周期Maven的生命周期是为了对所有的Maven项目构建过程进行抽象和统一。 Maven中有3套相互独立的生命周期： clean：清理工作 default：核心工作，如：编译、测试、打包、安装、部署等 site：生成报告、发布站点等 需要了解的五个生命周期： test为什么日志无法显示结果？test包里的Java文件必须以Test结尾,日志没显示出来是因为类名错误，找不到test的文件 SpringSpringBoot快速便捷的Spring框架，基于SpringBoot可以快速构建Spring框架。 SpringBoot快速入门新建模块依赖中要勾选Spring Web 创建请求处理类 HelloController 运行启动类，在浏览器中进行测试 Tips：包被识别成文件夹怎么办？右键Java目录，选择标记目录为源根 HTTP协议概述Hyper Text Tranfer Protocol 超文本传输协议 特点： 基于TCP协议：面向连接，安全 基于请求-响应模型：一次请求对应一次响应 HTTP协议是无状态的协议：对事务处理没有记忆能力。每次请求-响应都是独立的。 缺点：多次请求之间不能共享数据 优点：速度快 请求数据 响应数据 状态码大类 状态码分类 说明 1xx 响应中——临时状态码，表示请求已经接受，告诉客户端应该继续请求或者如果它已经完成则忽略它 2xx 成功——表示请求已经被成功接收，处理已完成 3xx 重定向——重定向到其它地方：它让客户端再发起一个请求以完成整个处理。 4xx 客户端错误——处理发生错误，责任在客户端，如：客户端的请求一个不存在的资源，客户端未被授权，禁止访问等 5xx 服务器端错误——处理发生错误，责任在服务端，如：服务端抛出异常，路由出错，HTTP版本不支持等 常见的响应状态码 状态码 英文描述 解释 &#x3D;&#x3D;200&#x3D;&#x3D; OK 客户端请求成功，即处理成功，这是我们最想看到的状态码 302 Found 指示所请求的资源已移动到由Location响应头给定的 URL，浏览器会自动重新访问到这个页面 304 Not Modified 告诉客户端，你请求的资源至上次取得后，服务端并未更改，你直接用你本地缓存吧。隐式重定向 400 Bad Request 客户端请求有语法错误，不能被服务器所理解 403 Forbidden 服务器收到请求，但是拒绝提供服务，比如：没有权限访问相关资源 &#x3D;&#x3D;404&#x3D;&#x3D; Not Found 请求资源不存在，一般是URL输入有误，或者网站资源被删除了 405 Method Not Allowed 请求方式有误，比如应该用GET请求方式的资源，用了POST 428 Precondition Required 服务器要求有条件的请求，告诉客户端要想访问该资源，必须携带特定的请求头 429 Too Many Requests 指示用户在给定时间内发送了太多请求（“限速”），配合 Retry-After(多长时间后可以请求)响应头一起使用 431 Request Header Fields Too Large 请求头太大，服务器不愿意处理请求，因为它的头部字段太大。请求可以在减少请求头域的大小后重新提交。 &#x3D;&#x3D;500&#x3D;&#x3D; Internal Server Error 服务器发生不可预期的错误。服务器出异常了，赶紧看日志去吧 503 Service Unavailable 服务器尚未准备好处理请求，服务器刚刚启动，还未初始化好 状态码大全：https://cloud.tencent.com/developer/chapter/13553 Tomcat概述 一个开源免费的轻量级Web服务器，支持Servlet&#x2F;JSP少量的JavaEE规范。 JavaEE：Java企业版，指企业级开发的技术规范总和。 Tomcat也被称为Web容器、Servlet容器。Servlet程序需要依赖于Tomcat才能运行 对HTTP协议操作进行了封装，简化web程序开发。 请求 Postman在网页调试中，只能在地址栏添加内容，这是GET类型的请求，很难对POST类型的请求进行测试。于是出现了Postman插件。 网页调试与发送网页HTTP请求的Chrome插件 常用于进行接口测试 SpringBoot接受请求的方式（简单参数）12345678@RestControllerpublic class HelloController &#123; @RequestMapping(&quot;/simpleRequest&quot;) public String simpleRequest(String name, int age)&#123; // 直接把请求需要传的参数写在函数的参数列表中，会自动进行类型转换，由String转换为你写的类型 System.out.println(name + &quot;:&quot; + age); return &quot;OK&quot;; &#125;&#125; 12345@RequestMapping(&quot;/simpleRequest&quot;)public String simpleRequest(@RequestParam(name = &quot;name&quot;) String username, int age)&#123; // 这里相当于给username添加了一个别名，叫name。到时候客户端发送请求的时候使用name进行请求。（不可以使用username） System.out.println(username + &quot;:&quot; + age); return &quot;OK&quot;;&#125; @RequestParam中的required属性默认为true，代表该请求参数必须传递，如果不传递则报错。如果这个参数是可选的，可以将required属性设置为false。 原始方式接受请求* SpringBoot接受请求的方式（实体参数）把所有参数封装到一个类中，获取时将参数全部放入类的对象中。 简单实体对象 复杂实体对象 注：这里要给类写toString方法，否则输出的是类的类似于地址的东西。 数组集合参数 数组参数：请求参数名与形参数组名称相同且请求参数为多个，定义数组类型参数即可接受参数 集合参数：需要使用 @RequestParam 绑定参数关系 日期参数 Json参数 路径参数 响应 这样响应回去的数据是各式各样的，前后端开发成本高、不便管理、很难维护。 —— 于是设定一个统一响应的规范 Result Springboot静态资源存放目录 分层解耦内聚：软件中各个功能模块内部的功能联系 耦合：衡量软件中各个层&#x2F;模块之间的依赖、关联程度 软件设计原则：高内聚低耦合 三层架构 Controller：控制层，接收前端发送的请求，对请求进行处理，并响应数据。 Service：业务逻辑层，处理具体的业务逻辑。 Dao：数据访问层（Data Access Object）（持久层），负责数据访问操作，包括数据的增删改查。 分层解耦 上图这种架构，如果ServiceA要改为ServiceB，那么不仅要修改Service层的代码，还要修改Controller层的代码，Service层和Controller层耦合度较高，不利于后续开发。 于是Spring提出了控制反转与依赖注入。 控制反转Inversion Of Control，IOC 对象的创建控制权由程序自身转移到外部（容器） 依赖注入Dependency Injection，DI 容器为应用程序提供运行时所依赖的资源 Bean对象IOC容器中创建、管理的对象 步骤只有单个bean 将Service层及Dao层的实现类交给IOC容器管理。 添加注解 @Component 为Controller及Service注入运行时依赖的对象。添加注解 @Autowired ​ 程序在运行时会自动为他们提供所注解的对象 如果要切换Service层的内容，直接将原来的Service层的@Component注解注释掉给新的添加注释就好了。 同时有多个bean@Autowired 默认是按照类型进行的，如果存在多个相同的bean，会报错。 解决方法： 在想要执行的类的注解上加上**@Primary**注解设置其为高优先级。 @Autowired + @Qualifier(“bean的名称”) @Resource(name&#x3D;”bean的名称”) 区别： @Autowired 是spring框架提供的注解，而@Resource是JDK提供的注解 @Autowired 默认是按照类型注入，而@Resource默认是按照名称注入 Bean组件扫描 前面声明bean的四大注解，要想生效，还需要被组件扫描注解**@ComponentScan**扫描 启动类声明的注解**@SpringBootApplication**中，默认扫描的范围是启动类所在包及其子包 如果在别的地方添加了组件，并且想要被扫描，就要使用 @ComponentScan(“包名”) 来显式配置，并且需要加上启动类所在的包名。 MyBatis是一款优秀的持久层（dao层），用于简化JDBC的开发 快速入门 程序会自动将获取到的数据封装到User对象中，并装入List类型的集合 这里运用了IOC（控制反转）和依赖注入。 将对象的创建控制权由程序自身转移到外部（容器），并且由IOC容器来自动创建对象，需加上@Autowired注解 JDBC sun公司提供的一套操作关系型数据库的API（规范），但是操作很繁琐，因此使用MyBatis来简化开发。 数据库连接池是一个容器，负责分配、管理数据库连接。 它允许应用程序重复使用一个现有的数据库连接，而不是重新建立一个连接，减少资源浪费。 释放空间时间超过最大空闲时间的连接，避免因为没有释放连接而引起的数据库连接遗漏。 优势： 资源重用 提升系统响应速度 避免数据库连接遗漏 标准接口：DataSource 第三方组织实现了该接口，springboot默认使用Hikari（追光者） Druid（德鲁伊）：阿里巴巴开源的数据库连接池项目，功能强大、性能优秀，是java语言最好的数据库连接池之一。 Lombok一个实用的Java类库，能通过注解自动生成构造器、getter&#x2F;setter、equals、toString等方法，并可以自动生成日志变量，简化java开发、提高效率。 需在pom文件中引入依赖： 基础操作删除12@Delete(&quot;delete from emp where id = #&#123;id&#125;&quot;) // 使用占位符来获取变量信息，如果只传一个参数，那占位符中的属性名可以随便写，可以写id、value等等public void delete(Integer id); 使用占位符编写的sql语句就是预编译的sql语句，编译时会用？来替换掉占位符 预编译 性能更高 更安全（防止sql注入） 参数占位符 新增 主键返回在数据添加成功后，需要获取插入数据库数据的主键。 如：添加套餐数据时，需要维护套餐菜品关系表数据 更新（修改） 查询 数据封装 方案1：给字段起别名，让别名与实体类属性一致 方案2：通过@Results，@Result注解手动映射封装 方案3：开启mybatis的驼峰命名自动映射开关即a_column –&gt; aColumn 在application.properties中添加： 条件查询 由于${ }是进行拼接，没有进行预编译，性能低。并且存在sql注入问题，所以更推荐使用concat进行拼接，这样仍然可以在concat中使用#{ } springboot版本问题 XML映射文件 XML映射文件的名称与Mapper接口名称一致，并且将XML映射文件和Mapper接口放置在相同包下（同包同名）。 XML映射文件的namespace属性与Mapper接口全限定名一致。 XML映射文件中sql语句的id与Mapper接口中的方法名一致，并保持返回类型一致。 注：如果函数是void类型的，那么就不需要写resultType了。 注解主要完成简单的增删改查功能，如果需要复杂的SQL功能，建议使用XML来配置映射语句。 动态SQL随着用户的输入或外部条件的变化而变化的SQL语句 &lt;if&gt;用于判断条件是否成立。使用test属性进行条件判断，如果条件为true，则拼接其中的SQL语句。 &lt;where&gt;where元素只会在子元素有内容的情况下才插入其中的内容，并且会自动判断是否需要删除子句开头的and或者or &lt;set&gt;动态在行首插入set关键字，并会删掉额外的逗号。（用在update语句中） &lt;foreach&gt; &lt;sql&gt;和&lt;include&gt;相当于封装为一个函数，需要时使用include调用即可。实现代码的复用。 案例开发规范RestfulREST（REpresentational State Transfer），表述性状态转换，它是一种软件架构风格。 是一种约定，而不是规定，可以打破。 统一响应结果 开发流程 日志定义日志对象 法一1private static Logger log = LoggerFactory.getLogger(DeptController.class); 法二直接在controller接口上添加@Slf4j注解，自动生成日志记录对象（lombok提供的便携方式） tips封装json数据当前端提供的是json格式的数据，可以使用@RequestBody注解来将json数据封装到一个实体类中 省略相同的路径可以将方法的注解中相同部分的路径提取到类上的@RequestMapping注解中 分页查询 文件上传使用MultipartFile类型的变量来接收上传的文件，变量名需要与前端中该表单项的名字相同。 上传大小限制在SpringBoot中，默认单个文件允许最大大小为1M，如果需要上传大文件，需要在application.properties中添加配置： 本地存储 云端存储根据云服务商提供的官方文档 将服务器信息写在配置文件中，通过注解的形式引入，便于后面的管理和维护。 如果使用@ConfiurationProperties注解的话需要将所有属性写到单独的一个类中，并交给IOC管理，需要使用的时候自动创建Bean对象，并通过这个对象的get方法获取对象中的属性。 单独的类： 依赖注入： yml配置文件常见配置文件格式对比 yml 大小写敏感 数值前必须有空格，作为分隔符 使用缩进表示层级关系，缩进时不可以使用tab键，只能用空格。（但是idea会自动将tab转换为空格） 缩进的空格数不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 左properties 右yml： 登录校验 会话技术会话：用户打开浏览器，访问web服务器的资源，会话建立。直到有一方断开连接，会话结束。在一次会话中可以包含多次请求和响应。 会话跟踪：一种维护浏览器状态的方法，服务器需要识别多次请求是否来自于同一浏览器，以便在同一会话的多次请求间共享数据。 会话跟踪方案： ​ 客户端会话跟踪技术：Cookie ​ 服务端会话跟踪技术：Session ​ 令牌技术 会话跟踪方案对比 主流方案： JWT令牌JSON Web Token 定义了一种简洁的、自包含的格式，用于在通信双方以json数据格式安全的传输信息。由于数字签名的存在，这些信息是可靠的。 使用场景： 登陆成功后，生成令牌。 后续每个请求，都要携带JWT令牌，系统在每次请求处理之前，先校验令牌，通过后，再处理。 生成令牌 解析、校验令牌 过滤器 Filter可以把对资源的请求拦截下来，从而实现一些特殊的功能（登录校验、统一编码处理、敏感字符处理等）。 入门 执行流程 拦截路径 过滤器链 登录校验流程 拦截器一种动态拦截方法调用的机制，类似于过滤器。Spring框架中提供，用来动态拦截控制器（Controller）方法的执行。 作用：拦截请求，在指定方法调用前后，根据业务执行预先设定的代码。 入门 拦截路径 执行流程 异常处理 事务管理事务是一组操作的集合，是一个不可分割的工作单位，这些操作要么同时成功，要么同时失败。 Spring事务管理@Transactional 注解写在业务（service）层的方法、类、接口上 作用：将当前方法交给Spring进行事务管理，方法执行前，开启事务。成功执行结束，则提交事务；出现异常，则回滚事务。 默认情况下，只有出现 RuntimeException 才会回滚。 事务管理日志在yml文件中配置 rollbackFor属性——回滚用于控制出现何种异常类型时，回滚事务。 1@Transactional(rollbackFor = Exception.class) // 这样设置是所有异常都会回滚 propagation属性——传播行为当一个事务被另一个事务方法调用时，这个事务方法应如何进行事务控制。 AOPAOP基础概述Aspect Oriented Programming （面向方面编程），其实就是面向特定方法编程 场景： 部分功能运行较慢，如果要定位执行耗时较长的业务方法，需要统计每一个业务方法的执行耗时 实现： 动态代理是面向切面编程最主流的实现。而SpringAOP是Spring框架的高级技术，旨在管理bean对象的过程中，主要通过底层的动态代理机制，对特定的方法进行编程。 更正，不是接口名，而是类名 核心概念 通知类型即什么时候执行方法。 切入点表达式用来描述切入点方法的一种表达式。 作用：决定项目中的哪些方法需要加入通知 常见形式1：execution () 匹配没有参数的方法 (..) 匹配有任意数量参数的方法 (*) 匹配有一个任意类型参数的方法 (*,String) 匹配有两个参数的方法，并且第一个为任意类型，第二个为 String 类型 通配符描述切入点： 根据业务需要，可以使用与&amp;&amp;，或||，非! 来组合比较复杂的切入点表达式 注：update* 表示以update开头的方法 封装如果几个切面的切入点表达式相同（重复——&gt;封装） 常见形式2：@annotation用于匹配标识有特定注解的方法 这样的话需要创建一个文件来定义注解： 12345@Retention(RetentionPolicy.RUNTIME) // 设置该注解用于代码运行时@Target(ElementType.METHOD) // 设置该注解只能用于方法public @interface MyLog&#123; &#125; 上图annotation中的内容时这个注解定义文件的具体包名。 通知顺序 SpringBoot 原理配置文件优先级 java系统属性和命令行参数配置springboot除了支持使用配置文件来配置属性，还支持以下两种方式配置属性。 bean的获取 bean的作用域可以通过 @Scope 注解来配置作用域 第三方bean对象","categories":[],"tags":[{"name":"JDBC","slug":"JDBC","permalink":"http://example.com/tags/JDBC/"}]},{"title":"JDBC","slug":"JDBC","date":"2025-06-03T16:00:00.000Z","updated":"2025-06-05T03:08:12.731Z","comments":true,"path":"2025/06/04/JDBC/","permalink":"http://example.com/2025/06/04/JDBC/","excerpt":"","text":"一、概述Java DataBase Connectivity ： Java 数据库连接 Java语言操作关系型数据库的一套规则（接口），各个数据库厂商去实现这套接口，提供数据库驱动jar包。真正执行的代码是驱动包中的实现类。 JDBC的好处：各数据库使用相同的接口，Java代码不需要针对不同数据库分别开发。可随时替换底层数据库，访问数据库的Java代码基本不变。 二、DriverManager注册驱动1Class.forName(&quot;com.mysql.jdbc.Driver&quot;); Driver类源码中含有静态代码块，静态代码块中直接就初始化驱动对象了。 注：MySQL5之后的驱动包，可以省略注册驱动这一步。 获取连接 参数： Connection获取执行SQL的statement对象普通执行SQL对象Statement createStatement() 预编译SQL的执行SQL对象：防止SQL注入PreparedStatement prepareStatement(sql) 执行存储过程的对象CallableStatement prepareCall(sql) 事务管理 Statement执行SQL语句 ResultSet封装DQL查询语句的结果获取查询结果： PreparedStatement继承自Statement类，预编译SQL语句并执行，预防SQL注入问题。 SQL注入：通过操作输入来修改事先定义好的SQL语句，以达到执行代码对服务器进行攻击的方法。 防止SQL注入：它相当于把你输入的敏感标点前加入转义字符\\，使得整体看成文本，而不会和代码进行结合，避免你输入的内容改变了代码的原义。 预编译SQL：可提升性能。开启此功能需要设置参数useServerPrepStms=true 数据库连接池概述数据库连接池是个容器，负责分配、管理数据库连接（Connection）。 它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个。 释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏 好处： 资源重用 提升系统响应速度 避免数据库连接遗漏 实现 标准接口：DataSource 官方提供的标准接口，由第三方实现此接口。 功能：获取连接 Connection getConnection() 目前常用的数据库连接池： Druid（德鲁伊） 阿里巴巴开源的数据库连接池项目 功能强大，性能优秀，是Java语言最好的数据库连接池之一。 使用步骤 导入jar包 druid-1.1.12.jar 定义配置文件 加载配置文件 获取数据库连接池对象 获取连接","categories":[],"tags":[{"name":"JDBC","slug":"JDBC","permalink":"http://example.com/tags/JDBC/"}]},{"title":"mysql 高级","slug":"mysql高级","date":"2025-06-01T16:00:00.000Z","updated":"2025-06-04T09:11:43.447Z","comments":true,"path":"2025/06/02/mysql高级/","permalink":"http://example.com/2025/06/02/mysql%E9%AB%98%E7%BA%A7/","excerpt":"","text":"存储过程概述数据库中内置的一种编程语言，可以把多条SQL语句以逻辑代码的方式串联起来执行。 每一个存储过程都是一个数据库对象，就像table和view一样，存储在数据库中，一次编译永久有效。每一个存储过程都有自己的名字，客户端程序通过名字来调用存储过程。 在数据量特别大的情况下使用存储过程能达到倍速的效率提升。 优缺点优点：速度快。 - 降低了**应用服务器**和**数据库服务器**之间网络通讯的开销。尤其在数据量庞大的情况下效果显著。 缺点：移植性差。编写难度大。维护性差。 - 每一个数据库都有自己的存储过程的语法规则，这种语法规则不是通用的。一旦使用了存储过程，则数据库产品很难更换，例如：编写了mysql的存储过程，这段代码只能在mysql中运行，无法在oracle数据库中运行。 - 对于数据库存储过程这种语法来说，没有专业的IDE工具（集成开发环境），所以编码速度较低。自然维护的成本也会较高。 在实际开发中，存储过程还是很少使用的。只有在系统遇到了性能瓶颈，在进行优化的时候，对于大数量的应用来说，可以考虑使用一些。 第一个存储过程存储过程的创建1234create procedure p1()begin select empno,ename from emp;end; 存储过程的调用1call p1(); 存储过程的查看查看创建存储过程的语句： 1show create procedure p1; 通过系统表information_schema.ROUTINES查看存储过程的详细信息：information_schema.ROUTINES 是 MySQL 数据库中一个系统表，存储了所有存储过程、函数、触发器的详细信息，包括名称、返回值类型、参数、创建时间、修改时间等。 1select * from information_schema.routines where routine_name = &#x27;p1&#x27;; information_schema.ROUTINES 表中的一些重要的列包括： SPECIFIC_NAME：存储过程的具体名称，包括该存储过程的名字，参数列表。 ROUTINE_SCHEMA：存储过程所在的数据库名称。 ROUTINE_NAME：存储过程的名称。 ROUTINE_TYPE：PROCEDURE表示是一个存储过程，FUNCTION表示是一个函数。 ROUTINE_DEFINITION：存储过程的定义语句。 CREATED：存储过程的创建时间。 LAST_ALTERED：存储过程的最后修改时间。 DATA_TYPE：存储过程的返回值类型、参数类型等。 存储过程的删除1drop procedure if exists p1; delimiter命令在 MySQL 中，delimiter 命令用于改变 MySQL 解释语句的定界符。MySQL 默认使用分号 ; 作为语句的定界符。而使用 delimiter 命令可以将分号 ; 更改为其他字符，从而可以在 SQL 语句中使用分号 ;。 例如，假设需要创建一个存储过程。在存储过程中通常会包括多条 SQL 语句，而这些语句都需要以分号 ; 结尾。但默认情况下，执行到第一条语句的分号 ; 后，MySQL 就会停止解释，导致后续的语句无法执行。解决方式就是使用 delimiter 命令将分号改为其他字符，使分号 ; 不再是语句定界符。例如： 123456789delimiter //CREATE PROCEDURE my_proc ()BEGINSELECT * FROM my_table;INSERT INTO my_table (col1, col2) VALUES (&#x27;value1&#x27;, &#x27;value2&#x27;);END //delimiter ; 在这个例子中，我们使用 delimiter // 命令将定界符改为两个斜线 //。在存储过程中，以分号 ; 结尾的语句不再被解释为语句的结束。而使用 delimiter ; 可以将分号恢复为语句定界符。 总之，delimiter 命令可以改变 MySQL 数据库系统中 SQL 查询语句的分隔符，从而可使一条 SQL 查询语句包含多个 SQL 语句。这样的话，就方便了我们在一个语句里面加入多个语句，而且不会被错 MySQL的变量mysql中的变量包括：系统变量、用户变量、局部变量。 系统变量MySQL 系统变量是指在 MySQL 服务器运行时控制其行为的参数。这些变量可以被设置为特定的值来改变服务器的默认设置，以满足不同的需求。MySQL 系统变量可以具有全局（global）或会话（session）作用域。 全局作用域是指对所有连接和所有数据库都适用； 会话作用域是指只对当前连接和当前数据库适用。 查看系统变量 12345show [global|session] variables;show [global|session] variables like &#x27;&#x27;;select @@[global|session.]系统变量名; 注意：没有指定session或global时，默认是session。 设置系统变量 123set [global | session] 系统变量名 = 值;set @@[global | session.]系统变量名 = 值; 注意：无论是全局设置还是会话设置，当mysql服务重启之后，之前配置都会失效。可以通过修改MySQL根目录下的my.ini配置文件达到永久修改的效果。（my.ini是MySQL数据库默认的系统级配置文件，默认是不存在的，需要新建，并参考一些资料进行配置。）windows系统是my.inilinux系统是my.cnfmy.ini文件通常放在mysql安装的根目录下，如下图：这个文件通常是不存在的，可以新建，新建后例如提供以下配置： 12[mysqld]autocommit=0 这种配置就表示永久性关闭自动提交机制。（不建议这样做。） 用户变量用户自定义的变量。只在当前会话有效。所有的用户变量‘@’开始。 给用户变量赋值 12345set @name = &#x27;jackson&#x27;;set @age := 30;set @gender := &#x27;男&#x27;, @addr := &#x27;北京大兴区&#x27;;select @email := &#x27;jackson@123.com&#x27;;select sal into @sal from emp where ename =&#x27;SMITH&#x27;; 读取用户变量的值 1select @name, @age, @gender, @addr, @email, @sal; 注意：mysql中变量不需要声明。直接赋值就行。如果没有声明变量，直接读取该变量，返回null 局部变量在存储过程中可以使用局部变量。使用declare声明。在begin和end之间有效。 变量的声明 1declare 变量名 数据类型 [default ...]; 变量的数据类型就是表字段的数据类型，例如：int、bigint、char、varchar、date、time、datetime等。注意：declare通常出现在begin end之间的开始部分。 变量的赋值 123set 变量名 = 值;set 变量名 := 值;select 字段名 into 变量名 from 表名 ...; 例如：以下程序演示局部变量的声明、赋值、读取： 123456789101112131415create PROCEDURE p2()begin /*声明变量*/ declare emp_count int default 0; /*声明变量*/ declare sal double(10,2) default 0.0; /*给变量赋值*/ select count(*) into emp_count from emp; /*给变量赋值*/ set sal := 5000.0; /*读取变量的值*/ select emp_count; /*读取变量的值*/ select sal;end; 1call p2(); if语句语法格式： 123456789if 条件 then......elseif 条件 then......elseif 条件 then......else......end if; 案例：员工月薪sal，超过10000的属于“高收入”，6000到10000的属于“中收入”，少于6000的属于“低收入”。 12345678910111213create procedure p3( )begin declare sal int default 5000; declare grade varchar(20); if sal &gt; 10000 then set grade := &#x27;高收入&#x27;; elseif sal &gt;= 6000 then set grade := &#x27;中收入&#x27;; else set grade := &#x27;低收入&#x27;; end if; select grade;end; 1call p3(); 参数存储过程的参数包括三种形式： in：入参（未指定时，默认是in） out：出参 inout：既是入参，又是出参 案例：员工月薪sal，超过10000的属于“高收入”，6000到10000的属于“中收入”，少于6000的属于“低收入”。 12345678910create procedure p4(in sal int, out grade varchar(20))begin if sal &gt; 10000 then set grade := &#x27;高收入&#x27;; elseif sal &gt;= 6000 then set grade := &#x27;中收入&#x27;; else set grade := &#x27;低收入&#x27;; end if;end; 12call p4(5000, @grade);select @grade; 案例：将传入的工资sal上调10% 1234create procedure p5(inout sal int)begin set sal := sal * 1.1;end; 123set @sal := 10000;call p5(@sal);select @sal; case语句语法格式： 12345678910case 值 when 值1 then ...... when 值2 then ...... when 值3 then ...... else ......end case; 12345678910case when 条件1 then ...... when 条件2 then ...... when 条件3 then ...... else ......end case; 案例：根据不同月份，输出不同的季节。3 4 5月份春季。6 7 8月份夏季。9 10 11月份秋季。12 1 2 冬季。其他非法。 123456789101112131415161718create procedure mypro(in month int, out result varchar(100))begin case month when 3 then set result := &#x27;春季&#x27;; when 4 then set result := &#x27;春季&#x27;; when 5 then set result := &#x27;春季&#x27;; when 6 then set result := &#x27;夏季&#x27;; when 7 then set result := &#x27;夏季&#x27;; when 8 then set result := &#x27;夏季&#x27;; when 9 then set result := &#x27;秋季&#x27;; when 10 then set result := &#x27;秋季&#x27;; when 11 then set result := &#x27;秋季&#x27;; when 12 then set result := &#x27;冬季&#x27;; when 1 then set result := &#x27;冬季&#x27;; when 2 then set result := &#x27;冬季&#x27;; else set result := &#x27;非法月份&#x27;; end case;end; 123456789101112131415create procedure mypro(in month int, out result varchar(100))begin case when month = 3 or month = 4 or month = 5 then set result := &#x27;春季&#x27;; when month = 6 or month = 7 or month = 8 then set result := &#x27;夏季&#x27;; when month = 9 or month = 10 or month = 11 then set result := &#x27;秋季&#x27;; when month = 12 or month = 1 or month = 2 then set result := &#x27;冬季&#x27;; else set result := &#x27;非法月份&#x27;; end case;end; 12call mypro(9, @season);select @season; while循环语法格式： 123while 条件 do 循环体;end while; 案例：传入一个数字n，计算1~n中所有偶数的和。 1234567891011create procedure mypro(in n int)begin declare sum int default 0; while n &gt; 0 do if n % 2 = 0 then set sum := sum + n; end if; set n := n - 1; end while; select sum;end; 1call mypro(10); repeat循环语法格式： 1234repeat 循环体; until 条件end repeat; 注意：条件成立时结束循环。 案例：传入一个数字n，计算1~n中所有偶数的和。 1234567891011create procedure mypro(in n int, out sum int)begin set sum := 0; repeat if n % 2 = 0 then set sum := sum + n; end if; set n := n - 1; until n &lt;= 0 end repeat;end; 12call mypro(10, @sum);select @sum; loop循环语法格式： 1234567891011create procedure mypro()begin declare i int default 0; mylp:loop set i := i + 1; if i = 5 then leave mylp; end if; select i; end loop;end; 1234567891011121314create procedure mypro()begin declare i int default 0; mylp:loop set i := i + 1; if i = 5 then iterate mylp; end if; if i = 10 then leave mylp; end if; select i; end loop;end; 游标cursor游标（cursor）可以理解为一个指向结果集中某条记录的指针，允许程序逐一访问结果集中的每条记录，并对其进行逐行操作和处理。 使用游标时，需要在存储过程或函数中定义一个游标变量，并通过 DECLARE 语句进行声明和初始化。然后，使用 OPEN 语句打开游标，使用 FETCH 语句逐行获取游标指向的记录，并进行处理。最后，使用 CLOSE 语句关闭游标，释放相关资源。游标可以大大地提高数据库查询的灵活性和效率。 声明游标的语法： 1declare 游标名称 cursor for 查询语句; 打开游标的语法： 1open 游标名称; 通过游标取数据的语法： 1fetch 游标名称 into 变量[,变量,变量......] 关闭游标的语法： 1close 游标名称; 案例：从dept表查询部门编号和部门名，创建一张新表dept2，将查询结果插入到新表中。 1234567891011121314151617181920212223242526272829drop procedure if exists mypro;create procedure mypro()begin declare no int; declare name varchar(100); /* 声明游标 */ declare dept_cursor cursor for select deptno,dname from dept; drop table if exists dept2; create table dept2( no int primary key, name varchar(100) ); /* 打开游标 */ open dept_cursor; while true do /* 使用游标抓取内容到变量中 */ fetch dept_cursor into no, name; insert into dept2(no,name) values(no,name); end while; /* 关闭游标 */ close dept_cursor;end;call mypro(); 执行结果：出现了异常：异常信息中显示没有数据了。这是因为while true循环导致的。 不过虽然出现了异常，但是表创建成功了，数据也插入成功了：注意：声明局部变量和声明游标有顺序要求，局部变量的声明需要在游标声明之前完成。 捕捉异常并处理语法格式： 1DECLARE handler_name HANDLER FOR condition_value action_statement handler_name 表示异常处理程序的名称，重要取值包括： CONTINUE：发生异常后，程序不会终止，会正常执行后续的过程。(捕捉) EXIT：发生异常后，终止存储过程的执行。（上抛） condition_value 是指捕获的异常，重要取值包括： SQLSTATE sqlstate_value，例如：SQLSTATE ‘02000’ SQLWARNING，代表所有01开头的SQLSTATE NOT FOUND，代表所有02开头的SQLSTATE SQLEXCEPTION，代表除了01和02开头的所有SQLSTATE action_statement 是指异常发生时执行的语句，例如：CLOSE cursor_name 给之前的游标添加异常处理机制： 12345678910111213141516171819202122232425262728drop procedure if exists mypro;create procedure mypro()begin declare no int; declare name varchar(100); declare dept_cursor cursor for select deptno,dname from dept; declare exit handler for not found close dept_cursor; drop table if exists dept2; create table dept2( no int primary key, name varchar(100) ); open dept_cursor; while true do fetch dept_cursor into no, name; insert into dept2(no,name) values(no,name); end while; close dept_cursor;end;call mypro(); 存储函数存储函数：带返回值的存储过程。参数只允许是in（但不能写显示的写in）。没有out，也没有inout。语法格式： 12345CREATE FUNCTION 存储函数名称(参数列表) RETURNS 数据类型 [特征]BEGIN --函数体 RETURN ...;END; “特征”的可取重要值如下： deterministic：用该特征标记该函数为确定性函数（什么是确定性函数？每次调用函数时传同一个参数的时候，返回值都是固定的）。这是一种优化策略，这种情况下整个函数体的执行就会省略了，直接返回之前缓存的结果，来提高函数的执行效率。 no sql：用该特征标记该函数执行过程中不会查询数据库，如果确实没有查询语句建议使用。告诉 MySQL 优化器不需要考虑使用查询缓存和优化器缓存来优化这个函数，这样就可以避免不必要的查询消耗产生，从而提高性能。 reads sql data：用该特征标记该函数会进行查询操作，告诉 MySQL 优化器这个函数需要查询数据库的数据，可以使用查询缓存来缓存结果，从而提高查询性能；同时 MySQL 还会针对该函数的查询进行优化器缓存处理。 案例：计算1~n的所有偶数之和 1234567891011121314151617181920-- 删除函数drop function if exists sum_fun;-- 创建函数create function sum_fun(n int)returns int deterministic begin declare result int default 0; while n &gt; 0 do if n % 2 = 0 then set result := result + n; end if; set n := n - 1; end while; return result;end;-- 调用函数set @result = sum_fun(100);select @result; 触发器MySQL 触发器是一种数据库对象，它是与表相关联的特殊程序。它可以在特定的数据操作（例如插入（INSERT）、更新（UPDATE）或删除（DELETE））触发时自动执行。MySQL 触发器使数据库开发人员能够在数据的不同状态之间维护一致性和完整性，并且可以为特定的数据库表自动执行操作。 触发器的作用主要有以下几个方面： 强制实施业务规则：触发器可以帮助确保数据表中的业务规则得到强制执行，例如检查插入或更新的数据是否符合某些规则。 数据审计：触发器可以声明在执行数据修改时自动记日志或审计数据变化的操作，使数据对数据库管理员和 SQL 审计人员更易于追踪和审计。 执行特定业务操作：触发器可以自动执行特定的业务操作，例如计算数据行的总数、计算平均值或总和等。 MySQL 触发器分为两种类型: BEFORE 和 AFTER。BEFORE 触发器在执行 INSERT、UPDATE、DELETE 语句之前执行，而 AFTER 触发器在执行 INSERT、UPDATE、DELETE 语句之后执行。 创建触发器的语法如下： 12345CREATE TRIGGER trigger_nameBEFORE/AFTER INSERT/UPDATE/DELETE ON table_name FOR EACH ROWBEGIN-- 触发器执行的 SQL 语句END; 其中： trigger_name：触发器的名称 BEFORE&#x2F;AFTER：触发器的类型，可以是 BEFORE 或者 AFTER INSERT&#x2F;UPDATE&#x2F;DELETE：触发器所监控的 DML 调用类型 table_name：触发器所绑定的表名 FOR EACH ROW：表示触发器在每行受到 DML 的影响之后都会执行 触发器执行的 SQL 语句：该语句会在触发器被触发时执行 需要注意的是，触发器是一种高级的数据库功能，只有在必要的情况下才应该使用，例如在需要实施强制性业务规则时。过多的触发器和复杂的触发器逻辑可能会影响查询性能和扩展性。 关于触发器的NEW和OLD关键字：在 MySQL 触发器中，NEW 和 OLD 是两个特殊的关键字，用于引用在触发器中受到修改的行的新值和旧值。具体而言： NEW：在触发 INSERT 或 UPDATE 操作期间，NEW 用于引用将要插入或更新到表中的新行的值。 OLD：在触发 UPDATE 或 DELETE 操作期间，OLD 用于引用更新或删除之前在表中的旧行的值。 通俗的讲，NEW 是指触发器执行的操作所要插入或更新到当前行中的新数据；而 OLD 则是指当前行在触发器执行前原本的数据。 在MySQL 触发器中，NEW 和 OLD 使用方法是相似的。在触发器中，可以像引用表的其他列一样引用 NEW 和 OLD。例如，可以使用 OLD.column_name 从旧行中引用列值，也可以使用 NEW.column_name 从新行中引用列值。 示例： 假设有一个名为 my_table 的表，其中包含一个名为 quantity 的列。当在该表上执行 UPDATE 操作时，以下触发器会将旧值 OLD.quantity 累加到新值 NEW.quantity 中： 123456CREATE TRIGGER my_triggerBEFORE UPDATE ON my_tableFOR EACH ROWBEGINSET NEW.quantity = NEW.quantity + OLD.quantity;END; 在此触发器中，OLD.quantity 引用原始行的 quantity 值（旧值），而 NEW.quantity 引用更新行的 quantity 值（新值）。在触发器执行期间，数据行的 quantity 值将设置为旧值加上新值。 需要注意的是，在使用 NEW 和 OLD 时，需要根据 DML 操作的类型进行判断，以确定哪个关键字表示新值，哪个关键字则表示旧值。 案例：当我们对dept表中的数据进行insert delete update的时候，请将这些操作记录到日志表当中，日志表如下： 12345678910drop table if exists oper_log;create table oper_log( id bigint primary key auto_increment, table_name varchar(100) not null comment &#x27;操作的哪张表&#x27;, oper_type varchar(100) not null comment &#x27;操作类型包括insert delete update&#x27;, oper_time datetime not null comment &#x27;操作时间&#x27;, oper_id bigint not null comment &#x27;操作的那行记录的id&#x27;, oper_desc text comment &#x27;操作描述&#x27;); 触发器1：向dept表中插入数据时，记录日志 1234567create trigger dept_trigger_insert after insert on deptfor each rowbegin insert into oper_log(id,table_name,oper_type,oper_time,oper_id,oper_desc) values(null,&#x27;dept&#x27;,&#x27;insert&#x27;,now(),new.deptno,concat(&#x27;插入数据：deptno=&#x27;, new.deptno, &#x27;,dname=&#x27;, new.dname,&#x27;,loc=&#x27;, new.loc));end; 查看触发器： 1show triggers; 删除触发器： 1drop trigger if exists dept_trigger_insert; 向dept表中插入一条记录：日志表中多了一条记录： 触发器2：修改dept表中数据时，记录日志 12345678create trigger dept_trigger_updateafter update on deptfor each rowbegin insert into oper_log(id,table_name,oper_type,oper_time,oper_id,oper_desc) values(null,&#x27;dept&#x27;,&#x27;update&#x27;,now(),new.deptno,concat(&#x27;更新前：deptno=&#x27;, old.deptno, &#x27;,dname=&#x27;, old.dname,&#x27;,loc=&#x27;, old.loc, &#x27;,更新后：deptno=&#x27;, new.deptno, &#x27;,dname=&#x27;, new.dname,&#x27;,loc=&#x27;, new.loc));end; 更新一条记录： 1update dept set loc = &#x27;北京&#x27; where deptno = 60; 日志表中多了一条记录：注意：更新一条记录则对应一条日志。如果一次更新3条记录，那么日志表中插入3条记录。 触发器3：删除dept表中数据时，记录日志 1234567create trigger dept_trigger_deleteafter delete on deptfor each rowbegin insert into oper_log(id,table_name,oper_type,oper_time,oper_id,oper_desc) values(null,&#x27;dept&#x27;,&#x27;delete&#x27;,now(),old.deptno,concat(&#x27;删除了数据：deptno=&#x27;, old.deptno, &#x27;,dname=&#x27;, old.dname,&#x27;,loc=&#x27;, old.loc));end; 删除一条记录： 1delete from dept where deptno = 60; 日志表中多了一条记录： 存储引擎概述MySQL存储引擎决定了数据在磁盘上的存储方式和访问方式。不同的存储引擎实现了不同的存储和检索算法，因此它们在处理和管理数据的方式上存在差异。 MySQL常见的存储引擎包括InnoDB、MyISAM、Memory、Archive等。每个存储引擎都有自己的特点和适用场景。 例如， InnoDB引擎支持事务和行级锁定，适用于需要高并发读写的应用； MyISAM引擎不支持事务，但适用于读操作较多的应用； Memory引擎数据全部存储在内存中，适用于对读写速度要求很高的应用等等。 选择适合的存储引擎可以提高MySQL的性能和效率，并且根据应用需求来合理选择存储引擎可以提供更好的数据管理和查询功能。 MySQL支持哪些存储引擎使用show engines \\G;命令可以查看所有的存储引擎： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677*************************** 1. row *************************** Engine: MEMORY Support: YES Comment: Hash based, stored in memory, useful for temporary tablesTransactions: NO XA: NO Savepoints: NO*************************** 2. row *************************** Engine: MRG_MYISAM Support: YES Comment: Collection of identical MyISAM tablesTransactions: NO XA: NO Savepoints: NO*************************** 3. row *************************** Engine: CSV Support: YES Comment: CSV storage engineTransactions: NO XA: NO Savepoints: NO*************************** 4. row *************************** Engine: FEDERATED Support: NO Comment: Federated MySQL storage engineTransactions: NULL XA: NULL Savepoints: NULL*************************** 5. row *************************** Engine: PERFORMANCE_SCHEMA Support: YES Comment: Performance SchemaTransactions: NO XA: NO Savepoints: NO*************************** 6. row *************************** Engine: MyISAM Support: YES Comment: MyISAM storage engineTransactions: NO XA: NO Savepoints: NO*************************** 7. row *************************** Engine: InnoDB Support: DEFAULT Comment: Supports transactions, row-level locking, and foreign keysTransactions: YES XA: YES Savepoints: YES*************************** 8. row *************************** Engine: ndbinfo Support: NO Comment: MySQL Cluster system information storage engineTransactions: NULL XA: NULL Savepoints: NULL*************************** 9. row *************************** Engine: BLACKHOLE Support: YES Comment: /dev/null storage engine (anything you write to it disappears)Transactions: NO XA: NO Savepoints: NO*************************** 10. row *************************** Engine: ARCHIVE Support: YES Comment: Archive storage engineTransactions: NO XA: NO Savepoints: NO*************************** 11. row *************************** Engine: ndbcluster Support: NO Comment: Clustered, fault-tolerant tablesTransactions: NULL XA: NULL Savepoints: NULL Support是Yes的表示支持该存储引擎。当前MySQL的版本是8.0.33MySQL默认的存储引擎是：InnoDB 指定和修改存储引擎指定存储引擎在MySQL中，你可以在创建表时指定使用的存储引擎。通过在CREATE TABLE语句中使用ENGINE关键字，你可以指定要使用的存储引擎。 以下是指定存储引擎的示例： 1CREATE TABLE my_table (column1 INT, column2 VARCHAR(50)) ENGINE = InnoDB; 在这个例子中，我们创建了一个名为my_table的表，并指定了使用InnoDB存储引擎。 如果你不显式指定存储引擎，MySQL将使用默认的存储引擎。默认情况下，MySQL 8的默认存储引擎是InnoDB。 修改存储引擎在MySQL中，你可以通过ALTER TABLE语句修改表的存储引擎。下面是修改存储引擎的示例： 1ALTER TABLE my_table ENGINE = MyISAM; 在这个例子中，我们使用ALTER TABLE语句将my_table表的存储引擎修改为MyISAM。 请注意，在修改存储引擎之前，你需要考虑以下几点： 修改存储引擎可能需要执行复制表的操作，因此可能会造成数据的丢失或不可用。确保在执行修改之前备份你的数据。 不是所有的存储引擎都支持相同的功能。要确保你选择的新存储引擎支持你应用程序所需的功能。 修改表的存储引擎可能会影响到现有的应用程序和查询。确保在修改之前评估和测试所有的影响。 ALTER TABLE语句可能需要适当的权限才能执行。确保你拥有足够的权限来执行修改存储引擎的操作。 总而言之，修改存储引擎需要谨慎进行，且需要考虑到可能的影响和风险。建议在进行修改之前进行适当的测试和备份。 常用的存储引擎及适用场景在实际开发中，以下存储引擎是比较常用的： InnoDB： MySQL默认的事务型存储引擎 支持ACID事务 具有较好的并发性能和数据完整性 支持行级锁定。 适用于大多数应用场景，尤其是需要事务支持的应用。 MyISAM： 是MySQL早期版本中常用的存储引擎 支持全文索引和表级锁定 不支持事务 由于其简单性和高性能，在某些特定的应用场景中会得到广泛应用，如读密集的应用。 MEMORY： 称为HEAP，是将表存储在内存中的存储引擎 具有非常高的读写性能，但数据会在服务器重启时丢失。 适用于需要快速读写的临时数据集、缓存和临时表等场景。 CSV： 将数据以纯文本格式存储的存储引擎 适用于需要处理和导入&#x2F;导出CSV格式数据的场景。 ARCHIVE： 将数据高效地进行压缩和存储的存储引擎 适用于需要长期存储大量历史数据且不经常查询的场景。 索引什么是索引索引是一种能够提高检索（查询）效率的提前排好序的数据结构。例如：书的目录就是一种索引机制。索引是解决SQL慢查询的一种方式。 索引的创建和删除主键会自动添加索引主键字段会自动添加索引，不需要程序员干涉，主键字段上的索引被称为主键索引 unique约束的字段自动添加索引unique约束的字段也会自动添加索引，不需要程序员干涉，这种字段上添加的索引称为唯一索引 给指定的字段添加索引建表时添加索引： 1234567CREATE TABLE emp ( ... name varchar(255), ... INDEX idx_name (name)); 如果表已经创建好了，后期给字段添加索引 1ALTER TABLE emp ADD INDEX idx_name (name); 也可以这样添加索引： 1create index idx_name on emp(name); 删除指定字段上的索引1ALTER TABLE emp DROP INDEX idx_name; 查看某张表上添加了哪些索引1show index from 表名; 索引的分类不同的存储引擎有不同的索引类型和实现： 按照数据结构分类： B+树 索引（mysql的InnoDB存储引擎采用的就是这种索引）采用 B+树 的数据结构 Hash 索引（仅 memory 存储引擎支持）：采用 哈希表 的数据结构 按照物理存储分类： 聚集索引：索引和表中数据在一起，数据存储的时候就是按照索引顺序存储的。一张表只能有一个聚集索引。 非聚集索引：索引和表中数据是分开的，索引是独立于表空间的，一张表可以有多个非聚集索引。 按照字段特性分类： 主键索引（primary key） 唯一索引（unique） 普通索引（index） 全文索引（fulltext：仅 InnoDB和MyISAM 存储引擎支持） 按照字段个数分类： 单列索引、联合索引（也叫复合索引、组合索引） MySQL索引采用了B+树数据结构常见的树相关的数据结构包括： 二叉树 红黑树 B树 B+树 区别：树的高度不同。树的高度越低，性能越高。这是因为每一个节点都是一次I&#x2F;O 二叉树有这样一张表如果不给id字段添加索引，默认进行全表扫描，假设查询id&#x3D;10的数据，那至少要进行10次磁盘IO。效率低。可以给id字段添加索引，假设该索引使用了二叉树这种数据结构，这个二叉树是这样的（推荐一个数据结构可视化网站Data Structure Visualizations，是旧金山大学（USFCA）的一个网站）：https://www.cs.usfca.edu/~galles&#x2F;visualization&#x2F;Algorithms.html 如果这个时候要找id&#x3D;10的数据，需要的IO次数是？4次。效率显著提升了。但是MySQL并没有直接使用这种普通的二叉树，这种普通二叉树在数据极端的情况下，效率较低。比如下面的数据：如果给id字段添加索引，并且该索引底层使用了普通二叉树，这棵树会是这样的：你虽然使用了二叉树，但这更像一个链表。查找效率等同于链表查询O(n)【查找算法的时间复杂度是线性的】。查找效率极低。因此对于MySQL来说，它并没有选择这种数据结构作为索引。 红黑树（自平衡二叉树）通过自旋平衡规则进行旋转，子节点会自动分叉为2个分支，从而减少树的高度，当数据有序插入时比二叉树数据检索性能更好。例如有以下数据给id字段添加索引，并且该索引使用了红黑树数据结构，那么会是这样：如果查找id&#x3D;10的数据，磁盘IO次数为：5次。效率比普通二叉树要高一些。 但是如果数据量庞大，例如500万条数据，也会导致树的高度很高，磁盘IO次数仍然很多，查询效率也会比较低。 因此MySQL并没有使用红黑树这种数据结构作为索引。 B Trees（B树）B Trees首先是一个自平衡的。B Trees每个节点下的子节点数量 &gt; 2。B Trees每个节点中也不是存储单个数据，可以存储多个数据。B Trees又称为平衡多路查找树。 B Trees分支的数量不是2，是大于2，具体是多少个分支，由阶决定。例如： 3阶的B Trees，一个节点下最多有3个子节点，每个节点中最多有2个数据。 4阶的B Trees，一个节点下最多有4个子节点，每个节点中最多有3个数据。 5阶（5, 4） 6阶（6, 5） …. 16阶（16, 15）【MySQL采用了16阶】 采用B Trees，你会发现相同的数据量，B Tree 树的高度更低。磁盘IO次数更少。3阶的B Trees：假设id字段添加了索引，并且采用了B Trees数据结构，查找id&#x3D;10的数据，只需要3次磁盘IO。4阶的B Trees： 更加详细的存储是这样的，请看下图：在B Trees中，每个节点不仅存储了索引值，还存储该索引值对应的数据行。并且每个节点中的p1 p2 p3是指向下一个节点的指针。 B Trees数据结构存在的缺点是：不适合做区间查找，对于区间查找效率较低。假设要查id在[3~7]之间的，需要查找的是3,4,5,6,7。那么查这每个索引值都需要从头节点开始。因此MySQL使用了B+ Trees解决了这个问题。 B+ Trees（B+ 树）B+ Trees 相较于 B Trees改进了哪些？ B+树将数据都存储在叶子节点中。并且叶子节点之间使用链表连接，这样很适合范围查询。 B+树的非叶子节点上只有索引值，没有数据，所以非叶子节点可以存储更多的索引值，这样让B+树更矮更胖，提高检索效率。 假设有这样一张表：B+ Trees方式存储的话如下图所示： 经典面试题：mysql为什么选择B+树作为索引的数据结构，而不是B树？ 非叶子节点上可以存储更多的键值，阶数可以更大，更矮更胖，磁盘IO次数少，数据查询效率高。 所有数据都是有序存储在叶子节点上，让范围查找，分组查找效率更高。 数据页之间、数据记录之间采用链表链接，让升序降序更加方便操作。 经典面试题：如果一张表没有主键索引，那还会创建B+树吗？当一张表没有主键索引时，默认会使用一个隐藏的内置的聚集索引（clustered index）。这个聚集索引是基于表的物理存储顺序构建的，通常是使用B+树来实现的。 其他索引及相关调优Hash索引支持Hash索引的存储引擎有： InnoDB（不支持手动创建Hash索引，系统会自动维护一个自适应的Hash索引） 对于InnoDB来说，即使手动指定了某字段采用Hash索引，最终show index from 表名的时候，还是BTREE。 Memory（支持Hash索引） Hash索引底层的数据结构就是哈希表。一个数组，数组中每个元素是链表。和java中HashMap一样。哈希表中每个元素都是key value结构。key存储索引值，value存储行指针。 原理如下：如果name字段上添加了Hash索引idx_name Hash索引长这个样子： 检索原理：假设 name&#x3D;’孙行者’。通过哈希算法将’孙行者’转换为数组下标，通过下标找链表，在链表上遍历找到孙行者的行指针。 注意：不同的字符串，经过哈希算法得到的数组下标可能相同，这叫做哈希碰撞&#x2F;哈希冲突。【不过，好的哈希算法应该具有很低的碰撞概率。常用的哈希算法如MD5、SHA-1、SHA-256等都被设计为尽可能减少碰撞的发生。】 Hash索引优缺点： 优点：只能用在等值比较中，效率很高。例如：name&#x3D;’孙悟空’ 缺点：不支持排序，不支持范围查找。 聚集索引和非聚集索引按照数据的物理存储方式不同，可以将索引分为聚集索引（聚簇索引）和非聚集索引（非聚簇索引）。 存储引擎是InnoDB的，主键上的索引属于聚集索引。存储引擎是MyISAM的，任意字段上的索引都是非聚集索引。 InnoDB的物理存储方式：当创建一张表t_user，并使用InnoDB存储引擎时，会在硬盘上生成这样一个文件： t_user.ibd （InnoDB data表索引 + 数据） t_user.frm （存储表结构信息） MyISAM的物理存储方式：当创建一张表t_user，并使用MyISAM存储引擎时，会在硬盘上生成这样一个文件： t_user.MYD （表数据） t_user.MYI （表索引） t_user.frm （表结构） 注意：从MySQL8.0开始，不再生成frm文件了，引入了数据字典，用数据字典来统一存储表结构信息，例如： information_schema.TABLES （表包含了数据库中所有表的信息，例如表名、数据库名、引擎类型等） information_schema.COLUMNS（表包含了数据库中所有表的列信息，例如列名、数据类型、默认值等） 聚集索引的原理图：（B+树，叶子节点上存储了索引值 + 数据） 非聚集索引的原理图：（B+树，叶子节点上存储了索引值 + 行指针） 聚集索引的优点和缺点： 优点：聚集索引将数据存储在索引树的叶子节点上。可以减少一次查询，因为查询索引树的同时可以获取数据。 缺点：对数据进行修改或删除时需要更新索引树，会增加系统的开销。 二级索引二级索引也属于非聚集索引。也有人把二级索引称为辅助索引。有表t_user，id是主键。age是非主键。在age字段上添加的索引称为二级索引。（所有非主键索引都是二级索引） 二级索引的数据结构： 二级索引的查询原理：假设查询语句为： 1select * from t_user where age = 30; 为什么会“回表”？因为使用了select *避免“回表【回到原数据表】”是提高SQL执行效率的手段。例如：select id from t_user where age &#x3D; 30; 这样的SQL语句是不需要回表的。 覆盖索引覆盖索引（Covering Index），顾名思义，是指某个查询语句可以通过索引的覆盖来完成，而不需要回表查询真实数据。其中的覆盖指的是在执行查询语句时，查询需要的所有列都可以从索引中提取到，而不需要再去查询实际数据行获取查询所需数据。当使用覆盖索引时，MySQL可以直接通过索引，也就是索引上的数据来获取所需的结果，而不必再去查找表中的数据。这样可以显著提高查询性能。 假设有一个用户表（user）包含以下列：id, username, email, age。 常见的查询是根据用户名查询用户的邮箱。如果为了提高这个查询的性能，可以创建一个覆盖索引，包含（username, email）这两列。 创建覆盖索引的SQL语句可以如下： 1CREATE INDEX idx_user_username_email ON user (username, email); 当执行以下查询时： 1SELECT email FROM user WHERE username = &#x27;lucy&#x27;; MySQL可以直接使用覆盖索引（idx_user_username_email）来获取查询结果，而不必再去查找用户表中的数据。这样可以减少磁盘I&#x2F;O并提高查询效率。而如果没有覆盖索引，MySQL会先使用索引（username）来找到匹配的行，然后再回表查询获取邮箱，这个过程会增加更多的磁盘I&#x2F;O和查询时间。 值得注意的是，覆盖索引的创建需要考虑查询的字段选择。如果查询需要的字段较多，可能需要创建包含更多列的覆盖索引，以满足完全覆盖查询的需要。 覆盖索引具有以下优点： 提高查询性能：覆盖索引能够满足查询的所有需求，同时不需要访问表中的实际数据行，从而可以提高查询性能。这是因为DBMS可以直接使用索引来执行查询，而不需要从磁盘读取实际的数据行。 减少磁盘和内存访问次数：当使用覆盖索引时，DBMS不需要访问实际的数据行。这样可以减少磁盘和内存访问次数，从而提高查询性能。 减少网络传输：由于在覆盖索引中可以存储所有查询所需的列，因此可以减少数据的网络传输次数，从而提高查询的性能。 可以降低系统开销：在高压力的数据库系统中，使用覆盖索引可以减少系统开销，从而提高系统的可靠性和可维护性。 覆盖索引的缺点包括： 需要更多的内存：覆盖索引需要存储查询所需的所有列，因此需要更多的内存来存储索引。在大型数据库系统中，这可能会成为一项挑战。 会使索引变得庞大：当索引中包含了许多列时，它们可能会使索引变得非常庞大，从而影响查询性能，并且可能会占用大量的磁盘空间。 只有在查询中包含了索引列时才能使用：只有当查询中包含了所有的索引列时才能使用覆盖索引。如果查询中包含了其他列，DBMS仍然需要访问实际的数据行，并且无法使用覆盖索引提高查询性能。 索引下推索引下推（Index Condition Pushdown）是一种 MySQL 中的优化方法，它可以将查询中的过滤条件下推到索引层级中处理，从而减少回表次数，优化查询性能。 具体来说，在使用索引下推时，MySQL 会在索引的叶节点层级执行查询的过滤条件，过滤掉无用的索引记录，仅返回符合条件的记录的主键，这样就可以避免查询时回表读取表格的数据行，从而缩短了整个查询过程的时间。 假设有以下表结构： 表名：users id name age city 1 John 25 New York 2 Alice 30 London 3 Bob 40 Paris 4 Olivia 35 Berlin 5 Michael 28 Sydney 现在我们创建了一个多列索引：（索引下推通常是基于多列索引的。） 1ALTER TABLE users ADD INDEX idx_name_city_age (name, city, age); 假设我们要查询年龄大于30岁，并且所在城市是”London”的用户，假设只给age字段添加了索引，它就不会使用索引下推。传统的查询优化器会将所有满足年龄大于30岁的记录读入内存，然后再根据城市进行筛选。 使用索引下推优化后，在索引范围扫描的过程中，优化器会判断只有在城市列为”London”的情况下，才会将满足年龄大于30岁的记录加载到内存中。这样就可以避免不必要的IO和数据传输，提高查询性能。 具体的查询语句可以是： 1SELECT * FROM users WHERE age &gt; 30 AND city = &#x27;London&#x27;; 在执行这个查询时，优化器会使用索引下推技术，先根据索引范围扫描找到所有满足条件的记录，然后再回到原数据表中获取完整的行数据，最终返回结果。 单列索引（单一索引）单列索引是指对数据库表中的某一列或属性进行索引创建，对该列进行快速查找和排序操作。单列索引可以加快查询速度，提高数据库的性能。 举个例子，假设我们有一个学生表（student），其中有以下几个列：学生编号（student_id）、姓名（name）、年龄（age）和性别（gender）。 如果我们针对学生表的学生编号（student_id）列创建了单列索引，那么可以快速地根据学生编号进行查询或排序操作。例如，我们可以使用以下SQL语句查询学生编号为123456的学生信息： 1SELECT * FROM student WHERE student_id = 123456; 由于我们对学生编号列建立了单列索引，所以数据库可以直接通过索引快速定位到具有学生编号123456的那一行记录，从而加快查询速度。 复合索引（组合索引）复合索引（Compound Index）也称为多列索引（Multi-Column Index），是指对数据库表中多个列进行索引创建。 与单列索引不同，复合索引可以包含多个列。这样可以将多个列的值组合起来作为索引的键，以提高多列条件查询的效率。 举个例子，假设我们有一个订单表（Order），其中包含以下几个列：订单编号（OrderID）、客户编号（CustomerID）、订单日期（OrderDate）和订单金额（OrderAmount）。 如果我们为订单表的客户编号和订单日期这两列创建复合索引（CustomerID, OrderDate），那么可以在查询时同时根据客户编号和订单日期来快速定位到匹配的记录。 例如，我们可以使用以下SQL语句查询客户编号为123456且订单日期为2021-01-01的订单信息： 1SELECT * FROM Order WHERE CustomerID = 123456 AND OrderDate = &#x27;2021-01-01&#x27;; 由于我们为客户编号和订单日期创建了复合索引，数据库可以使用这个索引来快速定位到符合条件的记录，从而加快查询速度。复合索引的使用能够提高多列条件查询的效率，但需要注意的是，复合索引的创建和维护可能会增加索引的存储空间和对于写操作的影响。 相对于单列索引，复合索引有以下几个优势： 减少索引的数量：复合索引可以包含多个列，因此可以减少索引的数量，减少索引的存储空间和维护成本。 提高查询性能：当查询条件中涉及到复合索引的多个列时，数据库可以使用复合索引进行快速定位和过滤，从而提高查询性能。 覆盖查询：如果复合索引包含了所有查询需要的列，那么数据库可以直接使用索引中的数据，而不需要再进行表的读取，从而提高查询性能。 排序和分组：由于复合索引包含多个列，因此可以用于排序和分组操作，从而提高排序和分组的性能。 索引的优缺点索引是数据库中一种重要的数据结构，用于加速数据的检索和查询操作。它的优点和缺点如下： 优点： 提高查询性能：通过创建索引，可以大大减少数据库查询的数据量，从而提升查询的速度。 加速排序：当查询需要按照某个字段进行排序时，索引可以加速排序的过程，提高排序的效率。 减少磁盘IO：索引可以减少磁盘IO的次数，这对于磁盘读写速度较低的场景，尤其重要。 缺点： 占据额外的存储空间：索引需要占据额外的存储空间，特别是在大型数据库系统中，索引可能占据较大的空间。 增删改操作的性能损耗：每次对数据表进行插入、更新、删除等操作时，需要更新索引，会导致操作的性能降低。 资源消耗较大：索引需要占用内存和CPU资源，特别是在大规模并发访问的情况下，可能对系统的性能产生影响。 何时用索引在以下情况下建议使用索引： 频繁执行查询操作的字段：如果这些字段经常被查询，使用索引可以提高查询的性能，减少查询的时间。 大表：当表的数据量较大时，使用索引可以快速定位到所需的数据，提高查询效率。 需要排序或者分组的字段：在对字段进行排序或者分组操作时，索引可以减少排序或者分组的时间。 外键关联的字段：在进行表之间的关联查询时，使用索引可以加快关联查询的速度。 在以下情况下不建议使用索引： 频繁执行更新操作的表：如果表经常被更新数据，使用索引可能会降低更新操作的性能，因为每次更新都需要维护索引。 小表：对于数据量较小的表，使用索引可能并不会带来明显的性能提升，反而会占用额外的存储空间。 对于唯一性很差的字段，一般不建议添加索引。当一个字段的唯一性很差时，查询操作基本上需要扫描整个表的大部分数据。如果为这样的字段创建索引，索引的大小可能会比数据本身还大，导致索引的存储空间占用过高，同时也会导致查询操作的性能下降。 总之，索引需要根据具体情况进行使用和权衡，需要考虑到表的大小、查询频率、更新频率以及业务需求等因素。 MySQL优化MySQL优化手段MySQL数据库的优化手段通常包括但不限于： SQL查询优化：这是最低成本的优化手段，通过优化查询语句、适当添加索引等方式进行。并且效果显著。 库表结构优化：通过规范化设计、优化索引和数据类型等方式进行库表结构优化，需要对数据库结构进行调整和改进 系统配置优化：根据硬件和操作系统的特点，调整最大连接数、内存管理、IO调度等参数 硬件优化：升级硬盘、增加内存容量、升级处理器等硬件方面的投入，需要购买和替换硬件设备，成本较高 我们主要掌握：SQL查询优化 SQL性能分析工具查看数据库整体情况通过以下命令可以查看当前数据库在SQL语句执行方面的整体情况： 123456show global status like &#x27;Com_select&#x27;;show global status like &#x27;Com_insert&#x27;;show global status like &#x27;Com_delete&#x27;;show global status like &#x27;Com_update&#x27;;show global status like &#x27;Com_______&#x27;; 这些结果反映了从 MySQL 服务器启动到当前时刻，所有的 SELECT 查询总数。对于 MySQL 性能优化来说，通过查看 Com_select 的值可以了解 SELECT 查询在整个 MySQL 服务期间所占比例的情况： 如果 Com_select 次数过高，可能说明查询表中的每条记录都会返回过多的字段。 如果 Com_select 次数很少，同时insert或delete或update的次数很高，可能说明服务器运行的应用程序过于依赖写入操作和少量读取操作。 总之，通过查看 Com_select 的值，可以了解 MySQL 服务器的长期执行情况，并在优化查询性能时，帮助我们了解 MySQL 的性能瓶颈。 慢查询日志慢查询日志文件可以将查询较慢的DQL语句记录下来，便于我们定位需要调优的select语句。通过以下命令查看慢查询日志功能是否开启： 1show variables like &#x27;slow_query_log&#x27;; 慢查询日志功能默认是关闭的。请修改my.ini文件来开启慢查询日志功能，在my.ini的[mysqld]后面添加如下配置：注意：slow_query_log&#x3D;1表示开启慢查询日志功能，long_query_time&#x3D;3表示：只要SELECT语句的执行耗时超过3秒则将其记录到慢查询日志中。重启mysql服务。再次查看是否开启慢查询日志功能： 尝试执行一条时长超过3秒的select语句： 1select empno,ename,sleep(4) from emp where ename=&#x27;smith&#x27;; 慢查询日志文件默认存储在：C:\\dev\\mysql-8.0.36-winx64\\data 目录下，默认的名字是：计算机名-slow.log通过该文件可以清晰的看到哪些DQL语句属于慢查询： show profiles通过show profiles可以查看一个SQL语句在执行过程中具体的耗时情况。帮助我们更好的定位问题所在。 查看当前数据库是否支持 profile操作： 1select @@have_profiling; 查看 profiling 开关是否打开： 1select @@profiling; 将 profiling 开关打开： 1set profiling = 1; 可以执行多条DQL语句，然后使用 show profiles; 来查看当前数据库中执行过的每个SELECT语句的耗时情况。 1234select empno,ename from emp;select empno,ename from emp where empno=7369;select count(*) from emp;show profiles; 查看某个SQL语句语句在执行过程中，每个阶段的耗时情况： 1show profile for query 4; 想查看执行过程中cpu的情况，可以执行以下命令： 1show profile cpu for query 4; explainexplain命令可以查看一个DQL语句的执行计划，根据执行计划可以做出相应的优化措施。提高执行效率。 1explain select * from emp where empno=7369; idid反映出一条select语句执行顺序，id越大优先级越高。id相同则按照自上而下的顺序执行。 1explain select e.ename,d.dname from emp e join dept d on e.deptno=d.deptno join salgrade s on e.sal between s.losal and s.hisal; 由于id相同，反映出三张表在执行顺序上属于平等关系，执行时采用，先d，再e，最后s。 1explain select e.ename,d.dname from emp e join dept d on e.deptno=d.deptno where e.sal=(select sal from emp where ename=&#x27;ford&#x27;); 反映出，先执行子查询，然后让e和d做表连接。 select_type反映了mysql查询语句的类型。常用值包括： SIMPLE：表示查询中不包含子查询或UNION操作。这种查询通常包括一个表或是最多一个联接（JOIN） PRIMARY：表示当前查询是一个主查询。（主要的查询） UNION：表示查询中包含UNION操作 SUBQUERY：子查询 DERIVED：派生表（表示查询语句出现在from后面） table反映了这个查询操作的是哪个表。 type反映了查询表中数据时的访问类型，常见的值： NULL：效率最高，一般不可能优化到这个级别，只有查询时没有查询表的时候，访问类型是NULL。例如：select 1; system：通常访问系统表的时候，访问类型是system。一般也很难优化到这个程序。 const：根据主键或者唯一性索引查询，索引值是常量值时。explain select * from emp where empno&#x3D;7369; eq_ref：根据主键或者唯一性索引查询。索引值不是常量值。 ref：使用了非唯一的索引进行查询。 range：使用了索引，扫描了索引树的一部分。 index：表示用了索引，但是也需要遍历整个索引树。 all：全表扫描 效率最高的是NULL，效率最低的是all，从上到下，从高到低。 possible_keys这个查询可能会用到的索引 key实际用到的索引 key_len反映索引中在查询中使用的列所占的总字节数。 rows查询扫描的预估计行数。 Extra给出了与查询相关的额外信息和说明。这些额外信息可以帮助我们更好地理解查询执行的过程。 索引优化加索引 vs 不加索引将这个sql脚本初始化到数据库中（初始化100W条记录）：t_vip.sql根据id查询（id是主键，有索引）： 1select * from t_vip where id = 900000; 根据name查询（name上没有索引）： 1select * from t_vip where name=&#x27;4c6494cb&#x27;; 给name字段添加索引： 1create index idx_t_user_name on t_vip(name); 再次根据name查询（此时name上已经有索引了） ： 1select * from t_vip where name=&#x27;4c6494cb&#x27;; 最左前缀原则假设有这样一张表： 1234567create table t_customer( id int primary key auto_increment, name varchar(255), age int, gender char(1), email varchar(255)); 添加了这些数据： 12345insert into t_customer values(null, &#x27;zhangsan&#x27;, 20, &#x27;M&#x27;, &#x27;zhangsan@123.com&#x27;);insert into t_customer values(null, &#x27;lisi&#x27;, 22, &#x27;M&#x27;, &#x27;lisi@123.com&#x27;);insert into t_customer values(null, &#x27;wangwu&#x27;, 18, &#x27;F&#x27;, &#x27;wangwu@123.com&#x27;);insert into t_customer values(null, &#x27;zhaoliu&#x27;, 22, &#x27;F&#x27;, &#x27;zhaoliu@123.com&#x27;);insert into t_customer values(null, &#x27;jack&#x27;, 30, &#x27;M&#x27;, &#x27;jack@123.com&#x27;); 添加了这样的复合索引： 1create index idx_name_age_gender on t_customer(name,age,gender); 最左前缀原则：当查询语句条件中包含了这个复合索引最左边的列 name 时，此时索引才会起作用。 验证1： 1explain select * from t_customer where name=&#x27;zhangsan&#x27; and age=20 and gender=&#x27;M&#x27;; 验证结果：完全使用了索引 验证2： 1explain select * from t_customer where name=&#x27;zhangsan&#x27; and age=20; 验证结果：使用了部分索引 验证3： 1explain select * from t_customer where name=&#x27;zhangsan&#x27;; 验证结果：使用了部分索引 验证4： 1explain select * from t_customer where age=20 and gender=&#x27;M&#x27; and name=&#x27;zhangsan&#x27;; 验证结果：完全使用了索引 验证5： 1explain select * from t_customer where gender=&#x27;M&#x27; and age=20; 验证结果：没有使用任何索引 验证6： 1explain select * from t_customer where name=&#x27;zhangsan&#x27; and gender=&#x27;M&#x27;; 验证结果：使用了部分索引 验证7： 1explain select * from t_customer where name=&#x27;zhangsan&#x27; and gender=&#x27;M&#x27; and age=20; 验证结果：完全使用了索引 范围查询时，在“范围条件”右侧的列索引会失效：验证： 1explain select * from t_customer where name=&#x27;zhangsan&#x27; and age&gt;20 and gender=&#x27;M&#x27;; 验证结果：name和age列索引生效。gender列索引无效。怎么解决？建议范围查找时带上“&#x3D;” 1explain select * from t_customer where name=&#x27;zhangsan&#x27; and age&gt;=20 and gender=&#x27;M&#x27;; 索引失效情况有这样一张表： 123456create table t_emp( id int primary key auto_increment, name varchar(255), sal int, age char(2)); 有这样一些数据： 123insert into t_emp values(null, &#x27;张三&#x27;, 5000,&#x27;20&#x27;);insert into t_emp values(null, &#x27;张飞&#x27;, 4000,&#x27;30&#x27;);insert into t_emp values(null, &#x27;李飞&#x27;, 6000,&#x27;40&#x27;); 有这样一些索引： 123create index idx_t_emp_name on t_emp(name);create index idx_t_emp_sal on t_emp(sal);create index idx_t_emp_age on t_emp(age); 索引列参加了运算，索引失效1explain select * from t_emp where sal &gt; 5000; 验证结果：使用了索引 1explain select * from t_emp where sal*10 &gt; 50000; 验证结果：索引失效 索引列进行模糊查询时以 % 开始的，索引失效1explain select * from t_emp where name like &#x27;张%&#x27;; 验证结果：索引有效 1explain select * from t_emp where name like &#x27;%飞&#x27;; 验证结果：索引失效 索引列是字符串类型，但查询时省略了单引号，索引失效1explain select * from t_emp where age=&#x27;20&#x27;; 验证结果：索引有效 1explain select * from t_emp where age=20; 验证结果：索引失效 查询条件中有or，只要有未添加索引的字段，索引失效1explain select * from t_emp where name=&#x27;张三&#x27; or sal=5000; 验证结果：使用了索引 将t_emp表sal字段上的索引删除： 1alter table t_emp drop index idx_t_emp_sal; 再次验证： 1explain select * from t_emp where name=&#x27;张三&#x27; or sal=5000; 验证结果：索引失效 当查询的符合条件的记录在表中占比较大，索引失效复制一张新表：emp2 1create table emp2 as select * from emp; 给sal添加索引： 1alter table emp2 add index idx_emp2_sal(sal); 验证1： 1explain select * from emp2 where sal &gt; 800; 不走索引： 验证2： 1explain select * from emp2 where sal &gt; 1000; 不走索引： 验证3： 1explain select * from emp2 where sal &gt; 2000; 走索引： 关于is null和is not null的索引失效问题给emp2的comm字段添加一个索引： 1create index idx_emp2_comm on emp2(comm); 将emp2表的comm字段值全部更新为NULL： 1update emp2 set comm=null; 验证此时条件使用is null是否走索引： 1explain select * from emp2 where comm is null; 验证结果：不走索引。验证此时条件使用is not null是否走索引： 将emp2表的comm字段全部更新为非NULL： 1update emp2 set comm=100; 验证此时条件使用is null是否走索引： 1explain select * from emp2 where comm is null; 验证结果：走索引验证此时条件使用is not null是否走索引： 1explain select * from emp2 where comm is not null; 验证结果：不走索引 结论：走索引还是不走索引，根数据分布有很大关系，如果符合条件的记录占比较大，会考虑使用全表扫描，而放弃走索引。 指定索引当一个字段上既有单列索引，又有复合索引时，我们可以通过以下的SQL提示来要求该SQL语句执行时采用哪个索引： use index(索引名称)：建议使用该索引，只是建议，底层mysql会根据实际效率来考虑是否使用你推荐的索引。 ignore index(索引名称)：忽略该索引 force index(索引名称)：强行使用该索引 查看 t_customer 表上的索引： 1show index from t_customer; 可以看到name age gender三列添加了一个复合索引。现在给name字段添加一个单列索引： 1create index idx_name on t_customer(name); 看看以下的语句默认使用了哪个索引： 1explain select * from t_customer where name=&#x27;zhangsan&#x27;; 通过测试得知，默认使用了联合索引。 如何建议使用单列索引idx_name： 1explain select * from t_customer use index(idx_name) where name=&#x27;zhangsan&#x27;; 如何忽略使用符合索引 idx_name_age_gender： 1explain select * from t_customer ignore index(idx_name_age_gender) where name=&#x27;zhangsan&#x27;; 如何强行使用单列索引idx_name： 1explain select * from t_customer force index(idx_name) where name=&#x27;zhangsan&#x27;; 覆盖索引覆盖索引我们在讲解索引的时候已经提到过了，覆盖索引强调的是：在select后面写字段的时候，这些字段尽可能是索引所覆盖的字段，这样可以避免回表查询。尽可能避免使用 select *，因为select * 很容易导致回表查询。（本质就是：能在索引上检索的，就不要再次回表查询了。） 例如：有一张表 emp3，其中 ename,job添加了联合索引：idx_emp3_ename_job，以下这个select语句就不会回表： 12345drop table if exists emp3;create table emp3 as select * from emp;alter table emp3 add constraint emp3_pk primary key(empno);create index idx_emp3_ename_job on emp3(ename,job);explain select empno,ename,job from emp3 where ename=&#x27;KING&#x27;; 如果查询语句要查找的列没有在索引中，则会回表查询，例如： 1explain select empno,ename,job,sal from emp3 where ename=&#x27;KING&#x27;; 面试题：t_user表字段如下：id,name,password,realname,birth,email。表中数据量500万条，请针对以下SQL语句给出优化方案： 1select id,name,realname from t_user where name=&#x27;鲁智深&#x27;; 如果只给name添加索引，底层会进行大量的回表查询，效率较低，建议给name和realname两个字段添加联合索引，这样大大减少回表操作，提高查询效率。 前缀索引如果一个字段类型是varchar或text字段，字段中存储的是文本或者大文本，直接对这种长文本创建索引，会让索引体积很大，怎么优化呢？可以将字符串的前几个字符截取下来当做索引来创建。这种索引被称为前缀索引，例如： 123drop table if exists emp4;create table emp4 as select * from emp;create index idx_emp4_ename_2 on emp4(ename(2)); 以上SQL表示将emp4表中ename字段的前2个字符创建到索引当中。 使用前缀索引时，需要通过以下公式来确定使用前几个字符作为索引： 1select count(distinct substring(ename,1,前几个字符)) / count(*) from emp4; 以上查询结果越接近1，表示索引的效果越好。（原理：做索引值的话，索引值越具有唯一性效率越高） 假设我们使用前1个字符作为索引值： 1select count(distinct substring(ename,1,1)) / count(*) from emp4; 假设我们使用前2个字符作为索引值： 1select count(distinct substring(ename,1,2)) / count(*) from emp4; 可见使用前2个字符作为索引值，能够让索引值更具有唯一性，效率越好，因此我们选择前2个字符作为前缀索引。 1create index idx_emp4_ename_2 on emp4(ename(2)); 执行以下的查询语句则会走这个前缀索引： 1explain select * from emp4 where ename=&#x27;KING&#x27;; 单列索引和复合索引怎么选择当查询语句的条件中有多个条件，建议将这几个列创建为复合索引，因为创建单列索引很容易回表查询。例如分别给emp5表ename，job添加两个单列索引： 12345create table emp5 as select * from emp;alter table emp5 add constraint emp5_pk primary key(empno);create index idx_emp5_ename on emp5(ename);create index idx_emp5_job on emp5(job); 执行以下查询语句： 1explain select empno,ename,job from emp5 where ename=&#x27;SMITH&#x27; and job=&#x27;CLERK&#x27;; ename和job都出现在查询条件中，可以给emp6表的ename和job创建一个复合索引： 12345create table emp6 as select * from emp;alter table emp6 add constraint emp6_pk primary key(empno);create index idx_emp6_ename_job on emp6(ename,job);explain select empno,ename,job from emp6 where ename=&#x27;SMITH&#x27; and job=&#x27;CLERK&#x27;; 对于以上查询语句，使用复合索引避免了回表，因此这种情况下还是建议使用复合索引。 注意：创建索引时应考虑最左前缀原则，主字段并且具有很强唯一性的字段建议排在第一位，例如： 1create index idx_emp_ename_job on emp(ename,job); 和以下方式对比： 1create index idx_emp_job_ename on emp(job,ename); 由于ename是主字段，并且ename具有很好的唯一性，建议将ename列放在最左边。因此这两种创建复合索引的方式，建议采用第一种。 复合索引底层原理： 索引创建原则 表数据量庞大，通常超过百万条数据。 经常出现在where，order by，group by后面的字段建议添加索引。 创建索引的字段尽量具有很强的唯一性。 如果字段存储文本，内容较大，一定要创建前缀索引。 尽量使用复合索引，使用单列索引容易回表查询。 如果一个字段中的数据不会为NULL，建议建表时添加not null约束，这样优化器就知道使用哪个索引列更加有效。 不要创建太多索引，当对数据进行增删改的时候，索引需要重新重新排序。 如果很少的查询，经常的增删改不建议加索引。 SQL优化order by的优化准备数据： 12345678910111213drop table if exists workers;create table workers( id int primary key auto_increment, name varchar(255), age int, sal int);insert into workers values(null, &#x27;孙悟空&#x27;, 500, 50000);insert into workers values(null, &#x27;猪八戒&#x27;, 300, 40000);insert into workers values(null, &#x27;沙和尚&#x27;, 600, 40000);insert into workers values(null, &#x27;白骨精&#x27;, 600, 10000); explain查看一个带有order by的语句时，Extra列会显示：using index 或者 using filesort，区别是什么？ using index: 表示使用索引，因为索引是提前排好序的。效率很高。 using filesort：表示使用文件排序，这就表示没有走索引，对表中数据进行排序，排序时将硬盘的数据读取到内存当中，在内存当中排好序。这个效率是低的，应避免。 此时name没有添加索引，如果根据name进行排序的话： 1explain select id,name from workers order by name; 显然这种方式效率较低。给name添加索引： 1create index idx_workers_name on workers(name); 再根据name排序： 1explain select id,name from workers order by name; 这样效率则提升了。 如果要通过age和sal两个字段进行排序，最好给age和sal两个字段添加复合索引，不添加复合索引时：按照age升序排，如果age相同则按照sal升序 1explain select id,age,sal from workers order by age,sal; 这样效率是低的。给age和sal添加复合索引： 1create index idx_workers_age_sal on workers(age, sal); 再按照age升序排，如果age相同则按照sal升序： 1explain select id,age,sal from workers order by age,sal; 这样效率提升了。 在B+树上叶子结点上的所有数据默认是按照升序排列的，如果按照age降序，如果age相同则按照sal降序，会走索引吗？ 1explain select id,age,sal from workers order by age desc,sal desc; 可以看到备注信息是：反向索引扫描，使用了索引。这样效率也是很高的，因为B+树叶子结点之间采用的是双向指针。可以从左向右（升序），也可以从右向左（降序）。 如果一个升序，一个降序会怎样呢？ 1explain select id,age,sal from workers order by age asc, sal desc; 可见age使用了索引，但是sal没有使用索引。怎么办呢？可以针对这种排序情况创建对应的索引来解决： 1create index idx_workers_ageasc_saldesc on workers(age asc, sal desc); 创建的索引如下：A表示升序，D表示降序。再次执行： 1explain select id,age,sal from workers order by age asc, sal desc; 我们再来看看，对于排序来说是否支持最左前缀法则： 1explain select id,age,sal from workers order by sal; 通过测试得知，order by也遵循最左前缀法则。 我们再来看一下未使用覆盖索引会怎样？ 1explain select * from workers order by age,sal; 通过测试得知，排序也要尽量使用覆盖索引。 order by 优化原则总结： 排序也要遵循最左前缀法则。 使用覆盖索引。 针对不同的排序规则，创建不同索引。（如果所有字段都是升序，或者所有字段都是降序，则不需要创建新的索引） 如果无法避免filesort，要注意排序缓存的大小，默认缓存大小256KB，可以修改系统变量 sort_buffer_size ： 1show variables like &#x27;sort_buffer_size&#x27;; group by优化创建empx表： 1create table empx as select * from emp; job字段上没有索引，根据job进行分组，查看每个工作岗位有多少人： 1select job,count(*) from empx group by job; 看看是否走索引了： 1explain select job,count(*) from empx group by job; 使用了临时表，效率较低。 给job添加索引： 1create index idx_empx_job on empx(job); 再次执行： 1explain select job,count(*) from empx group by job; 效率提升了。 我们再来看看group by是否需要遵守最左前缀法则：给deptno和sal添加复合索引 1create index idx_empx_deptno_sal on empx(deptno, sal); 根据部门编号分组，查看每个部门人数： 1explain select deptno,count(*) from empx group by deptno; 效率很高，因为deptno是复合索引中最左边的字段。根据sal分组，查看每个工资有多少人： 1explain select sal, count(*) from empx group by sal; 使用了临时表，效率较低。通过测试得知，group by也同样遵循最左前缀法则。 我们再来测试一下，如果将部门编号deptno（复合索引的最左列）添加到where条件中，效率会不会提升： 1explain select sal, count(*) from empx where deptno=10 group by sal; 效率有提升的，这说明了，group by确实也遵循最左前缀法则。（where中使用了最左列） limit优化数据量特别庞大时，取数据时，越往后效率越低，怎么提升？mysql官方给出的解决方案是：使用覆盖索引+子查询的形式来提升效率。 怎么解决？使用覆盖索引，加子查询使用覆盖索引：速度有所提升使用子查询形式取其他列的数据：通过测试，这种方式整体效率有所提升。 主键优化主键设计原则： 主键值不要太长，二级索引叶子结点上存储的是主键值，主键值太长，容易导致索引占用空间较大。 尽量使用auto_increment生成主键。尽量不要使用uuid做主键，因为uuid不是顺序插入。 最好不要使用业务主键，因为业务的变化会导致主键值的频繁修改，主键值不建议修改，因为主键值修改，聚集索引一定会重新排序。 在插入数据时，主键值最好是顺序插入，不要乱序插入，因为乱序插入可能会导致B+树叶子结点频繁的进行页分裂与页合并操作，效率较低。 主键值对应聚集索引，插入主键值如果是乱序的，B+树叶子结点需要不断的重新排序，重排过程中还会频繁涉及到页分裂和页合并的操作，效率较低。 B+树上的每个节点都存储在页（page）中。一个页面中存储一个节点。 MySQL的InnoDB存储引擎一个页可以存储16KB的数据。 如果主键值不是顺序插入的话，会导致频繁的页分裂和页合并。在一个B+树中，页分裂和页合并是树的自动调整机制的一部分。当一个页已经满了，再插入一个新的关键字时就会触发页分裂操作，将页中的关键字分配到两个新的页中，同时调整树的结构。相反，当一个页中的关键字数量下降到一个阈值以下时，就会触发页合并操作，将两个相邻的页合并成一个新的页。如果主键值是随机的、不是顺序插入的，那么页的利用率会降低，页分裂和页合并的次数就会增加。由于页的分裂和合并是比较耗时的操作，频繁的分裂和合并会降低数据库系统的性能。因此，为了优化B+树的性能，可以将主键值设计成顺序插入的，这样可以减少页的分裂和合并的次数，提高B+树的性能。在实际应用中，如果对主键值的顺序性能要求不是特别高，也可以采用一些技术手段来减少页分裂和合并，例如B+树分裂时采用“延迟分裂”技术，或者通过调整页的大小和节点的大小等方式来优化B+树的性能。 insert优化insert优化原则： 批量插入：数据量较大时，不要一条一条插入，可以批量插入，当然，建议一次插入数据不超过1000条 1insert into t_user(id,name,age) values (1,&#x27;jack&#x27;,20),(2,&#x27;lucy&#x27;,30),(3,&#x27;timi&#x27;,22); mysql默认是自动提交事务，只要执行一条DML语句就自动提交一次，因此，当插入大量数据时，建议手动开启事务和手动提交事务。不建议使用数据库事务自动提交机制。 主键值建议采用顺序插入，顺序插入比乱序插入效率高。 超大数据量插入可以考虑使用mysql提供的load指令，load指令可以将csv文件中的数据批量导入到数据库表当中，并且效率很高，过程如下： 第一步：登录mysql时指定参数 1mysql --local-infile -uroot -p1234 第二步：开启local_infile功能 1set global local_infile = 1; 第三步：执行load指令 1234567891011use powernode;create table t_temp( id int primary key, name varchar(255), password varchar(255), birth char(10), email varchar(255));load data local infile &#x27;E:\\\\powernode\\\\05-MySQL高级\\\\resources\\\\t_temp-100W.csv&#x27; into table t_temp fields terminated by &#x27;,&#x27; lines terminated by &#x27;\\n&#x27;; 文件中的数据如下： 导入表中之后，数据如下： count(*)优化分组函数count的使用方式： count(主键) 原理：将每个主键值取出，累加 count(常量值) 原理：获取到每个常量值，累加 count(字段) 原理：取出字段的每个值，判断是否为NULL，不为NULL则累加。 count(*) 原理：不用取值，底层mysql做了优化，直接统计总行数，效率最高。 结论：如果你要统计一张表中数据的总行数，建议使用 count(*) 注意： 对于InnoDB存储引擎来说，count计数的实现原理就是将表中每一条记录取出，然后累加。如果你想真正提高效率，可以自己使用额外的其他程序来实现，例如每向表中插入一条记录时，在redis数据库中维护一个总行数，这样获取总行数的时候，直接从redis中获取即可，这样效率是最高的。 对于MyISAM存储引擎来说，当一个select语句没有where条件时，获取总行数效率是极高的，不需要统计，因为MyISAM存储引擎维护了一个单独的总行数。 update优化当存储引擎是InnoDB时，表的行级锁是针对索引添加的锁，如果索引失效了，或者不是索引列时，会提升为表级锁。什么是行级锁？A事务和B事务，开启A事务后，通过A事务修改表中某条记录，修改后，在A事务未提交的前提下，B事务去修改同一条记录时，无法继续，直到A事务提交，B事务才可以继续。 有一张表：t_fruit 12345678create table t_fruit( id int primary key auto_increment, name varchar(255));insert into t_fruit values(null, &#x27;苹果&#x27;);insert into t_fruit values(null, &#x27;香蕉&#x27;);insert into t_fruit values(null, &#x27;橘子&#x27;); 开启A事务和B事务，演示行级锁：事务A没有结束之前，事务B卡住：事务A结束之后，事务B继续执行：当然，如果更新的不是同一行数据，事务A和事务B可以并发： 行级锁是对索引列加锁，以上更新语句的where条件是id，id是主键，当然有索引，所以使用了行级锁，如果索引失效，或者字段上没有索引，则会升级为表级锁： 因此，为了更新的效率，建议update语句中where条件中的字段是添加索引的。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]},{"title":"mysql 初级","slug":"mysql初级","date":"2025-05-24T16:00:00.000Z","updated":"2025-08-03T08:55:46.544Z","comments":true,"path":"2025/05/25/mysql初级/","permalink":"http://example.com/2025/05/25/mysql%E5%88%9D%E7%BA%A7/","excerpt":"","text":"第一步操作 以管理员身份运行cmd，输入net start mysql 运行mysql 在cmd中输入mysql -h[地址] -P[端口] -u[用户名] -p[密码] （使用本机的mysql数据库时，可以省略地址和端口） MySQL命令行基本命令 列出当前数据库管理系统中有哪些数据库。 1show databases; 创建数据库，起名bjpowernode。 1create database bjpowernode; 使用bjpowernode数据库。 1use bjpowernode; 查看当前用的是哪个数据库。 1select database(); 查看当前数据库中有哪些表。 1show tables; 删除数据库bjpowernode。 1drop database bjpowernode; 退出mysql exit quit ctrl + c 查看当前mysql版本 1select version(); 还可以使用mysql.exe命令来查看版本信息（在没有登录mysql之前使用）：mysql –version 数据库表的概述 name age gender 张三 20 男 李四 22 女 以上就是数据库表格的直观展示形式。 表是数据库存储数据的基本单元，数据库存储数据的时候，是将数据存储在表对象当中的。为什么将数据存储在表中呢？因为表存储数据非常直观。 任何一张表都有行和列： 行：记录（一行就是一条数据） 列：字段（name字段、age字段、gender字段） 每个字段包含以下属性： 字段名：name、age、gender都是字段的名字 字段的数据类型：每个字段都有数据类型，比如：字符类型、数字类型、日期类型 字段的数据长度：每个字段有可能会有长度的限制 字段的约束：比如某些字段要求该字段下的数据不能重复、不能为空等，用来保证表格中数据合法有效 初始化数据sql脚本：文件名是.sql，并且该文件中编写了大量的SQL语句，执行sql脚本程序就相当于批量执行SQL语句。 执行SQL脚本文件，初始化数据库 第一步：命令窗口登录mysql 第二步：创建数据库bjpowernode（如果之前已经创建就不需要再创建了）：create database bjpowernode; 第三步：使用数据库bjpowernode：use bjpowernode; 第四步：source命令执行sql脚本，注意：source命令后面是sql脚本文件的绝对路径。 第五步：查看是否初始化成功，执行：show tables; 使用其他的mysql客户端工具也可以执行sql脚本，比如navicat。使用source命令执行sql脚本的优点：可支持大文件。 查询DQL专题简单查询查一个字段 查询一个字段说的是：一个表有多列，查询其中的一列。语法格式：select 字段名 from 表名; select和from是关键字，不能随便写 一条SQL语句必须以“;”结尾 对于SQL语句来说，大小写都可以 字段名和表名属于标识符，按照表的实际情况填写，不知道字段名的，可以使用desc命令查看表结构 案例1：查询公司中所有员工编号 1select empno from emp; 案例2：查询公司中所有员工姓名 1SELECT ENAME FROM EMP; 在mysql命令行客户端中，sql语句没有分号是不会执行的：末尾加上“;”就执行了：以上sql虽然以分号结尾之后执行了，但是报错了，错误信息显示：语法错误。假设一个SQL语句在书写过程中出错了，怎么终止这条SQL呢？\\c 查询时字段可参与数学运算 在进行查询操作的时候，字段是可以参与数学运算的，例如加减乘除等。案例1：查询每个员工的月薪 1select ename, sal from emp; 案例2：查询每个员工的年薪（月薪 * 12） 1select ename, sal * 12 from emp; 查询时字段可起别名 我们借用一下之前的SQL语句 1select ename, sal * 12 from emp; 以上的查询结果列名“sal * 12”可读性较差，是否可以给查询结果的列名进行重命名呢？ as关键字 使用as关键字 1select ename, sal * 12 as yearsal from emp; 通过as关键字起别名后，查询结果列显示yearsal，可读性增强。 省略as关键字 其实as关键字可以省略，只要使用空格即可 1select ename, sal * 12 yearsal from emp; 通过以上测试，得知as可以省略，可以使用空格代替as，但如果别名中有空格呢？ 别名中有空格1select ename, sal * 12 year sal from emp; 可以看出，执行报错了，说语法有问题，这是为什么？分析一下：SQL语句编译器在检查该语句的时候，在year后面遇到了空格，会继续找from关键字，但year后面不是from关键字，所以编译器报错了。怎么解决这个问题？记住：如果别名中有空格的话，可以将这个别名使用双引号或者单引号将其括起来。 12select ename, sal * 12 &quot;year sal&quot; from emp;select ename, sal * 12 &#x27;year sal&#x27; from emp; 在mysql中，字符串既可以使用双引号也可以使用单引号，但还是建议使用单引号，因为单引号属于标准SQL。 别名中有中文 如果别名采用中文呢？ 1select ename, sal * 12 年薪 from emp; 别名是中文是可以的，但是对于低版本的mysql来说会报错，需要添加双引号或单引号。我们当前使用的mysql版本是：8.0.24 条件查询 通常在进行查询操作的时候，都是查询符合某些条件的数据，很少将表中所有数据都取出来。怎么取出表的部分数据？需要在查询语句中添加条件进行数据的过滤。常见的过滤条件如下： 条件 说明 &#x3D; 等于 &lt;&gt;或!&#x3D; 不等于 &gt;&#x3D; 大于等于 &lt;&#x3D; 小于等于 &gt; 大于 &lt; 小于 between…and… 等同于 &gt;&#x3D; and &lt;&#x3D; is null 为空 is not null 不为空 &lt;&#x3D;&gt; 安全等于（可读性差，很少使用了）。 and 或 &amp;&amp; 并且 or 或 &#124;&#124; 或者 in 在指定的值当中 not in 不在指定的值当中 exists not exists like 模糊查询 条件查询语法格式 123456select ...from ...where 过滤条件; 过滤条件放在where子句当中，以上语句的执行顺序是： 第一步：先执行from 第二步：再通过where条件过滤 第三步：最后执行select，查询并将结果展示到控制台 等于、不等于 等于 &#x3D;判断等量关系，支持多种数据类型，比如：数字、字符串、日期等。案例1：查询月薪3000的员工编号及姓名 123456select empno,enamefrom empwhere sal = 3000; 案例2：查询员工FORD的岗位及月薪 123456select job, salfrom empwhere ename = &#x27;FORD&#x27;; 存储在表emp中的员工姓名是FORD，全部大写，如果在查询的时候，写成全部小写会怎样呢？ 123456select job, salfrom empwhere ename = &#x27;ford&#x27;; 通过测试发现，即使写成小写ford，也是可以查询到结果的，不过这里需要注意的是：在Oracle数据库当中是查询不到数据的，Oracle的语法要比MySQL的语法严谨。对于SQL语句本身来说是不区分大小写的，但是对于表中真实存储的数据，大写A和小写a还是不一样的，这一点Oracle做的很好。MySQL的语法更随性。另外在Oracle当中，字符串是必须使用单引号括起来的，但在MySQL当中，字符串可以使用单引号，也可以使用双引号，如下： 123456select job, salfrom empwhere ename = &quot;FORD&quot;; 案例3：查询岗位是MANAGER的员工编号及姓名 123456select empno, enamefrom empwhere job = &#x27;MANAGER&#x27;; 任务：查询工资级别是1的最低工资以及最高工资 不等于 &lt;&gt; 或 !&#x3D;判断非等量关系，支持字符串、数字、日期类型等。不等号有两种写法，第一种&lt;&gt;，第二种!&#x3D;，第二种写法和Java程序中的不等号相同，第一种写法比较诡异，不过也很好理解，比如&lt;&gt;3，表示小于3、大于3，就是不等于3。你get到了吗？案例1：查询工资不是3000的员工编号、姓名、薪资 123456select empno,ename,salfrom empwhere sal &lt;&gt; 3000; 案例2：查询工作岗位不是MANAGER的员工姓名和岗位 123456select ename,jobfrom empwhere job &lt;&gt; &#x27;MANAGER&#x27;; 任务：查询不在部门编号为10的部门工作的员工信息 大于、大于等于、小于、小于等于 大于 &gt;案例：找出薪资大于3000的员工姓名、薪资 123456select ename, salfrom empwhere sal &gt; 3000; 大于等于 &gt;&#x3D;案例：找出薪资大于等于3000的员工姓名、薪资 123456select ename, salfrom empwhere sal &gt;= 3000; 小于 &lt;案例：找出薪资小于3000的员工姓名、薪资 123456select ename, salfrom empwhere sal &lt; 3000; 小于等于 &lt;&#x3D;案例：找出薪资小于等于3000的员工姓名、薪资 123456select ename, salfrom empwhere sal &lt;= 3000; and and表示并且，还有另一种写法：&amp;&amp;案例：找出薪资大于等于3000并且小于等于5000的员工姓名、薪资。 123456select ename,salfrom empwhere sal &gt;= 3000 and sal &lt;= 5000; 任务：找出工资级别为2~4（包含2和4）的最低工资和最高工资。 or or表示或者，还有另一种写法：||案例：找出工作岗位是MANAGER和SALESMAN的员工姓名、工作岗位 123456select ename, jobfrom empwhere job = &#x27;MANAGER&#x27; or job = &#x27;SALESMAN&#x27;; 注意：这个题目描述中有这样一句话：MANAGER和SALESMAN，有的同学一看到“和”，就直接使用“and”了，因为“和”对应的英文单词是“and”，如果是这样的话，就大错特错了，因为and表示并且，使用and表示工作岗位既是MANAGER又是SALESMAN的员工，这样的员工是不存在的，因为每一个员工只有一个岗位，不可能同时从事两个岗位。所以使用and是查询不到任何结果的。如下 123456select ename, jobfrom empwhere job = &#x27;MANAGER&#x27; and job = &#x27;SALESMAN&#x27;; 任务：查询20和30部门的员工信息。 and和or的优先级问题 and和or同时出现时，and优先级较高，会先执行，如果希望or先执行，这个时候需要给or条件添加小括号。另外，以后遇到不确定的优先级时，可以通过添加小括号的方式来解决。对于优先级问题没必要记忆。案例：找出薪资小于1500，并且部门编号是20或30的员工姓名、薪资、部门编号。先来看一下错误写法： 123456select ename,sal,deptnofrom empwhere sal &lt; 1500 and deptno = 20 or deptno = 30; 认真解读题意得知：薪资小于1500是一个大前提，要找出的是薪资小于1500的，满足这个条件的前提下，再找部门编号是20或30的，显然以上的运行结果中出现了薪资为1600的，为什么1600的会出现呢？这是因为“sal &lt; 1500 and deptno &#x3D; 20”结合在一起了，“depnto &#x3D; 30”成了一个独立的条件。会导致部门编号为30的所有员工全部查询出来。我们应该让“deptno &#x3D; 20 or deptno &#x3D; 30”结合在一起，正确写法如下： 123456select ename,sal,deptnofrom empwhere sal &lt; 1500 and (deptno = 20 or deptno = 30); 任务：找出薪资小于1500的，并且工作岗位是CLERK和SALESMAN的员工姓名、薪资、岗位。 between…and… between…and…等同于 &gt;&#x3D; and &lt;&#x3D;做区间判断的，包含左右两个边界值。它支持数字、日期、字符串等数据类型。between…and…在使用时一定是**左小右大**。左大右小时无法查询到数据。between…and… 和 &gt;&#x3D; and &lt;&#x3D;只是在写法结构上有区别，执行原理和效率方面没有区别。案例：找出薪资在1600到3000的员工姓名、薪资 123456select ename,salfrom empwhere sal between 1600 and 3000; 采用左大右小的方式： 123456select ename,salfrom empwhere sal between 3000 and 1600; 没有查询到任何数据，所以在使用的时候一定要注意：左小右大。 任务：查询在1982-01-23到1987-04-19之间入职的员工 注意：以上SQL语句中日期需要加上单引号。 is null、is not null 判断某个数据是否为null，不能使用等号，只能使用 is null判断某个数据是否不为null，不能使用不等号，只能使用 is not null在数据库中null不是一个值，不能用等号和不等号衡量，null代表什么也没有，没有数据，没有值 is null案例1：找出津贴为空的员工姓名、薪资、津贴。 123456select ename,sal,commfrom empwhere comm is null; 我们使用等号，尝试一下： 123456select ename,sal,commfrom empwhere comm = null; 查询不到任何数据，所以判断是否为空，不能用等号。 is not null案例2：找出津贴不为空的员工姓名、薪资、津贴 123456select ename,sal,commfrom empwhere comm is not null; in、not in injob in(‘MANAGER’,’SALESMAN’,’CLERK’) 等同于 job &#x3D; ‘MANAGER’ or job &#x3D; ‘SALESMAN’ or job &#x3D; ‘CLERK’sal in(1600, 3000, 5000) 等同于 sal &#x3D; 1600 or sal &#x3D; 3000 or sal &#x3D; 5000in后面有一个小括号，小括号当中有多个值，值和值之间采用逗号隔开sal in(1500, 5000)，需要注意的是：这个并不是说薪资在1500到5000之间，in不代表区间，表示sal是1500的和sal是5000的案例1：找出工作岗位是MANAGER和SALESMAN的员工姓名、薪资、工作岗位第一种：使用or 123456select ename,sal,jobfrom empwhere job = &#x27;MANAGER&#x27; or job = &#x27;SALESMAN&#x27;; 第二种：使用in 123456select ename,sal,jobfrom empwhere job in(&#x27;MANAGER&#x27;, &#x27;SALESMAN&#x27;); 案例2：找出薪资是1500&#x2F;1600&#x2F;3000的员工姓名、工作岗位 123456select ename,jobfrom empwhere sal in(1500, 1600, 3000); not injob not in(‘MANAGER’,’SALESMAN’) 等同于 job &lt;&gt; ‘MANAGER’ and job &lt;&gt; ‘SALESMAN’sal not in(1600, 5000) 等同于 sal &lt;&gt; 1600 and sal &lt;&gt; 5000案例：找出工作岗位不是MANAGER和SALESMAN的员工姓名、工作岗位第一种：使用and 123456select ename,jobfrom empwhere job &lt;&gt; &#x27;MANAGER&#x27; and job &lt;&gt; &#x27;SALESMAN&#x27;; 第二种：使用not in 123456select ename,jobfrom empwhere job not in(&#x27;MANAGER&#x27;, &#x27;SALESMAN&#x27;); in、not in 与 NULL先来看一下emp表中的数据 1select * from emp; 通过表中数据观察到，有4个员工的津贴不为NULL，剩下10个员工的津贴都是NULL。写这样一条SQL语句： 1select * from emp where comm in(NULL, 300); 为什么以上执行结果只有一条记录呢？分析一下：首先你要知道in的执行原理实际上是采用&#x3D;和or的方式，也就是说，以上SQL语句实际上是： 1select * from emp where comm = NULL or comm = 300; 其中NULL不能用等号&#x3D;进行判断，所以comm &#x3D; NULL结果是false，然而中间使用的是or，所以comm &#x3D; NULL被忽略了。所以查询结果就以上一条数据。通过以上的测试得知：in是自动忽略NULL的。再写这样一条SQL语句： 1select * from emp where comm not in(NULL, 300); 以上的执行结果奇怪了，为什么没有查到任何数据呢？我们分析一下：首先你要知道not in的执行原理实际上是采用&lt;&gt;和and的方式，也就是说，以上SQL语句实际上是： 1select * from emp where comm &lt;&gt; NULL and comm &lt;&gt; 300; 其中NULL的判断不能使用&lt;&gt;，所以comm &lt;&gt; NULL结果是false，由于后面是and，and表示并且，comm &lt;&gt; NULL已经是false了，所以and右边的就没必要运算了，comm &lt;&gt; NULL and comm &lt;&gt; 300的整体运算结果就是false。所以查询不到任何数据。通过以上测试得知，not in是不会自动忽略NULL的，所以在使用not in的时候一定要提前过滤掉NULL。 in和or的效率问题or的效率为O(n)，而in的效率为O(log n), 当n越大的时候效率相差越明显（也就是说数据量越大的时候，in的效率越高） 模糊查询like 模糊查询又被称为模糊匹配，在实际开发中使用较多，比如：查询公司中所有姓张的，查询岗位中带有经理两个字的职位等等，这些都需要使用模糊查询。模糊查询的语法格式如下： 1select .. from .. where 字段 like &#x27;通配符表达式&#x27;; 在模糊查询中，通配符主要包括两个：一个是%，一个是下划线_。其中%代表任意多个字符。下划线_代表任意一个字符。案例1：查询员工名字以’S’开始的员工姓名 1select ename from emp where ename like &#x27;S%&#x27;; 案例2：查询员工名字以’T’结尾的员工姓名 1select ename from emp where ename like &#x27;%T&#x27;; 案例3：查询员工名字中含有’O’的员工姓名 1select ename from emp where ename like &#x27;%O%&#x27;; 案例4：查询员工名字中第二个字母是’A’的员工姓名 1select ename from emp where ename like &#x27;_A%&#x27;; 案例5：查询学员名字中含有下划线的。执行以下SQL语句，先准备测试数据： 123456789drop table if exists student;create table student( id int, name varchar(255));insert into student(id,name) values(1, &#x27;susan&#x27;);insert into student(id,name) values(2, &#x27;lucy&#x27;);insert into student(id,name) values(3, &#x27;jack_son&#x27;);select * from student; 查询学员名字中含有下划线的，执行以下SQL试试： 1select * from student where name like &#x27;%_%&#x27;; 显然这个查询结果不是我们想要的，以上SQL之所以将所有数据全部显示了，因为下划线代表任意单个字符，如果你想让这个下划线变成一个普通的下划线字符，就要使用转义字符了，在mysql当中转义字符是“\\”，这个和java语言中的转义字符是一样的： 1select * from student where name like &#x27;%\\_%&#x27;; 排序操作 排序操作很常用，比如查询学员成绩，按照成绩降序排列。排序的SQL语法： 1select .. from .. order by 字段 asc/desc 单一字段升序查询员工的编号、姓名、薪资，按照薪资升序排列。 1select empno,ename,sal from emp order by sal asc; 单一字段降序查询员工的编号、姓名、薪资，按照薪资降序排列。 1select empno,ename,sal from emp order by sal desc; 默认采用升序查询员工的编号、姓名、薪资，按照薪资升序排列。 1select empno,ename,sal from emp order by sal; 查询员工的编号、姓名，按照姓名升序排列。 1select empno,ename from emp order by ename; 多个字段排序查询员工的编号、姓名、薪资，按照薪资升序排列，如果薪资相同的，再按照姓名升序排列。 1select empno,ename,sal from emp order by sal asc, ename asc; where和order by的位置找出岗位是MANAGER的员工姓名和薪资，按照薪资升序排列。 1select ename,sal from emp where job = &#x27;MANAGER&#x27; order by sal asc; 通过这个例子主要是想告诉大家：where先执行，order by语句是最后执行的。 distinct去重查询工作岗位 1select job from emp; 可以看到工作岗位中有重复的记录，如何在显示的时候去除重复记录呢？在字段前添加distinct关键字。 1select distinct job from emp; 注意：这个去重只是将显示的结果去重，原表数据不会被更改。接下来测试一下，在distinct关键字前添加其它字段是否可以？ 1select ename, distinct job from emp; 分析一下：ename是14条记录，distinct job是5条记录，可以同时显示吗？报错了，通过测试得知，distinct只能出现在所有字段的最前面。 当distinct出现后，后面多个字段一定是联合去重的（多个字段如果都相同就只出现一次) 练习1：找出公司中所有的工作岗位。 练习2：找出公司中不同部门的不同工作岗位。 数据处理函数 关于select语句，我们之前都是这样写：select 字段名 from 表名; 其实，这里的字段名可以看做“变量”，select后面既然可以跟变量，那么可以跟常量吗，尝试一下：通过以上sql的测试得知，select后面既可以跟变量，又可以跟常量。以上三条SQL中前两条中100和’abc’都是常量，最后一条SQL的abc没有添加单引号，它会被当做某个表的字段名，因为没有这个字段所以报错。 字符串相关转大写upper和ucase12# 查询所有员工名字，以大写形式展现select upper(ename) as ename from emp; 还有一个和upper函数功能相同的函数ucase，也可以转大写，了解一下即可： 12# 查询所有员工姓名，以大写形式展现select ucase(ename) as ename from emp; 12# 查询员工smith的岗位、薪资（假如你不知道数据库表中的人名是大写、小写还是大小写混合）select ename, job, sal from emp where upper(ename) = &#x27;SMITH&#x27;; 转小写lower和lcase很简单，不再赘述，直接上代码： 123# 查询员工姓名，以小写形式展现select lower(ename) as ename from emp;select lcase(ename) as ename from emp; 截取字符串substr语法：substr(‘被截取的字符串’, 起始下标, 截取长度)有两种写法：第一种：substr(‘被截取的字符串’, 起始下标, 截取长度)第二种：substr(‘被截取的字符串’, 起始下标)，当第三个参数“截取长度”缺失时，截取到字符串末尾注意：起始下标从1开始，不是从0开始。（1表示从左侧开始的第一个位置，-1表示从右侧开始的第一个位置。） 练习：找出员工名字中第二个字母是A的 1select ename from emp where substr(ename, 2, 1) = &#x27;A&#x27;; 获取字符串长度length注意：一个汉字是2个长度。 获取字符的个数char_length 字符串拼接语法：concat(‘字符串1’, ‘字符串2’, ‘字符串3’….)拼接的字符串数量没有限制。注意：在mysql8之前，双竖线||也是可以完成字符串拼接的。但在mysql8之后，||只作为逻辑运算符，不能再进行字符串拼接了。 1select &#x27;abc&#x27; || &#x27;def&#x27; || &#x27;xyz&#x27;; mysql8之后，|| 只作为“或者”运算符，例如：找出工资高于3000或者低于900的员工姓名和薪资： 1select ename, sal from emp where sal &gt; 3000 || sal &lt; 900; mysql中可以使用+进行字符串的拼接吗？不可以，在mysql中+只作加法运算，在进行加法运算时，会将加号两边的数据尽最大的努力转换成数字再求和，如果无法转换成数字，最终运算结果通通是0 去除字符串前后空白trim1select concat(trim(&#x27; abc &#x27;), &#x27;def&#x27;); 默认是去除前后空白，也可以去除指定的前缀后缀，例如：去除前置0 1select trim(leading &#x27;0&#x27; from &#x27;000111000&#x27;); 去除后置0 1select trim(trailing &#x27;0&#x27; from &#x27;000111000&#x27;); 前置0和后置0全部去除 1select trim(both &#x27;0&#x27; from &#x27;000111000&#x27;); 数字相关rand()和rand(x)rand()生成0到1的随机浮点数。rand(x)生成0到1的随机浮点数，通过指定整数x来确定每次获取到相同的浮点值。 round(x)和round(x,y)四舍五入round(x) 四舍五入，保留整数位，舍去所有小数round(x,y) 四舍五入，保留y位小数 truncate(x, y)舍去y是保留几位小数 以上SQL表示保留两位小数，剩下的全部舍去。 ceil与floor数字处理函数除了以上的之外，还有ceil和floor函数： ceil函数：返回大于或等于数值x的最小整数 floor函数：返回小于或等于数值x的最大整数 空处理ifnull(x, y)，空处理函数，当x为NULL时，将x当做y处理。ifnull(comm, 0)，表示如果员工的津贴是NULL时当做0处理。在SQL语句中，凡是有NULL参与的数学运算，最终的计算结果都是NULL：看这样一个需求：查询每个员工的年薪。（年薪 &#x3D; (月薪 + 津贴) * 12个月。注意：有的员工津贴comm是NULL。） 以上查询结果中显示SMITH等人的年薪是NULL，这是为什么，这是因为SMITH等人的津贴comm是NULL，有NULL参与的数学运算，最终结果都是NULL，显然这个需要空处理，此时就用到了ifnull函数： 日期和时间相关函数获取当前日期和时间 now()和sysdate()的区别： now()：获取的是执行select语句的时刻。 sysdate()：获取的是执行sysdate()函数的时刻。 获取当前日期获取当前日期有三种写法，掌握任意一种即可： curdate() current_date() current_date 获取当前时间获取档期时间有三种写法，掌握其中一种即可： curtime() current_time() current_time 获取单独的年、月、日、时、分、秒注意：这些函数在使用的时候，需要传递一个日期参数给它，它可以获取到你给定的这个日期相关的年、月、日、时、分、秒的信息。一次性提取一个给定日期的“年月日”部分，可以使用date()函数，例如：一次性提取一个给定日期的“时分秒”部分，可以使用time()函数，例如： date_add函数date_add函数的作用：给指定的日期添加间隔的时间，从而得到一个新的日期。date_add函数的语法格式：date_add(日期, interval expr 单位)，例如：以’2023-01-03’为基准，间隔3天之后的日期：’2023-01-06’ 以’2023-01-03’为基准，间隔3个月之后的日期：’2023-04-03’详细解释一下这个函数的相关参数： 日期：一个日期类型的数据 interval：关键字，翻译为“间隔”，固定写法 expr：指定具体的间隔量，一般是一个数字。也可以为负数，如果为负数，效果和date_sub函数相同。 单位： year：年 month：月 day：日 hour：时 minute：分 second：秒 microsecond：微秒（1秒等于1000毫秒，1毫秒等于1000微秒） week：周 quarter：季度 请分析下面这条SQL语句所表达的含义：以上SQL表示：以2022-10-01 10:10:10为基准，在这个时间基础上添加-1微秒，也就是减去1微秒。以上SQL也可以采用date_sub函数完成，例如：另外，单位也可以采用复合型单位，例如： SECOND_MICROSECOND MINUTE_MICROSECOND MINUTE_SECOND：几分几秒之后 HOUR_MICROSECOND HOUR_SECOND HOUR_MINUTE：几小时几分之后 DAY_MICROSECOND DAY_SECOND DAY_MINUTE DAY_HOUR：几天几小时之后 YEAR_MONTH：几年几个月之后 如果单位采用复合型的话，expr该怎么写呢？例如单位采用：day_hour，假设我要表示3天2小时之后，怎么写？‘3,2’这个应该很好理解，表示3天2个小时之后。’3,2’和day_hour是对应的。 date_format日期格式化函数将日期转换成具有某种格式的日期字符串，通常用在查询操作当中。（date类型转换成char类型）语法格式：date_format(日期, ‘日期格式’)该函数有两个参数： 第一个参数：日期。这个参数就是即将要被格式化的日期。类型是date类型。 第二个参数：指定要格式化的格式字符串。 %Y：四位年份 %y：两位年份 %m：月份（1..12） %d：日（1..30） %H：小时（0..23） %i：分（0..59） %s：秒（0..59） 例如：获取当前系统时间，让其以这个格式展示：2000-10-11 20:15:30注意：在mysql当中，默认的日期格式就是：%Y-%m-%d %H:%i:%s，所以当你直接输出日期数据的时候，会自动转换成该格式的字符串： str_to_date函数该函数的作用是将char类型的日期字符串转换成日期类型date，通常使用在插入和修改操作当中。（char类型转换成date类型）假设有一个学生表t_student，学生有一个生日的字段，类型是date类型： 123456drop table if exists t_student;create table t_student( name varchar(255), birth date);desc t_student; 我们要给这个表插入一条数据：姓名zhangsan，生日85年10月1日，执行以下insert语句：错误原因：日期值不正确。意思是：birth字段需要一个日期，你给的这个字符串’10&#x2F;01&#x2F;1985’我识别不了。这种情况下，我们就可以使用str_to_date函数进行类型转换：当然，如果你提供的日期字符串格式能够被mysql解析，str_to_date函数是可以省略的，底层会自动调用该函数进行类型转换：如果日期格式符合以上的几种格式，mysql都会自动进行类型转换的。 dayofweek、dayofmonth、dayofyear函数dayofweek：一周中的第几天（17），周日是1，周六是7。dayofmonth：一个月中的第几天（131）dayofyear：一年中的第几天（1~366) last_day函数获取给定日期所在月的最后一天的日期： datediff函数计算两个日期之间所差天数：时分秒不算，只计算日期部分相差的天数。 timediff函数计算两个日期所差时间，例如日期1和日期2所差10:20:30，表示差10小时20分钟30秒。 if函数如果条件为TRUE则返回“YES”，如果条件为FALSE则返回“NO”： 1SELECT IF(500&lt;1000, &quot;YES&quot;, &quot;NO&quot;); 例如：如果工资高于3000，则输出1，反之则输出0再例如：如果名字是SMITH的，工资上调10%，其他员工工资正常显示。再例如：工作岗位是MANAGER的工资上调10%，是SALESMAN的工资上调20%，其他岗位工资正常。上面这个需求也可以使用：case.. when.. then.. when.. then.. else.. end来完成： cast函数cast函数用于转换数据类型语法：cast(值 as 数据类型)例如：cast(‘2020-10-11’ as date)，表示将字符串’2020-10-11’转换成日期date类型。在使用cast函数时，可用的数据类型包括： date：日期类型 time：时间类型 datetime：日期时间类型 signed：有符号的int类型（有符号指的是正数负数） char：定长字符串类型 decimal：浮点型 加密函数md5函数，可以将给定的字符串经过md5算法进行加密处理，字符串经过加密之后会生成一个固定长度32位的字符串，md5加密之后的密文通常是不能解密的： 分组函数分组函数的执行原则：先分组，然后对每一组数据执行分组函数。如果没有分组语句group by的话，整张表的数据自成一组。分组函数包括五个： max：最大值 min：最小值 avg：平均值 sum：求和 count：计数 max找出员工的最高薪资 1select max(sal) from emp; min找出员工的最低工资 1select min(sal) from emp; avg计算员工的平均薪资 1select avg(sal) from emp; sum计算员工的工资和 1select sum(sal) from emp; 计算员工的津贴之和 1select sum(comm) from emp; 重点：所有的分组函数都是自动忽略NULL的。 count统计员工人数 123select count(ename) from emp;select count(*) from emp;select count(1) from emp; count(*)和count(1)的效果一样，统计该组中总记录行数。count(ename)统计的是这个ename字段中不为NULL个数总和。例如：count(comm) 结果是 4，而不是14 1select count(comm) from emp; 统计岗位数量 1select count(distinct job) from emp; 分组函数组合使用select count(*),max(sal),min(sal),avg(sal),sum(sal) from emp; 分组函数注意事项分组函数不能直接使用在where子句当中select ename,job from emp where sal &gt; avg(sal); 这个会报错的原因：分组的行为是在where执行之后才开始的。 分组查询group by按照某个字段分组，或者按照某些字段联合分组。注意：group by的执行是在where之后执行。语法：group by 字段group by 字段1,字段2,字段3….找出每个岗位的平均薪资 1select job, avg(sal) from emp group by job; 找出每个部门最高工资 1select deptno,max(sal) from emp group by deptno; 找出每个部门不同岗位的平均薪资 1select deptno,job,avg(sal) from emp group by deptno,job; 当select语句中有group by的话，select后面只能跟分组函数或参加分组的字段 1select ename,deptno,avg(sal) from emp group by deptno; // 这个SQL执行后会报错。 havinghaving写在group by的后面，当你对分组之后的数据不满意，可以继续通过having对分组之后的数据进行过滤。where的过滤是在分组前进行过滤。使用原则：尽量在where中过滤，实在不行，再使用having。越早过滤效率越高。 找出除20部分之外，其它部门的平均薪资。 12select deptno,avg(sal) from emp where deptno&lt;&gt;20 group by deptno; // 建议select deptno,avg(sal) from emp group by deptno having deptno &lt;&gt; 20; // 不建议 查询每个部门平均薪资，找出平均薪资高于2000的。 1select deptno,avg(sal) from emp group by deptno having avg(sal) &gt; 2000; 组内排序案例：找出每个工作岗位的工资排名在前两名的。substring_index函数的使用：group_concat函数的使用：学习了这两个函数之后，自己可以尝试写出来吗？ 总结单表的DQL语句select …5from …1where …2group by …3having …4order by …6重点掌握一个完整的DQL语句执行顺序。 连接查询什么是连接查询 从一张表中查询数据称为单表查询。 从两张或更多张表中联合查询数据称为多表查询，又叫做连接查询。 什么时候需要使用连接查询？ 比如这样的需求：员工表中有员工姓名，部门表中有部门名字，要求查询每个员工所在的部门名字，这个时候就需要连接查询。 连接查询的分类 根据语法出现的年代进行分类： SQL92（这种语法很少用，可以不用学。） SQL99（我们主要学习这种语法。） 根据连接方式的不同进行分类： 内连接 等值连接 非等值连接 自连接 外连接 左外连接（左连接） 右外连接（右连接） 全连接 笛卡尔积现象 当两张表进行连接查询时，如果没有任何条件进行过滤，最终的查询结果条数是两张表条数的乘积。为了避免笛卡尔积现象的发生，需要添加条件进行筛选过滤。 需要注意：添加条件之后，虽然避免了笛卡尔积现象，但是匹配的次数没有减少。 为了SQL语句的可读性，为了执行效率，建议给表起别名。 内连接什么叫内连接满足条件的记录才会出现在结果集中。 内连接之等值连接连接时，条件为等量关系。案例：查询每个员工所在的部门名称，要求显示员工名、部门名。 12345678select e.ename,d.dnamefrom emp einner join dept don e.deptno = d.deptno; 注意：inner可以省略。 内连接之非等值连接连接时，条件是非等量关系。案例：查询每个员工的工资等级，要求显示员工名、工资、工资等级。 12345678select e.ename,e.sal,s.gradefrom emp ejoin salgrade son e.sal between s.losal and s.hisal; 内连接之自连接连接时，一张表看做两张表，自己和自己进行连接。案例：找出每个员工的直属领导，要求显示员工名、领导名。 12345678select e.ename 员工名, l.ename 领导名from emp ejoin emp lon e.mgr = l.empno; 思路：将emp表当做员工表 e将emp表当做领导表 l可以发现连接条件是：e.mgr &#x3D; l.empno（员工的领导编号&#x3D;领导的员工编号）注意：KING这个员工没有查询出来。如果想将KING也查询出来，需要使用外连接。 外连接什么叫外连接内连接是满足条件的记录查询出来。也就是两张表的交集。外连接是除了满足条件的记录查询出来，再将其中一张表的记录全部查询出来，另一张表如果没有与之匹配的记录，自动模拟出NULL与其匹配。左外连接：右外连接： 外连接之左外连接（左连接）案例：查询所有部门信息，并且找出每个部门下的员工。 12345678select d.*,e.enamefrom dept dleft outer join emp eon d.deptno = e.deptno; 注意：outer可以省略。任何一个左连接都可以写作右连接。 外连接之右外连接（右连接）还是上面的案例，可以写作右连接。 12345678select d.*,e.enamefrom emp eright outer join dept don d.deptno = e.deptno; 案例：找出所有员工的上级领导，要求显示员工名和领导名。 12345678select e.ename 员工名,l.ename 领导名 from emp e left join emp l on e.mgr = l.empno; 12345678select e.ename 员工名,l.ename 领导名 from emp l right join emp e on e.mgr = l.empno; 全连接什么是全连接？MySQL不支持full join。oracle数据库支持。两张表数据全部查询出来，没有匹配的记录，各自为对方模拟出NULL进行匹配。客户表：t_customer订单表：t_order案例：查询所有的客户和订单。 12345678select c.*,o.* from t_customer c full join t_order o on c.cid = o.cid; 多张表连接三张表甚至更多张表如何进行表连接案例：找出每个员工的部门，并且要求显示每个员工的薪资等级。 123456789101112select e.ename,d.dname,s.grade from emp e join dept d on e.deptno = d.deptno join salgrade s on e.sal between s.losal and s.hisal; 子查询什么是子查询 select语句中嵌套select语句就叫做子查询。 select语句可以嵌套在哪里？ where后面、from后面、select后面都是可以的。 123select ..(select)..from ..(select)..where ..(select).. where后面使用子查询案例：找出高于平均薪资的员工姓名和薪资。错误的示范： 1select ename,sal from emp where sal &gt; avg(sal); 错误原因：where后面不能直接使用分组函数。可以使用子查询： 1select ename,sal from emp where sal &gt; (select avg(sal) from emp); from后面使用子查询小窍门：from后面的子查询可以看做一张临时表。案例：找出每个部门的平均工资的等级。第一步：先找出每个部门平均工资。 1select deptno, avg(sal) avgsal from emp group by deptno; 第二步：将以上查询结果当做临时表t，t表和salgrade表进行连接查询。条件：t.avgsal between s.losal and s.hisal 1select t.*,s.grade from (select deptno, avg(sal) avgsal from emp group by deptno) t join salgrade s on t.avgsal between s.losal and s.hisal; select后面使用子查询1select e.ename,(select d.dname from dept d where e.deptno = d.deptno) as dname from emp e; exists、not exists在 MySQL 数据库中，EXISTS（存在）用于检查子查询的查询结果行数是否大于0。如果子查询的查询结果行数大于0，则 EXISTS 条件为真。（即存在查询结果则是true。） 主要应用场景： EXISTS 可以与 SELECT、UPDATE、DELETE 一起使用，用于检查另一个查询是否返回任何行； EXISTS 可以用于验证条件子句中的表达式是否存在； EXISTS 常用于子查询条件过滤，例如查询有订单的用户等。 1234567891011121314151617181920212223242526drop table if exists t_customer;drop table if exists t_order;create table t_customer( customer_id int, customer_name varchar(32));create table t_order( order_id int, order_price decimal(5,1), customer_id int);insert into t_customer(customer_id,customer_name) values(1,&#x27;zhangsan&#x27;);insert into t_customer(customer_id,customer_name) values(2,&#x27;lisi&#x27;);insert into t_customer(customer_id,customer_name) values(3,&#x27;wangwu&#x27;);insert into t_order(order_id, order_price, customer_id) values(10, 1000.0, 1);insert into t_order(order_id, order_price, customer_id) values(20, 2000.0, 1);insert into t_order(order_id, order_price, customer_id) values(30, 3000.0, 2);insert into t_order(order_id, order_price, customer_id) values(40, 4000.0, 2);commit;select * from t_customer;select * from t_order; 现在我们来看一个简单的案例，假设我们要查询先前有过订单的顾客，而订单信息保存在 t_order 表中，顾客信息保存在 t_customer 表中。我们可以使用以下 sql 语句： 1select * from t_customer c where exists(select * from t_order o where o.customer_id=c.customer_id); 在这个查询语句中，子查询用于检查是否有订单与每个客户相关联。如果子查询返回至少一行，则表示该顾客已经下过订单，并返回此客户的所有信息，否则该顾客将不被包含在结果中。 以下是这个查询语句的执行过程： 首先查询表 t_customer 中的所有顾客信息（以下简称为顾客表）； 对于顾客表中的每一行，都执行一次子查询，子查询查询该顾客有没有订单，如果有，则在结果集中保留该顾客信息；如果没有，则将该顾客排除； 最终返回有订单顾客的所有信息。 除了 EXISTS，也可以使用 NOT EXISTS 条件从 SELECT、UPDATE、DELETE 语句中获取子查询的返回结果。NOT EXISTS 用于检查一个子查询是否返回任何行，如果没有行返回，那么 NOT EXISTS 将返回 true。 例如，我们想要查找所有没有下过订单的顾客，可以使用以下 sql 语句： 1select * from t_customer c where not exists(select * from t_order o where o.customer_id=c.customer_id); 在这个查询语句中，如果没有任何与顾客相关联的订单，则 NOT EXISTS 子查询将返回一个空结果集，这时候 WHERE 条件为 true，并将返回所有顾客信息。如果顾客有订单，则 NOT EXISTS 子查询的结果集将不为空，WHERE 条件为 false，则不会返回该顾客的信息。 总之，无论是 EXISTS 还是 NOT EXISTS，都是非常有用的 SQL 工具。可以通过它们来结合子查询来动态过滤查询结果，使 SQL 查询变得更加灵活和高效。 in和exists区别IN 和 EXISTS 都是用于关系型数据库查询的操作符。不同之处在于： IN 操作符是根据指定列表中的值来判断是否满足条件，而 EXISTS 操作符则是根据子查询的结果是否有返回记录集来判断。 EXISTS 操作符通常比 IN 操作符更快，尤其是在子查询返回记录数很大的情况下。因为 EXISTS 只需要判断是否存在符合条件的记录，而 IN 操作符需要比对整个列表，因此执行效率相对较低。 IN 操作符可同时匹配多个值，而 EXISTS 只能匹配一组条件。 下面是一个简单的示例，用于演示 IN 和 EXISTS 之间的区别。假设我们有两个表 orders 和 products，orders 表中记录了订单信息，products 表中记录了商品信息。现在我们想查询所有“手机”和“平板电脑”这两种商品中，至少有一笔订单销售了 $1000 以上的商品： 使用 IN 操作符： 12345678SELECT *FROM productsWHERE product_name IN (&#x27;手机&#x27;, &#x27;平板电脑&#x27;)AND product_id IN ( SELECT product_id FROM orders WHERE order_amount &gt; 1000); 使用 EXISTS 操作符： 123456789SELECT *FROM productsWHERE product_name IN (&#x27;手机&#x27;, &#x27;平板电脑&#x27;)AND EXISTS ( SELECT * FROM orders WHERE orders.product_id = products.product_id AND order_amount &gt; 1000); 总之，IN 和 EXISTS 都是用于条件过滤的操作符，但其实现方式和性能特点都不同，需要根据具体情况进行选择和使用。 union&amp;union all不管是union还是union all都可以将两个查询结果集进行合并。union会对合并之后的查询结果集进行去重操作。union all是直接将查询结果集合并，不进行去重操作。（union all和union都可以完成的话，优先选择union all，union all因为不需要去重，所以效率高一些。）案例：查询工作岗位是MANAGER和SALESMAN的员工。 123select ename,sal from emp where job=&#x27;MANAGER&#x27;union allselect ename,sal from emp where job=&#x27;SALESMAN&#x27;; 以上案例采用or也可以完成，那or和union all有什么区别？考虑走索引优化之类的选择union all，其它选择or。两个结果集合并时，列数量要相同： limit limit作用：查询第几条到第几条的记录。通常是因为表中数据量太大，需要分页显示。 limit语法格式： limit 开始下标, 长度 案例：查询员工表前5条记录 1select ename,sal from emp limit 0, 5; 如果下标是从0开始，可以简写为： 1select ename,sal from emp limit 5; 查询工资排名在前5名的员工（limit是在order by执行之后才会执行的） 1select ename,sal from emp order by sal desc limit 5; 通用的分页sql 假设每页显示3条记录：pageSize &#x3D; 3第1页：limit 0, 3第2页：limit 3, 3第3页：limit 6, 3第pageNo页：limit (pageNo - 1)*pageSize, pageSize 表相关创建表语法格式： 123456create table 表名( 字段名1 数据类型, 字段名2 数据类型, 字段名3 数据类型, ......); 例如：创建学生表 12345create table t_student( no int, name varchar, gender char(1) default &#x27;男&#x27;); 插入数据语法格式： 1insert into 表名(字段名1, 字段名2, 字段名3,......) values (值1,值2,值3,......); 字段名和值要一一对应。类型要一一对应，数量要一一对应。字段名也可以省略，如果字段名省略就表示把所有字段名都写上去了，并且顺序和建表时的顺序相同。 删除表语法格式： 1drop table 表名; 或者 1drop table if exists 表名; 判断是否存在这个表，如果存在则删除。避免不存在时的报错。 MySQL数据类型数据类型（data_type）是指系统中所允许的数据的类型。数据库中的每个列都应该有适当的数据类型，用于限制或允许该列中存储的数据。例如，列中存储的为数字，则相应的数据类型应该为数值类型。如果使用错误的数据类型可能会严重影响应用程序的功能和性能，所以在设计表时，应该特别重视数据列所用的数据类型。更改包含数据的列不是一件小事，这样做可能会导致数据丢失。因此，在创建表时必须为每个列设置正确的数据类型和长度。MySQL 的数据类型可以分为整数类型、浮点数类型、定点数类型、日期和时间类型、字符串类型、二进制类型等。 整数类型tinyint：1个字节（微小整数）smallint：2个字节（小整数）mediumint：3个字节（中等大小的整数）int（integer）：4个字节（普通大小整数）bigint：8个字节（大整数） 浮点数类型float：4个字节，单精度（最多5位小数）double：8个字节，双精度（最多16位小数） 定点数类型decimal：定点数类型。底层实际上采用字符串的形式存储数字。语法：decimal(m, d)例如：decimal(3, 2) 表示3个有效数字，2个小数。（有效数字最多65个，小数位最多30个） 日期和时间类型year：1个字节，只存储年，格式YYYYtime：3个字节，只存储时间，格式HH:MM:SS &#x2F; HHMMSSdate：3个字节，只存储年月日，格式：YYYY-MM-DDdatetime：8个字节，存储年月日+时分秒，格式：YYYY-MM-DD HH:MM:SS（从公元1000年公元9999年）timestamp：4个字节，存储年月日+时分秒，格式：YYYY-MM-DD HH:MM:SS（从公元1980年公元2040年）或者格式为 YYYYMMDDHHMMSS（采用这种格式不需要使用单引号，当然你使用单引号也可以） 字符串类型charchar(m)：m长度是0~255个字符。固定长度字符串，在定义时指定字符串列长。当保存时，在右侧填充空格以达到指定的长度。m表示列的长度，范围是 0～255 个字符。例如，CHAR(4) 定义了一个固定长度的字符串列，包含的字符个数最大为 4。当插入的字符长度大于4，则报错（除非超过4个长度之后都是空格字符，则空格字符会自动被删除用来保证插入的成功）。 varcharvarchar(m)：m长度是0~16383个字符长度可变的字符串。varchar 的最大实际长度由最长的行的大小和使用的字符集确定，而实际占用的空间为字符串的实际长度加 1。例如，varchar(50) 定义了一个最大长度为 50 的字符串，如果插入的字符串只有 10 个字符，则实际存储的字符串为 10 个字符和一个字符串结束字符。varchar在值保存和检索时尾部的空格仍保留。 texttext类型： tinytext 表示长度为 255字符的 TEXT 列。 text 表示长度为 65535字符的 TEXT 列。 mediumtext 表示长度为 16777215字符的 TEXT 列。 longtext 表示长度为 4294967295 或 4GB 字符的 TEXT 列。 enumenum类型： 语法：&lt;字段名&gt; enum(‘值1’,’值2’,…) 该字段插入值时，只能是指定的枚举值。 setset类型： 语法：&lt;字段名&gt; set(‘值1’,’值2’,’值3’,…) 注意：值不可重复。 该字段插入值时，只能是指定的值。 二进制类型BLOB类型：二进制大对象，可以存储图片、声音、视频等文件。 blob：小的，最大长度65535个字节 mediumblob：中等的，最大长度16777215个字节 longblob：大的，最大长度4GB的字节 增删改表结构DDL创建一个学生表12345create table t_student( no bigint, name varchar(255), age int comment &#x27;年龄&#x27;); 查看建表语句1show create table 表名; 修改表名1alter table 表名 rename 新表名; 新增字段1alter table 表名 add 字段名 数据类型; 修改字段名1alter table 表名 change 旧字段名 新字段名 数据类型; 修改字段数据类型1alter table 表名 modify column 字段名 数据类型; 删除字段1alter table 表名 drop 字段名; DML语句当我们对表中的数据进行增删改的时候，称它为DML语句。（数据操纵语言），主要包括：insert、delete、update insert 增语法格式： 1insert into 表名(字段名1,字段名2,字段名3,...) values(值1,值2,值3,...); 表名后面的小括号当中的字段名如果省略掉，表示自动将所有字段都列出来了，并且字段的顺序和建表时的顺序一致。一般为了可读性强，建议把字段名写上。 1insert into 表名 values(值1,值2,值3,...); 一次可以插入多条记录： 1insert into t_stu(no,name,age) values(1,&#x27;jack&#x27;,20),(2,&#x27;lucy&#x27;,30); delete 删语法格式： 12345# 将所有记录全部删除delete from 表名;# 删除符合条件的记录delete from 表名 where 条件; 以上的删除属于DML的方式删除，这种删除的数据是可以通过事务回滚的方式重新恢复的，但是删除的效率较低。（这种删除是支持事务的。）另外还有一种删除表中数据的方式，但是这种方式不支持事务，不可以回滚，删了之后数据是永远也找不回来了。这种删除叫做：表被截断。注意：这个语句删除效率非常高，巨大的表，瞬间干掉所有数据。但不可恢复。 1truncate table 表名; update 改语法格式： 1update 表名 set 字段名1=值1, 字段名2=值2, 字段名3=值3 where 条件; 如果没有更新条件的话，所有记录全部更新。 约束constraint创建表时，可以给表的字段添加约束，可以保证数据的完整性、有效性。比如大家上网注册用户时常见的：用户名不能为空。对不起，用户名已存在。等提示信息。约束通常包括： 非空约束：not null 检查约束：check 唯一性约束：unique 主键约束：primary key 外键约束：foreign key 非空约束语法格式： 12345create table t_stu( no int, name varchar(255) not null, age int); name字段不能为空。插入数据时如果没有给name指定值，则报错。 检查约束123456create table t_stu( no int, name varchar(255), age int, check(age &gt; 18)); 唯一性约束语法格式： 12345create table t_stu( no int, name varchar(255), email varchar(255) unique); email字段设置为唯一性，唯一性的字段值是可以为NULL的。但不能重复。以上在字段后面添加的约束，叫做列级约束。当然，添加约束还有另一种方式：表级约束： 123456create table t_stu( no int, name varchar(255), email varchar(255), unique(email)); 使用表级约束可以为多个字段添加联合唯一。 123456create table t_stu( no int, name varchar(255), email varchar(255), unique(name,email)); 创建约束时也可以给约束起名字，将来可以通过约束的名字来删除约束： 123456create table t_stu( no int, name varchar(255), email varchar(255), constraint t_stu_name_email_unique unique(name,email)); 所有的约束都存储在一个系统表当中：table_constraints。这个系统表在这个数据库当中：information_schema 主键约束 主键：primary key，简称PK 主键约束的字段不能为NULL，并且不能重复。 任何一张表都应该有主键，没有主键的表可以视为无效表。 主键值是这行记录的身份证号，是唯一标识。在数据库表中即使两条数据一模一样，但由于主键值不同，我们也会认为是两条完全的不同的数据。 主键分类： 根据字段数量分类： 单一主键（1个字段作为主键）&#x3D;&#x3D;&gt;建议的 复合主键（2个或2个以上的字段作为主键） 根据业务分类： 自然主键（主键和任何业务都无关，只是一个单纯的自然数据）&#x3D;&#x3D;&#x3D;&gt;建议的 业务主键（主键和业务挂钩，例如：银行卡账号作为主键） 单一主键（建议使用这种方式） 12345create table t_student( id bigint primary key, sno varchar(255) unique, sname varchar(255) not null) 复合主键（很少用，了解） 123456create table t_user( no int, name varchar(255), age int, primary key(no,name)); 主键自增：既然主键值是一个自然的数字，mysql为主键值提供了一种自增机制，不需要我们程序员维护，mysql自动维护该字段 1234create table t_vip( no int primary key auto_increment, name varchar(255)); 外键约束 有这样一个需求：要求设计表，能够存储学生以及学校信息。 第一种方案：一张表 这种方式会导致数据冗余，浪费空间。 2. 第二种方案：两张表：一张存储学生，一张存储学校 t_school 表t_student 表如果采用以上两张表存储数据，对于学生表来说，sno这个字段的值是不能随便填的，这个sno是学校编号，必须要求这个字段中的值来自学校表的sno。为了达到要求，此时就必须要给t_student表的sno字段添加外键约束了。 外键约束：foreign key，简称FK。 添加了外键约束的字段中的数据必须来自其他字段，不能随便填。 假设给a字段添加了外键约束，要求a字段中的数据必须来自b字段，b字段不一定是主键，但至少要有唯一性。 外键约束可以给单个字段添加，叫做单一外键。也可以给多个字段联合添加，叫做复合外键。复合外键很少用。 a表如果引用b表中的数据，可以把b表叫做父表，把a表叫做子表。 创建表时，先创建父表，再创建子表。 插入数据时，先插入父表，在插入子表。 删除数据时，先删除子表，再删除父表。 删除表时，先删除子表，再删除父表。 如何添加外键： 1234567891011create table t_school( sno int primary key, sname varchar(255) ); create table t_student( no int primary key, name varchar(255), age int, sno int, constraint t_school_sno_fk foreign key(sno) references t_school(sno) ); 级联删除 创建子表时，外键可以添加：on delete cascade，这样在删除父表数据时，子表会级联删除。谨慎使用。 1234567create table t_student( no int primary key, name varchar(255), age int, sno int, constraint t_school_sno_fk foreign key(sno) references t_school(sno) on delete cascade ); 1234###删除约束alert table t_student drop foreign key t_student_sno_fk;###添加约束alert table t_student add constraint t_student_sno_fk foreign key(sno) references t_school(sno) on delete cascade; 级联更新 1234567create table t_student( no int primary key, name varchar(255), age int, sno int, constraint t_school_sno_fk foreign key(sno) references t_school(sno) on update cascade ); 级联置空 1234567create table t_student( no int primary key, name varchar(255), age int, sno int, constraint t_school_sno_fk foreign key(sno) references t_school(sno) on delete set null ); 三范式什么是数据库设计三范式数据库表设计的原则。教你怎么设计数据库表有效，并且节省空间。 三范式 第一范式：任何一张表都应该有主键，每个字段是原子性的不能再分 以下表的设计不符合第一范式：无主键，并且联系方式可拆分。 2. 应该这样设计： 第二范式：建立在第一范式基础上的，另外要求所有非主键字段完全依赖主键，不能产生部分依赖 以下表存储了学生和老师的信息 虽然符合第一范式，但是违背了第二范式，学生姓名、老师姓名都产生了部分依赖。导致数据冗余。 2. 以下这种设计方式就是符合第二范式的： 第三范式：建立在第二范式基础上的，非主键字段不能传递依赖于主键字段 以下设计方式就是违背第三范式的 以上因为产生了传递依赖，导致班级名称冗余。 2. 以下这种方式就是符合第三范式的： 一对多怎么设计口诀：一对多两张表，多的表加外键。 多对多怎么设计多对多三张表，关系表添加外键。 一对一怎么设计两种方案： 第一种：主键共享 第二种：外键唯一 最终的设计最终以满足客户需求为原则，有的时候会拿空间换速度。 视图 只能将select语句创建为视图。 创建视图 1create or replace view v_emp as select e.ename,d.dname from emp e join dept d on e.deptno = d.deptno; 视图作用 如果开发中有一条非常复杂的SQL，而这个SQL在多处使用，会给开发和维护带来成本。使用视图可以降低开发和维护的成本。 视图可以隐藏表的字段名。 修改视图 1alter view v_emp as select e.ename,d.dname,d.deptno from emp e join dept d on e.deptno = d.deptno; 删除视图 drop view if exists v_emp; 对视图增删改（DML：insert delete update）可以影响到原表数据。 事务事务概述 事务是一个最小的工作单元。在数据库当中，事务表示一件完整的事儿。 一个业务的完成可能需要多条DML语句共同配合才能完成，例如转账业务，需要执行两条DML语句，先更新张三账户的余额，再更新李四账户的余额，为了保证转账业务不出现问题，就必须保证要么同时成功，要么同时失败，怎么保证同时成功或者同时失败呢？就需要使用事务机制。 也就是说用了事务机制之后，在同一个事务当中，多条DML语句会同时成功，或者同时失败，不会出现一部分成功，一部分失败的现象。 事务只针对DML语句有效：因为只有这三个语句是改变表中数据的。 insert delete update 事务四大特性：ACID 原子性（Atomicity）：是指事务包含的所有操作要么全部成功，要么同时失败。 一致性（Consistency）：是指事务开始前，和事务完成后，数据应该是一致的。例如张三和李四的钱加起来是5000，中间不管进行过多少次的转账操作(update)，总量5000是不会变的。这就是事务的一致性。 隔离性（Isolation）：隔离性是当多个⽤户并发访问数据库时，⽐如操作同⼀张表时，数据库为每⼀个⽤户开启的事务，不能被其他事务的操作所⼲扰，多个并发事务之间要相互隔离。 持久性（Durability）：持久性是指⼀个事务⼀旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 演示MySQL事务在dos命令窗口中开启MySQL事务：start transaction; 或者：begin;回滚事务：rollback;提交事务：commit;只要执行以上的rollback或者commit，事务都会结束。MySQL默认情况下采用的事务机制是：自动提交。所谓自动提交就是只要执行一条DML语句则提交一次。 事务隔离级别隔离级别从低到高排序：读未提交 &lt; 读提交 &lt; 可重复读 &lt; 串行化****不同隔离级别会存在不同的现象，现象按照严重性从高到低排序：脏读 &gt; 不可重复读 &gt; 幻读 查看与设置隔离级别mysql默认的隔离级别：可重复读（REPEATABLE READ）。 查看当前会话的隔离级别：select @@transaction_isolation; 查看全局的隔离级别：select @@gobal.transaction_isolation; 设置事务隔离级别： 会话级：set session transaction isolation level read committed; 全局级：set global transaction isolation level read committed; 不同现象脏读指的是一个事务读取了另一个事务尚未提交的数据，即读取了另一个事务中的脏数据（Dirty Data）。在此情况下，如果另一个事务回滚了或者修改了这些数据，那么读取这些脏数据的事务所处理的数据就是不准确的。 不可重复读指在一个事务内，多次读取同一个数据行，得到的结果可能是不一样的。这是由于其他事务对数据行做出了修改操作，导致数据的不一致性。 幻读指在事务执行过程中，前后两次相同的查询条件得到的结果集不一致，可能会变多或变少。 隔离级别读未提交（READ UNCOMMITTED）A事务与B事务，A事务可以读取到B事务未提交的数据。这是最低的隔离级别。几乎两个事务之间没有隔离。这种隔离级别是一种理论层面的，在实际的数据库产品中，没有从这个级别起步的。当事务隔离级别是读未提交时，三种现象都存在：脏读，不可重复读，幻读。我们可以开启两个DOS命令窗口，模拟两个事务，演示一下这种隔离级别。三种现象中最严重的是脏读，我们只需要演示脏读问题即可，因为存在脏读的话，就一定存在不可重复读和幻读问题。 将全局事务隔离级别设置为：READ UNCOMMITTED 1set global transaction isolation level read uncommitted; 开启两个DOS命令窗口来模拟两个事务：A事务与B事务。 A事务 B事务 mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a; mysql&gt; insert into a values(4); mysql&gt; select * from a; 通过以上测试，可以看到，A事务读取到了B事务还没有提交的数据。这种现象就是脏读。 读提交（READ COMMITTED）A事务与B事务，A事务可以读取到B事务提交之后的数据。Oracle数据库默认的就是这种隔离级别。 将数据库的全局事务隔离级别设置为读提交：READ COMMITTED 1set global transaction isolation level read committed; 演示： A事务 B事务 mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a; mysql&gt; insert into a values(4); mysql&gt; select * from a; mysql&gt; commit; mysql&gt; select * from a; 通过以上测试看出，A事务只能读取到B事务提交之后的数据。这种隔离级别解决了脏读问题，但肯定是存在不可重复读和幻读问题。因为只要事务B进行了增删改操作之后并提交了，事务A读取到的数据肯定是不同的。即：不可重复读和幻读都存在。 可重复读（REPEATABLE READ）这个隔离级别是MySQL数据库默认的。A事务和B事务，A事务开启后，读取了某一条记录，然后B事务对这条记录进行修改并提交，A事务读取到的还是修改前的数据。这种隔离级别称为可重复读。 将数据库全局隔离级别修改为可重复读： 1set global transaction isolation level repeatable read; 演示： A事务 B事务 mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select empno,ename,sal from emp where empno&#x3D;7369; mysql&gt; update emp set ename&#x3D;’SMITH’,sal&#x3D;8000 where empno&#x3D;7369; mysql&gt; commit; mysql&gt; select empno,ename,sal from emp where empno&#x3D;7369; 通过以上测试得知：当事务隔离级别设置为可重复读时，避免了不可重复读问题。 那么在MySQL当中，当事务隔离级别设置为可重复读时，能够避免幻读问题吗？测试一下： 事务A 事务B mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a; mysql&gt; insert into a values(5); mysql&gt; commit; mysql&gt; select * from a; 通过以上测试得知：当事务隔离级别设置为可重复读时，也避免了幻读问题。是完全避免了幻读问题吗？并不是。请看以下测试： 事务A 事务B mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a; mysql&gt; insert into a values(6); mysql&gt; commit; mysql&gt; select * from a for update; 通过以上测试得知：当事务隔离级别设置为可重复读，MySQL会尽最大努力避免幻读问题，但这种隔离级别无法完全避免幻读问题。 串行化（SERIALIZABLE）这种隔离级别最高，避免了所有的问题，缺点是效率低，因为这种隔离级别会导致事务排队处理，不支持并发。 设置数据库全局隔离级别为串行化： 1set global transaction isolation level serializable; 演示： 事务A 事务B mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a; mysql&gt; insert into a values(7); mysql&gt; select * from a; mysql&gt; commit; 通过以上测试得知：当事务隔离级别设置为串行化时，事务只能排队执行，不支持并发。 可重复读的幻读问题在上面讲解过程中我提到，MySQL默认的隔离级别可重复读，在很大程度上避免了幻读问题（并不能完全解决），那么它是如何解决幻读问题的呢，解决方案包括两种： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好的避免了幻读问题。 针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好的避免了幻读问题。 快照读是如何解决幻读的什么是快照读？普通的select语句都是采用的快照读。顾名思义：在整个事务的处理过程中，执行相同的一个select语句时，每次都是读取的快照。（快照指的是固定的某个时刻的数据，就像现实世界中的拍照一样，把那个美好的时刻留下来）。也就是说，当事务隔离级别是可重复读，并且执行的select语句是一个普通的select语句时，都会采用快照读的方式读取数据，底层实现原理是： 底层由 MVCC（多版本并发控制）实现，实现的方式是开始事务后，在执行第一个查询语句后，会创建一个 Read View，后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的，即使中途有其他事务插入了新纪录，是查询不出来这条数据的，所以就很好的避免了幻读问题。 演示： 事务A 事务B mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a; &#x2F;&#x2F;快照读 mysql&gt; insert into a values(5); mysql&gt; commit; mysql&gt; select * from a; &#x2F;&#x2F;快照读 当前读是如何解决幻读的当前读，顾名思义：每一次都读取最新的数据。当前读包括：update、delete、insert、select…for update。这个很好理解，因为增删改的时候都要基于最新的数据进行增删改。而select…for update原理是：对查询范围内的数据进行加锁，不允许其它事务对这个范围内的数据进行增删改。也就是说这个select语句范围内的数据是不允许并发的，只能排队执行，从而避免幻读问题。select…for update加的锁叫做：next-key lock。我们可以称其为：间隙锁 + 记录锁。间隙锁用来保证在锁定的范围内不允许insert操作。记录锁用来保证在锁定的范围内不允许delete和update操作。 假如有这样的数据：SQL语句是这样写的： 1select * from a where id between 2 and 4 for update; 那么id在[2-4]区间的所有记录行被锁定，不能插入3是通过间隙锁来搞定的。不能修改或删除2和4是通过记录锁来搞定的。 演示： 事务A 事务B mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a where id between 2 and 4 for update; &#x2F;&#x2F; 当前读 出现幻读的两种情况在同一个事务处理过程中，如果前后两次都采用快照读，或者都采用当前读，则不会出现幻读问题。如果第一次使用快照读，后面使用了当前读，则会出现幻读问题。 第一种产生幻读的场景A事务与B事务。在A事务中第一次查询使用快照读，B事务插入数据。然后在A事务中第二次查询使用当前读。则会产生幻读现象。演示： 事务A 事务B mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a; mysql&gt; insert into a values(5); mysql&gt; commit; mysql&gt; select * from a for update; &#x2F;&#x2F; 产生了幻读 第二种产生幻读的场景事务A与事务B，在事务A中第一次查询使用快照读，在事务B中插入一条数据，然后在事务A中更新事务B插入的那条记录，最后在事务A中再次使用快照读。则会发生幻读现象。 事务A 事务B mysql&gt; use powernode mysql&gt; use powernode mysql&gt; start transaction; mysql&gt; start transaction; mysql&gt; select * from a; mysql&gt; insert into a values(6); mysql&gt; commit; mysql&gt; update a set id&#x3D;100 where id&#x3D;6; &#x2F;&#x2F;主要是因为这个SQL语句的执行触发了当前读 mysql&gt; select * from a; &#x2F;&#x2F; 产生了幻读 总结可重复读的幻读问题MySQL的可重复读隔离级别（默认隔离级），根据不同的查询方式，分别提出了避免幻读的方案： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读。 针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。 我举例了两个发生幻读场景的例子。 第一个例子：对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。 第二个例子：对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。 所以，MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select … for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。 DBA命令新建用户创建一个用户名为java1，密码设置为123的本地用户： 1create user &#x27;java1&#x27;@&#x27;localhost&#x27; identified by &#x27;123&#x27;; 创建一个用户名为java2，密码设置为123的外网用户： 1create user &#x27;java2&#x27;@&#x27;%&#x27; identified by &#x27;123&#x27;; 采用以上方式新建的用户没有任何权限：系统表也只能看到以下两个使用root用户查看系统中当前用户有哪些？ 1select user,host from mysql.user; 给用户授权授权语法：grant [权限1，权限2…] on 库名.表名 to ‘用户名‘@’主机名&#x2F;IP地址’;给本地用户授权：grant [权限1，权限2…] on 库名.表名 to ‘用户名‘@’localhost’;给外网用户授权：grant [权限1，权限2…] on 库名.表名 to ‘用户名‘@’%’;所有权限：all privileges细粒度权限：select、insert、delete、update、alter、create、drop、index(索引)、usage(登录权限)……库名可以使用 * ，它代表所有数据库表名可以采用 * ，它代表所有表也可以提供具体的数据库和表，例如：powernode.emp （powernode数据库的emp表） 12345# 将所有库所有表的查询权限赋予本地用户java1grant select,insert,delete,update,create on *.* to &#x27;java1&#x27;@&#x27;localhost&#x27;;# 将powernode库中所有表的所有权限赋予本地用户java1grant all privileges on powernode.* to &#x27;java1&#x27;@&#x27;localhost&#x27;; 授权后必须刷新权限，才能生效：flush privileges查看某个用户拥有哪些权限？show grants for ‘java1‘@’localhost’show grants for ‘java2‘@’%’ with grant option： 12# with grant option的作用是：java2用户也可以给其他用户授权了。grant select,insert,delete,update on *.* to &#x27;java2&#x27;@&#x27;%&#x27; with grant option; 撤销用户权限revoke 权限 on 数据库名.表名 from ‘用户‘@’IP地址’; 12345# 撤销本地用户java1的insert、update、delete权限revoke insert, update, delete on powernode.* from &#x27;java1&#x27;@&#x27;localhost&#x27;# 撤销外网用户java2的insert权限revoke insert on powernode.* from &#x27;java2&#x27;@&#x27;%&#x27; 撤销权限后也需要刷新权限：flush privileges 注意：撤销权限时 “数据库名.表名” 不能随便写，要求和授权语句时的 “数据库名.表名” 一致。 修改用户的密码具有管理用户权限的用户才能修改密码，例如root账户可以修改其他账户的密码： 12345# 本地用户修改密码alter user &#x27;java1&#x27;@&#x27;localhost&#x27; identified by &#x27;456&#x27;;# 外网用户修改密码alter user &#x27;java2&#x27;@&#x27;%&#x27; identified by &#x27;456&#x27;; 修改密码后，也需要刷新权限才能生效：flush privileges以上是MySQL8版本以后修改用户密码的方式。 修改用户名12345rename user &#x27;原始用户名&#x27;@&#x27;localhost&#x27; to &#x27;新用户名&#x27;@&#x27;localhost&#x27;;rename user &#x27;原始用户名&#x27;@&#x27;localhost&#x27; to &#x27;新用户名&#x27;@&#x27;%&#x27;;rename user &#x27;java1&#x27;@&#x27;localhost&#x27; to &#x27;java11&#x27;@&#x27;localhost&#x27;;rename user &#x27;java11&#x27;@&#x27;localhost&#x27; to &#x27;java123&#x27;@&#x27;%&#x27;; flush privileges; 删除用户12drop user &#x27;java123&#x27;@&#x27;localhost&#x27;;drop user &#x27;java2&#x27;@&#x27;%&#x27;; flush privileges; 数据备份 导出数据（请在登录mysql数据库之前进行） 12345# 导出powernode这个数据库中所有的表mysqldump powernode &gt; e:/powernode.sql -uroot -p1234 --default-character-set=utf8# 导出powernode中emp表的数据mysqldump powernode emp &gt; e:/powernode.sql -uroot -p1234 --default-character-set=utf8 导入数据第一种方式：（请在登录mysql之前进行） 1234# 现在登录mysql状态下新建一个数据库create database powernode;# 在登录mysql之前执行以下命令mysql powernode &lt; e:/powernode.sql -uroot -p1234 --default-character-set=utf8 导入数据第二种方式：（请在登录mysql之后操作） 123create database powernode;use powernode;source d:/powernode.sql","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]},{"title":"javase 数组","slug":"javase 数组","date":"2025-04-24T16:00:00.000Z","updated":"2025-05-25T10:50:11.600Z","comments":true,"path":"2025/04/25/javase 数组/","permalink":"http://example.com/2025/04/25/javase%20%E6%95%B0%E7%BB%84/","excerpt":"","text":"四、数组数组概述 数组是引用数据类型，隐式继承Object，因此可以调用Object类中的方法 数组对象存储在堆内存中 数组的特点 数组长度一旦确定不可改变 所有数组对象都有length属性，用来获取数组元素个数 优点： 根据下标查找某个元素的效率极高 缺点： 随机增删的效率低，需要后移&#x2F;前移很多元素 无法存储大量数据，因为很难在内存上找到非常大的一块连续内存 一维数组静态初始化一维数组已经知道数组中的值时使用 1234// 第一种int[] arr = &#123;11,22,33&#125;; 或者 int arr[] = &#123;11,22,33&#125;; //后者不建议// 第二种int[] arr = new int[] &#123;11,22,33&#125;; 用第一种就好了！ JDK5 新特性：增强for循环 &#x2F; for-each 循环123for(元素数据类型 变量名:数组名)&#123; // 变量名代表数组中的每个元素，可以自己取名 &#125; 优点：代码简洁 缺点：没有下标 动态初始化不知道数组中具体存储哪些元素时使用 1数据类型[] 变量名 = new 数据类型[长度] 数组长度确定，数组中存储的每个元素将采用默认值。 数组中如何存储不同类的对象创建父类类型的数组，即可存子类的对象 eg. 123Apple a = new Apple();Bird b = new Bird();Object[] objs = &#123;a,b&#125;; 存的是对象的地址 关于main方法的形参args 作用：接收命令行参数用的 JVM负责调用main方法时用的 ——JVM负责给main方法准备一个String[ ]一维数组对象 java fileName abc def xyz命令行参数：abc def xyz，JVM会将命令行参数以空格进行拆分，生成一个新的数组对象。 String[ ] args &#x3D; {“abc”,”def”,”xyz”}; ​ 命令行参数有什么用？ ​ 需求：使用该系统的时候，需要提供正确的口令（用户名和密码），非法用户直接退出系统。 ​ 当两个字符串进行equals比较时，如果其中有一个字符串是字面量，建议将字面量写到前面。即：&quot;string&quot;.equals(variable)，避免出现空指针异常。 可变长度的参数function1(int ... nums) 语法格式：数据类型... 在形参列表中，可变长度的参数只能有一个，且只能在参数列表的末尾 可变长度的参数可以当做数组来看待 可通过这种方式访问：nums[0],nums[1] 一维数组的扩容 数组长度一旦确定不可改变 只能新建一个更大的数组，然后将原数组的数据全部拷贝到新数组中，可以使用System.arraycopy() 数组扩容会影响程序的执行效率，因此尽可能预测数据量，减小扩容次数。 二维数组静态初始化123int[][] arr = new int [][]&#123;&#123;1,2,3&#125;,&#123;1,2,3,4,5&#125;,&#123;1&#125;&#125;;int[][] arr = &#123;&#123;1,2,3&#125;,&#123;1,2,3&#125;,&#123;1&#125;&#125;; // 可以等长，也可以不等长 动态初始化1234// 等长int[][] arr = new int [3][4];// 不等长int[][] arr = new int [3][]; Arrays 工具类 自定义类型做比较的话，这个自定义类型必须实现Comparable接口，并实现compareTo方法。使用sort进行排序时也需要实现该方法。 int[] Arrays.copyOf()是系统自动在内部新建一个数组，将原来的数组复制到新建的数组中，并返回新建的数组。而System.arraycopy()没有新建数组，是直接将内容复制到另一个数组中的。而且arraycopy是native方法，由c++代码实现，因此arraycopy的拷贝速度更快。 五、异常什么是异常？java程序执行过程中的意外、错误、不正确的情况 异常在java中的形式以类和对象的形式存在。 定义异常其实本质上就是定义一个类。 异常如果发生的话，在底层其实通过了这个类new了一个对象。 自定义异常 自定义异常的类需要继承Exception或者RuntimeException，如果继承的是Exception就认为这个异常是编译时异常。 提供两个构造方法，一个是无参数的，一个是带有String参数的，并且在构造方法中调用super(String)； 处理异常的两种方法 抛出异常：在类的声明中添加 throws 异常类名 如果有些方法不允许使用thorws，也可以使用try catch然后在catch里面使用throw 捕捉异常 12345678try&#123; // 尝试执行的代码&#125;catch(异常类型1 变量名)&#123; &#125;catch(异常类型2 变量名)&#123; &#125;...... 注：异常类型1,2,3，… 一定是从小到大的，否则如果第一个就是父类，那永远都不可能运行后面的异常处理代码了。 throw和throws的区别： throw是运行时的语句，真正地抛出一个异常实例 throws是编译时的声明，告诉编译器和调用者，如果出现这些问题就抛出。 JAVA7 新特性 —— 异常统一处理方式1. 123456try&#123; // 尝试执行的代码&#125;catch(异常类型1 | 异常类型2 变量名)&#123; &#125;...... 异常对象的方法 getMessage printStackTrace 1234567891011try&#123; // 尝试执行的代码&#125;catch(IllegalNameException e)&#123; // 这个方法可以获取当时创建异常对象时给异常构造方法传递的String message参数的值 String message = e.getMessage(); // 打印异常的堆栈信息 e.printStackTrace();&#125;......后面执行的代码 异常的堆栈信息： 异常信息的打印是符合栈这个数据结构的，因此优先看最上面的异常行数，最上面是最后执行的代码 打印异常堆栈信息可能出现在“后面执行的代码”前面，也可能在后面。因为高版本的底层是用多线程并行打印的。 finally 语句块放在该语句块中的代码是一定会执行的（无论前面的程序是否有异常），一般在finally语句块中完成资源的释放。 顺序：try…(catch)…finally 继承问题子类继承父类后，重写了父类的方法，重写之后不能抛出更多的异常，可以更少。 六、常用类字符串 String为什么string 字面量不可变？因为底层代码中string是用byte数组存的，而byte数组是private final修饰的，因此无法修改它的值。（java8及之前是char数组） 字符串拼接 如果拼接的两个字符串中有一个是变量，那么拼接后的新字符串不会放到字符串常量池中。而是在堆中。 ​ 底层在进行拼接时，会创建一个StringBuilder对象，进行字符串拼接。最后自动调用StringBuilder对象中的toString()方法，再将StringBuilder对象转换成String对象。 两个字符串字面量拼接会在编译阶段做优化，在编译阶段进行拼接（可以这么理解，但不准确）因此字符串常量池中只有拼接后的内容。 怎么把字符串手动放进字符串常量池？12String m = &quot;test&quot;;String str = m.intern(); // 将&quot;test&quot;放入字符串常量池，并且将&quot;test&quot;对象的地址返回。如果字符串常量池已经存在&quot;test&quot;，那么就直接返回地址。 只能加东西，不能删东西。 String类常用的构造方法 String常用方法 正则表达式 String 中正则表达式相关的方法 StringBuffer 与 StringBuilder 可变长度字符串 这两个类是专门为频繁进行字符串拼接而准备的 StringBuffer是先出现的，Java5时新增了StringBuilder。StringBuffer是线程安全的，而StringBuilder效率更高。 两者底层都是byte[]数组，并且没有被final修饰，因此可以扩容。 优化策略：创建对象时预估好字符串的长度，给定一个合适的初始化容量，减少底层数组扩容的次数。 StringBuilder默认初始化容量：16 StringBuilder扩容策略：每次扩容为原来的两倍+2 为什么频繁拼接字符串时使用StringBuilder&#x2F;StringBuffer更好？ 使用“+”进行拼接，底层每次都会创建一个StringBuilder对象，然后再调用toString方法，10000次拼接就要创建10000次对象，同时给垃圾回收也造成了很大的压力。 而StringBuilder的append不创建新对象，直接在原来的位置进行拼接，且不调用toString方法，只有用print输出的时候才调用一次，因此节省了大量的时间。 包装类 包装类中的6个数字类型都继承了Number类 装箱boxing：将基本数据类型包装成引用数据类型 Integer i = new Integer(100); 拆箱：int num = i.intValue() Integer 常用方法 String、int、Integer 三者相互转换 自动装箱&#x2F;拆箱（JAVA5新特性）编译阶段的功能，底层仍然是之前的装箱&#x2F;拆箱。只是让你编程的时候方便一点。 自动装箱Integer x = 100; 自动拆箱int num = x; 整数型常量池[-128~127]这些数字太常用了，为了提高效率，Java提供了一个整数型常量池。 这个常量池是一个数组：Integer[ ] integerCache; 数组中存储了256个Integer的引用，只要没有超出这个范围的数字，直接从整数型常量池中取。 BigInteger大数字： 超过long了使用java.math.BigInteger 他的父类是Number 他是引用数据类型 常用方法： BigDecimal浮点型超过double就使用BigDecimal 构造方法：BigDecimal(String val) 常用方法： DecimalFormat该类是专门用来对数字进行格式化的。 常用数字格式： ###,###.## 三个数字为一组，组和组之间使用逗号隔开，保留两位小数 ###,###.0000 三个数字为一组，组和组之间使用逗号隔开，保留4位小数，不够补0 构造方法：DecimalFormat(String pattern) 常用方法：String format(数字) 日期相关API获取时间123456789// java.util.Date 日期API// 获取系统当前时间Date date = new Date() // 获取指定的时间Date date1 = new Date(输入毫秒数) //1970年0时0分0秒 + 输入的毫秒数 // 获取1970到当前的毫秒数,这是java.lang.System类的方法。long time = System.currentTimeMillis(); 日期格式化123456789import java.util.Date;import java.text.SimpleDateFormat;public class DateTest01&#123; public static void main(String[] args)&#123; SimpleDateFormat sdf = new SimpleDateFormat(输入格式的字符串) // 各种格式见文档 String str = sdf.format(输入要转换的时间) // 日期转格式化字符串 &#125;&#125; 将String转化成Date1234String strDate = &quot;2008-08-08 08:08:08 888&quot;;SimpleDateFormat sdf2 = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss SSS&quot;);Date date = sdf2.parse(strDate); // 用自己创建的格式去解析字符串中的日期 java.util.Calend ar 日历类获取当前时间的日历对象1Calendar c = Calendar.getInstance(); 获取日历中的某部分 修改日历中的内容 日历的新API（java8）日期传统的日期API存在线程安全问题，于是java8提供了一套全新的日期API 时间戳 计算时间间隔、日期间隔 时间矫正器 日期格式化 注意：这里使用LocalDateTime去调用parse方法，还需要把格式作为参数传入。 数学类 Math回顾：工具类的方法都是静态的，直接使用类名调用。 枚举类优点 可读性强 做了类型的限定，在编译阶段就可以确定类型是否正确，不正确会报错 定义123enum 枚举类型名 &#123; 枚举值1,枚举值2,枚举值3,枚举值4&#125; 特点： 高级用法 Random 随机数生成器 12Random random = new Random();int num = random.nextInt(101); // 生成一个[0,101)的随机数 System类 UUID 通用唯一标识符UUID是一种软件构建的标准，用来生成具有唯一性的ID。 12UUID uuid = UUID.randomUUID();String s = uuid.toString(); 七、集合集合概述 集合是一种容器，用来组织和管理数据。 Java的集合框架对应的这套类库其实就是对各种数据结构的实现。 集合存储的是引用。 默认情况下，如果不使用泛型，集合中可以存储任何类型的引用。 Java集合框架分为两部分： Collection结构：元素以单个的形式存储 Map结构：元素以键值对的映射关系存储 Collection 关系图 Collection接口的通用方法 Collection的通用遍历&#x2F;迭代方式面向接口编程 1234567891011Collection col = new ArrayList();// 第一步：获取集合的迭代器对象Iterator it = col.iterator();// 第二步：判断光标当前指向的位置是否有元素while(it.hasNext())&#123; // 第三步：光标返回当前指向的内容，并移动到下一个元素 Object obj = it.next(); System.out.println(obj);&#125; SequencedCollection接口所有的有序集合都实现了SequencedCollection接口 泛型 java5新特性，是编译阶段的功能。 泛型初体验 程序编写时看帮助文档中是否有”&lt;&gt;”符号，如果有这个符号就可以使用泛型。 创建一个集合，要求这个集合中只能存放某种类型的对象，就可以使用泛型 12345678Collection&lt;User&gt; users = new ArrayList&lt;User&gt;();Iterator&lt;User&gt; it = users.iterator();while(it.hasNext())&#123; User user = it.next(); user.pay()&#125;// 如果不用泛型，it.next()返回的类型是Object，还需要向下转型才能使用子类独有的方法。而使用了泛型后，迭代器返回的类型就自动向下转型为子类了。 泛型的作用 钻石表达式 （Java7新特性）1Collection&lt;User&gt; users = new ArrayList&lt;&gt;() // 后面尖括号中的内容可以省略 泛型擦除与补偿（了解） 泛型的定义在类上自定义泛型12345678public class vip&lt;NameType, AgeType&gt;&#123; // 在声明类时写上泛型名称 public vip(NameType name, AgeType age)&#123; this.name = name; this.age = age; &#125; private NameType name; private AgeType age;&#125; 在类上定义的泛型，在静态方法中无法使用。（因为静态方法直接通过类名调用，此时还没有通过声明类的对象来指定泛型的类型。） 在静态方法上定义泛型123456789101112public class test&#123; public static &lt;T&gt; void print(T element)&#123; // 在使用前需要先定义泛型 System.out.println(element); &#125; public static void main(String[] args)&#123; String a = &quot;Hello World!&quot;; test.print(a); &#125;&#125; 在接口上定义泛型和类定义泛型差不多。 12345678910111213141516171819public interface MyCompare&lt;T&gt;&#123; public int compare(T element); &#125;// 第一种实现接口的方式：此时我已经知道泛型要用什么类型了public class Product implements MyCompare&lt;int&gt;&#123; @Override public int compare(int a)&#123; 比较的代码; &#125;&#125;// 第二种实现接口的方式：此时还不知道泛型用什么类型public class test&lt;T&gt; implements MyCompare&lt;T&gt;&#123; // 再给类定义一个泛型，然后等创建对象时再确定泛型的类型 @Override public int compare(T a)&#123; // 或者这个时候就不要用泛型了，直接把参数的类型写成 Object 比较的代码; &#125;&#125; 泛型的使用泛型通配符无限定通配符&lt;?&gt; 此处表示后面填写的泛型可以是任意数据类型。 上限通配符&lt;? extends Number&gt; 表示泛型必须为Number及其子类 下限通配符&lt;？ super Number&gt; 表示泛型必须为Number及其父类 集合的并发修改问题 fail-fast 机制 集合中设置了一个modCount属性，用来记录修改的次数，使用集合对象执行增删改的操作时，modCount就会自动加1。 获取迭代器对象时，会给迭代器对象初始化一个expectedModCount属性，并且将modCount的值赋值给expectedModCount。 即int expectedModCount = modCount; 当使用集合对象删除元素时，modCount会加1，但是迭代器中的expectedModCount没有加1。而当迭代起对象的next()方法执行时，会检测expectedModCount和modCount是否相等，如果不相等，就会抛出ConcurrentModificationException异常 而如果使用迭代起删除元素时，modCount和expectedModCount都会加1.这样next()方法在检测时就是相等的，不会出现异常。 注：即使没有使用多线程编程，但是用迭代器去遍历的同时使用集合去删除元素，这个行为将被认为并发修改。 所以，迭代集合时，要使用 迭代器对象.remove()，移除的是当前光标所执行的元素。 List 接口特点有序、可重复 常见的实现类 ArrayList 数组 Vector、Stack 数组（线程安全的） LinkedList 双向链表 List接口特有的方法 List特有的迭代方式 注：调用迭代器的remove和set方法的前提是之前调用了next或者previous方法获取了一个元素，remove和set是作用于之前获取的那个元素上的。 List接口使用Comparator排序回顾数组中自定义类型是如何排序的？ 所有自定义类型排序时必须指定排序规则，实现Comparable接口，并重写compareTo方法。 重写是override List集合的排序 default void sort(Comparator&lt;? super E&gt; c); sort方法需要一个参数：java.util.Comparator ，我们把它叫做比较器，它是一个接口。 如何给自定义类型指定比较规则？可以对Comparator提供一个实现类，并重写compare方法来指定比较规则 这个实现类也可以看采用匿名内部类的方式。 对数组的排序是在类里面重写比较规则，对List集合的排序是单独设定一个比较规则并在需要时使用。 ArrayList 类回顾：数组的优缺点优点数组在内存中是连续存储的，有下标就有偏移量，可以通过偏移量计算出对应元素的内存地址。检索效率高，时间复杂度O（1） 缺点 不能存储大数据（因为内存地址是连续的） 随机增删元素耗时很长 使用场景需要频繁检索元素，很少进行随机增删的情况。 ArrrayList扩容策略 当调用无参构造方法时，初始化容量为0。 当第一次调用add方法时，将ArrayList容量初始化为10个长度。 后续扩容时，底层会创建一个新的数组，然后使用数组拷贝。新数组的容量是原容量的1.5倍。 Vector 类（*不怎么使用了） LinkedList 双向链表类 栈 数据结构 队列 数据结构 入队：offer 出队：poll 三种Set map和set的关系 map是键值对，把键那一列单独拿出来，就是set集合。 Map Map 接口的常用方法 Map 集合的遍历方法一：获取Map集合的所有key，然后遍历每个key，通过key获取value12345678910111213Set&lt;Integer&gt; keys = maps.keySet();// 写法一Iterator&lt;Integer&gt; it = keys.iterator();while(it.hasNext())&#123; Integer key = it.next(); System.out.println(key + &quot;=&quot; + maps.get(key))&#125;// 写法二for(Integer key : keys)&#123; System.out.println(key + &quot;=&quot; + maps.get(key))&#125; 方法二：获取Map的内部类Map.Entry (效率更高，常用这个)不需要再通过key去找value了 12345678910111213Set&lt;Map.Entry&lt;Integer,String&gt;&gt; entries = maps.entrySet();// 写法一Iterator it = entries.iterator();while(it.hasNext())&#123; Map.Entry&lt;Integer,String&gt; entry = it.next(); System.out.println(entry.getKey() + &quot;=&quot; + entry.getValue());&#125;// 写法二for(Map.Entry&lt;Integer,String&gt; entry : entries)&#123; System.out.println(entry.getKey() + &quot;=&quot; + entry.getValue());&#125; HashMap哈希表存储原理 ！！hashCode和equals方法要同时重写使用equals的前提条件是两个元素计算得到的索引值是相同的，在同一个链表中。那么保证这两个元素使用hashCode()返回的结果是相同的才能准确的保证索引值相同。 因此，存放在HashMap集合key部分的元素，以及存放在HashSet集合中的元素，需要同时重写hashCode和equals方法 HashMap在Java8后的改进初始化时机java8之前，构造方法执行初始化table数组 java8之后，第一次调用put方法时初始化table数组 插入方法java8之前：头插法 java8之后：尾插法 数据结构java8之前：数组+单向链表 java8之后：数组+单向链表&#x2F;红黑树 如果结点数量&gt;&#x3D;8，且table长度&gt;&#x3D;64，单向链表转为红黑树 当删除红黑树上的结点，使节点数量&lt;&#x3D;6时，红黑树转换为单向链表 HashMap的容量永远是2的次幂原因： 提高哈希计算的效率（位运算的效率比%取模运算效率高） 当length为2的次幂时,length-1的二进制低位全是1，此时hash &amp; (length - 1) 相当于 保留 hash 的低 n 位，结果与hash%length一致，使用位运算效率更高。 减少哈希冲突，让散列分布更加均匀 假设length是偶数，length-1结果一定是奇数，它的二进制中的最后一位一定是1，和别人相与可能是0或1。如果length是奇数，length-1是偶数，那么二进制最后一位是0，和别人相与只能是0，那么最后table有一半都是空的，存不了东西。 HashMap的初始化容量设置 当哈希表中的元素越来越多时，散列碰撞的几率就会越来越高，导致单链表过长，降低了哈希表的性能，此时要进行哈希表扩容 而一旦进行扩容，由于length改变，所有元素的hash值都会改变，效率比较低，所以在初始化的时候最好设置好数组大小，避免过多次数的扩容。 扩容时间点：当哈希表中的元素个数超过数组大小*0.75后进行扩容，新数组大小为2*原数组大小 LinkedHashMap LinkedHashMap是HashMap集合的子类 用法和HashMap几乎一样 只不过LinkedHashMap可以保证元素的插入顺序 底层数据结构：哈希表+双向链表（记录顺序） Hashtable（效率低，不常用） Properties 属性类 TreeMap排序二叉树按照左小右大存储，按照中序遍历自动得到升序排列的元素。 缺点：如果插入的节点集本来就是有序的，那么最后得到的二叉树其实就是一个普通链表，检索效率很差。 平衡二叉树 红黑二叉树一棵自平衡的排序二叉树 构造方法一个是没有参数的，一个是需要传比较器的 put() 方法先调用比较器，如果比较器是NULL，就使用类中的compareTo方法进行比较。 因此有两种方式来修改比较方法。 法一：实现Comparable&lt;&gt;接口，并重写compareTo方法 适用于比较规则不会改变的情况，比如数字、字符串的比较 法二：再写一个类去实现Comparator&lt;&gt;接口，重写compare方法，在创建对象时将比较器传递给TreeMap 适用于比较规则会改变的情况 总结：哪些集合不能添加NULL Hashtable的key、value Properties的key、value TreeMap的key ​ -&gt; TreeSet不能添加null Collections 工具类 八、IO流IO流概述分类根据流向分输入流（read）、输出流（write） 根据读写数据的形式分 字节流：一次读取一个字节。适合读取非文本数据，比如图片、音频、视频等。 字符流：一次读取一个字符。只适合读取普通文本，不适合读取二进制文件。因为字符流统一使用Unicode编码，可以避免出现编码混乱的问题。 根据流在IO操作中的作用和实现方式分 节点流：负责数据源和数据目的地的连接，是IO中最基本的组成部分。 处理流：处理流对节点流进行装饰&#x2F;包装，提供更多高级处理操作，方便用户进行数据处理。 IO流体系结构 InputStream 字节输入流 OutputStream 字节输出流 Reader 字符输入流 Writer 字符输出流 所有流都实现了Closable接口，都有close()方法，流用完要关闭。 所有的输出流都实现了Flushable，都有flush()方法，flush方法的作用是，将缓存全部写出并清空。 FileInputStream 类称为文件字节输入流，是一个万能流，任何文件都能读，但还是建议读二进制文件，例如图片、声音、视频。 常用构造方法FileInputStream(String name)通过文件路径构建一个文件字节输入流对象。 注意: 反斜杠需要使用转义字符，即两个反斜杠 \\\\ 也可使用一个正的斜杠 / 使用方法int read();调用一次read()方法就读取一个字节，返回读到的字节本身。如果读不到任何数据则返回-1 int read(byte[] b);一次最多可以读到b.length个字节（只要文件内容足够多），返回值是读取到的字节数。读取的内容存在b数组中。 int read(byte[] b, int off, int len);一次读取len个字节，将读到的数据从byte数组的off位置开始放 long skip(long n);跳过n个字节 int available();获取流中剩余的预估计字节数。 可以用这个初始化数组长度，这样就不需要使用循环来判断是否还有可读取的内容。 void close()；关闭流 FileOutputStream文件字节输出流，负责写。 常用构造方法 FileOutputStream(String name) 创建一个文件字节输出流对象，这个流在使用时，会先将原文件内容全部清空，然后写入。 FileOutputStream(String name, boolean append) ​ 创建一个文件字节输出流对象，当append是true时，不会清空原文件的内容，在原文件末尾追加。 ​ 当append是false时，会清空原文件的内容，在原文件末尾追加。 常用方法void close();void flush();刷新 void write(int b);写一个字节 void write(byte[] b);将整个byte字节数组写入 void write(byte[] b, int off, int len);将byte字节数组的一部分写入 TryWithResources 资源自动关闭 Java7新特性凡是实现了AutoCloseable接口的流都可以使用try-with-resources，都会自动关闭。 格式： 123456789try( 声明流; 声明流; 声明流; 声明流)&#123; // 最后一个不用写分号 &#125;catch()&#123; &#125; FileReader 读取普通文本 FileWriter 注意：只能复制普通文本文件！！！ 路径绝对路径、相对路径、类路径 12String path = Thread.currentThread().getContextClassLoader().getResource(&quot;filename&quot;).getPath();System.out.println(path); Thread.currentThread() 获取当前线程 Thread.currentThread().getContextClassLoader() 获取当前线程的类加载器 getResource(&quot;filename&quot;) 从类的根路径下开始加载资源 src文件夹是类路径的根路径 优点：通用，在进行系统移植的时候，仍然可以使用。 注：这种方式只能从类路径中加载资源，如果这个资源在类路径之外，就无法访问到。 BufferedInputStream&#x2F;BufferedOutputStream对缓冲流的理解 使用 1️⃣为什么这里仍然需要使用数组呢？ 这个数组是接收缓冲区中的大数组中的内容，它本身不和文件进行交互。 标记mark() 在当前位置打上标记 reset() 回到上一次打标记的位置 一个文件中最多只有一个标记 调用顺序：先调用mark，再调用reset 如何解决乱码问题 所有输入输出底层都需要使用字节流，而字符流是将字节流包装后得到的。进行了这种包装操作的流叫包装流。 使用InputStreamReader&#x2F;OutputStreamWriter时可以指定解码的字符集。 常用构造方法： InputStreamReader(InputStream in) 采用平台默认的字符集进行解码 InputStreamReader(InputStream in, String charsetName) 采用指定的字符集进行解码 FileReader是InputStreamReader的子类，是一个包装流。 ​ FileWriter同理。 InputStreamReader&#x2F;OutputStreamWriter 的创建需要传入字节流，而FileReader&#x2F;FileWriter 的创建直接输入文件地址即可。 数据流 将java程序中的数据直接写入文件，写进去就是二进制。 效率很高——写的过程不用转码 DataOutputStream写到文件中的数据，只能由DataInputStream来读取 读取顺序必须按照写入顺序！ 123456789101112131415161718// 写入DataOutputStream dos = new DataOutputStream(new FileOutputStream(&quot;filename&quot;)); byte b1 = 127;short s1 = 222;dos.writeByte(b1);dos.writeShort(s1);dos.flush();dos.close();// 读取DataInputStream dis = new DataInputStream(new FileInputStream(&quot;filename&quot;)); byte b2 = dis.readByte();short s2 = dis.readShort();dis.close(); 对象的序列化与反序列化序列化：将对象变成二进制文件 1234567ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;filename&quot;));Date nowDate = new Date();// 序列化Serialoos.writeObject(nowTime); oos.flush();oos.close(); 反序列化：将字节序列转换成JVM中的java对象 1234ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;filename&quot;));//反序列化Object o = ois.readObject(); // 如果明确知道对象的类型，可以强转。ois.close(); 如果是多个对象，那就把这些对象放在集合中。 要参与序列化与反序列化的对象，必须实现 java.io.Serializable 接口。该接口是一个标志接口，没有任何方法。 ObjectOutputStream也有关于数据输出的方法，比如writeInt()、writeBoolean()等，和DataOutputStream中的方法一样。 序列化版本号 为了保证序列化的安全，只有同一个类的对象才能序列化和反序列化。在java中 通过 类名 + 序列化版本号（serialVersionUID）来判断。 当类的内容修改后，serialVersionUID会改变，java程序不允许序列化版本号不同的类进行反序列化。 那如果几个月后，对这个类进行了升级，增加了一些内容怎么办？ ​ 如果确定这个类确实是之前的那个类，类本身是合法的，可以将序列化版本号写死。 1private static final long serialVersionUID = 1231231231231L; serial注解1234import java.io.Serial@Serial // 会自动检查下面的序列号代码是否拼错，在这里alt+回车可以自动生成一个序列号版本。private static final long serialVersionUID = 1231231231231L; transient关键字transient关键字修饰的属性不会参与序列化。 所以进行反序列化的时候这个属性会赋默认值。 打印流 PrintStream&#x2F;PrintWriterPrintStream主要用于打印，提供便携的打印方法和格式化输出。主要打印内容到文件或控制台。 不需要手动刷新。 构造方法PrintStream(OutputStream out); PrintStream(String filename); 常用方法print(Type x); println(Type x); PrintWriter比PrintStream多一个构造方法：PrintWriter(Writer); 标准输入流 System.in用来接收用户在控制台上的输入。 12345678InputStream in = System.in;byte[] bytes = new byte[1024];int readCount = in.read(bytes);for(int i = 0; i &lt; readCount; i++)&#123; System.out.println(bytes[i]); // 这个是逐个输出每个字节的内容，不适合中文等内容&#125; 对于标准输入流来说，也可以改变数据源。不让其从控制台读数据，而是从文件中&#x2F;网络中读取数据。 12345678910// 修改标准输入流的数据源System.setIn(new FileInputStream(&quot;filename&quot;));InputStream in = System.in;byte[] bytes = new byte[1024];int readCount = 0;while((readCount = in.read(bytes)) != -1)&#123; System.out.print(new String(bytes,0,readCount));&#125; 标准输出流 System.out用于输出内容到控制台。 改变输出方向：(常用于记录日志) 123System.setOut(new PrintStream(&quot;filename&quot;));System.out.println(&quot;zhangsan&quot;); File类文件&#x2F;目录的抽象表示形式。 构造方法1234567891011121314151617File file = new File(&quot;e:/filename&quot;);// 如果不存在就以新文件的形式创建if(!file.exists())&#123; file.createNewFile();&#125;// 如果不存在就以目录的形式创建if(!file.exists())&#123; file.mkdir();&#125;// 如果不存在就创建多层文件夹File file2 = new File(&quot;e:/a/b/c/d&quot;);if(!file2.exist())&#123; file2.mkdirs();&#125; 常见方法见文档。12345678File file = new File(&quot;e:/directoryAddress&quot;);File[] files = file.listFiles() // 直接获取所有文档File[] files2 = file.listFiles(new FilenameFilter())&#123; @Override public boolean accept(File dir, String name)&#123; return name.endsWith(&quot;.txt&quot;); // 进行判断，如果结果不是txt就返回false，就不选中这些文件 &#125;&#125; 读取属性配置文件 xxx.properties 文件称为属性配置文件 属性配置文件可以配置一些简单的信息，例如连接数据库的信息通常配置到属性文件中。这样可以做到在不修改java代码的前提下，切换数据库。 属性配置文件的格式: ​ key1 &#x3D; value1 ​ key2 &#x3D; value2 ​ … ​ 注：使用#进行注释，key不能重复，否则value会被覆盖。等号两边不能有空格。 1234567891011String path = Thread.currentThread().getContextClassLoader().getResource(&quot;filename&quot;).getPath();FileReader reader = new FileReader(path); // 创建一个Map集合（属性类对象） Properties pro = new Properties();// 将属性配置文件中的配置信息加载到Properties对象中。pro.load(reader) String driver = pro.getProperty(&quot;driver&quot;);String url = pro.getProperty(&quot;url&quot;); ResourceBundle进行资源绑定 装饰器设计模式符合OCP的情况下怎么完成对类功能的扩展？ 使用子类对父类进行方法扩展。但这种方法会导致两个问题：代码耦合度高、类爆炸问题（会有很多类） 装饰器设计模式：可以做到在不修改原有代码的基础上，完成功能扩展，符合OCP原则，并且避免了使用继承带来的类爆炸问题。 装饰器设计模式中涉及的角色： 抽象的装饰者 具体的装饰者1、具体的装饰者2 被装饰者 装饰者和被装饰者的公共接口&#x2F;公共抽象类 IO流中使用了大量的装饰器设计模式。 压缩流压缩流的使用12345678910111213141516171819202122232425public class GZIPOutputStreamTest &#123; public static void main(String[] args) throws Exception&#123; // 创建文件字节输入流（读某个文件，这个文件将来就是被压缩的。） FileInputStream in = new FileInputStream(&quot;e:/test.txt&quot;); // 创建一个GZIP压缩流对象 GZIPOutputStream gzip = new GZIPOutputStream(new FileOutputStream(&quot;e:/test.txt.gz&quot;)); // 开始压缩（一边读一边写） byte[] bytes = new byte[1024]; int readCount = 0; while((readCount = in.read(bytes)) != -1)&#123; gzip.write(bytes, 0, readCount); &#125; // 非常重要的代码需要调用 // 刷新并且最终生成压缩文件。 gzip.finish(); // 关闭流 in.close(); gzip.close(); &#125;&#125; 解压缩流的使用123456789101112131415161718192021public class GZIPInputStreamTest &#123; public static void main(String[] args) throws Exception &#123; // 创建GZIP解压缩流对象 GZIPInputStream gzip = new GZIPInputStream(new FileInputStream(&quot;e:/test.txt.gz&quot;)); // 创建文件字节输出流 FileOutputStream out = new FileOutputStream(&quot;e:/test.txt&quot;); // 一边读一边写 byte[] bytes = new byte[1024]; int readCount = 0; while((readCount = gzip.read(bytes)) != -1)&#123; out.write(bytes, 0, readCount); &#125; // 关闭流 gzip.close(); // 节点流关闭的时候会自动刷新，包装流是需要手动刷新的。 out.close(); &#125;&#125; 注：节点流关闭时会自动刷新，包装流需要手动刷新。 字节数组流 ByteArrayInputStream、ByteArrayOutputStream都是内存操作流，不需要打开和关闭文件等操作。这些流是非常常用的，可以将它们看作开发中的常用工具，能够方便地读写字节数组、图像数据等内存中的数据。 都是节点流。 使用对象流装饰字节数组流！！为什么要这样做？ 你使用字节数组流直接写入、读出可能只能读取普通的字节数组，还需要自己实现一些转换成复杂类型（各种类）的方法，而包装流已经在内部包含了很多将复杂类型序列化的方法，一行代码就可以帮你直接序列化复杂类型然后写入字节流。 对象深克隆目前为止对象拷贝方式： 调用Object的clone方法，默认是浅克隆，需要深克隆的话，就需要重写clone方法 可以通过序列化和反序列化完成对象的克隆（深克隆） 123456789101112131415161718192021222324252627public class DeepCloneTest &#123; public static void main(String[] args) throws Exception&#123; // 准备对象 Address addr = new Address(&quot;北京&quot;, &quot;朝阳&quot;); User user = new User(&quot;zhangsan&quot;, 20, addr); // 将Java对象写到一个byte数组中。 ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(user); oos.flush(); // 从byte数组中读取数据恢复java对象 ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bais); // 这就是那个经过深拷贝之后的新对象 User user2 = (User) ois.readObject(); user2.getAddr().setCity(&quot;南京&quot;); System.out.println(user); System.out.println(user2); &#125;&#125; 九、多线程概述多线程 进程：操作系统中的一段程序，具有独立的内存空间和系统资源，如文件、网络端口等。在计算机程序执行时，先创建进程，再在进程中进行程序的执行。 线程：进程中的一个执行单元。每个线程都有自己的栈和程序计数器，并且可以共享进程的资源。多个线程可以在同一时刻执行不同操作，提高程序的执行效率。一个进程可以有多个线程。 静态变量、实例变量是在堆中的，所以是共享的。 并发使用单核CPU时，同一时刻只能有一条指令执行，但多个指令被快速的轮换执行，使得在宏观上具有多个指令同时执行的效果。 并行多核CPU，同一时刻，多条指令在多个CPU上同时执行。（无论微观还是宏观） 并发与并行 CPU比较繁忙时，如果开启了多个线程，则只能为一个线程分配仅有的CPU资源，多线程会竞争CPU资源。 在CPU资源比较充足时，一个进程内的多个线程可以被分配到不同的CPU资源，实现并行。 多线程实现的是并发还是并行？如上所述，看运行时CPU的资源，都有可能。 线程的调度模型多个线程抢夺一个CPU内核的执行权，需要线程调度策略。 分时调度模型所有线程轮流使用CPU的执行权，并且平均分配每个线程占用的CPU时间 抢占式调度模型让优先级高的线程以较大的概率优先获得CPU的执行权，如果线程的优先级相同，那么就随机选择一个线程获得CPU的执行权。 JAVA采用的就是抢占式调度。 实现多线程的方法第一种 编写一个类继承java.lang.Thread 重写run方法 new线程对象 调用线程对象的start()方法来启动线程 1234567891011121314public class ThreadTest&#123; public static void main(String[] args)&#123; MyThread mt = new MyThread(); mt.start(); &#125;&#125;class MyThread extends Thread&#123; @Override public void run()&#123; 多线程执行的内容; &#125;&#125; start方法的任务是启动一个新线程，分配一个新的栈空间就结束了。 java永远满足一个语法规则：必须自上而下依次逐行运行。 第二种 编写一个类实现java.lang.Runnable接口 实现接口中的run方法 （此处不能thorws异常） new线程对象（把实现Runnable接口的类传给Thread构造方法） 调用线程对象的start()方法来启动线程 这种方式更好，因为以后还可以继承别的类。而第一种已经使用掉继承一个类的名额了。 12345678910111213public class ThreadTest&#123; public static void main(String[] args)&#123; Thread t = new Thread(new MyRunnable()); t.start(); &#125;&#125;class MyRunnable implements Runnable&#123; @Override public void run()&#123; 多线程执行的内容; &#125;&#125; 这种方式还可以使用匿名内部类： 1. 1234567891011public class ThreadTest&#123; public static void main(String[] args)&#123; Thread t = new Thread(new Runnable()&#123; @Override public void run()&#123; 多线程执行的内容; &#125; &#125;); t.start(); &#125;&#125; ​ 2. 1234567891011public class ThreadTest&#123; public static void main(String[] args)&#123; new Thread(new Runnable()&#123; @Override public void run()&#123; 多线程执行的内容; &#125; &#125;).start(); &#125;&#125; 线程常用的三个方法 String getName()； 获取线程对象的名字 void setName(String threadName); 修改线程的名字 static Thread currentThread(); 获取当前线程对象的引用 除了使用setName修改线程的名字，还可以使用有参构造方法。但是需要在类中实现这个有参构造方法。 123public MyThread(String threadName)&#123; super(threadName);&#125; 线程生命周期的7个状态 新建状态 NEW 就绪状态 运行状态 （2-3 官方统称为可运行状态RUNNABLE） 超时等待状态 TIMED_WAITING 等待状态 WAITING 阻塞状态 BLOCKED 终止状态 TERMINATED 线程的休眠Thread.sleep(毫秒数); 在规定的时间内，当前线程没有权利抢夺CPU时间片了。 中断线程的休眠 interrupt()是一个实例方法。 线程对象.interrupt();可以中断线程的休眠。（当然要放在另一个线程里使用才能起作用） 底层原理是利用了异常处理机制。 当调用这个方法的时候，如果t线程正在睡眠，必然会抛出：InterrupttedException，然后捕捉异常，终止睡眠。 停止运行线程线程对象.stop() 已经不建议使用 一般是设置一个标记，然后在线程的循环中使用if语句判断这个标记。 比如 boolean run &#x3D; true; 当达到某个条件后将run改为false，然后if(run){ 运行的内容 } else{return;} return后就终止这个线程了。 守护线程在java中，线程被分为两类：守护线程、用户线程 所有用户线程结束后，守护线程自动退出&#x2F;结束。 在JVM中，有一个隐藏的守护线程一直在守护着，它就是GC线程。 将线程设置为守护线程： 线程对象.setDaemon(true); 定时任务java.util.Timer 定时器 java.util.TimerTask 定时任务 123456789101112131415161718// 创建定时器对象（本质上就是一个线程）Timer timer = new Timer(true); // 这里的true表示设置为守护线程// 指定定时任务SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);Date firstTime = sdf.parse(&quot;2024-01-27 10:22:00&quot;);// 匿名内部类的方式timer.schedule(new TimerTask() &#123; int count = 0; @Override public void run() &#123; // 执行任务 Date now = new Date(); String strTime = sdf.format(now); System.out.println(strTime + &quot;: &quot; + count++); &#125;&#125;,firstTime,1000*5) 线程合并join() 方法是一个实例方法 t.join() 是让当前线程进入阻塞状态，直到t线程结束，当前线程的阻塞状态结束。 个人理解：就是先让t线程打断当前线程自己运行，如果设置的时间结束或者t线程在时间结束前已经运行完了，那当前线程就继续执行。 线程优先级最低1(Thread.MIN_PRIORITY)，最高10(Thread.MAX_PRIORITY) t.setPriority(传入优先级数值) 让位静态方法：Thread.yield() 让当前线程让位。让位不会让其进入阻塞状态，只是放弃当前占有的CPU时间片，进入就绪状态，继续抢夺CPU时间片。 线程安全问题什么情况下需要考虑线程安全问题？ 多线程并发 有共享的数据 共享数据涉及修改操作 一般情况下局部变量不存在线程安全问题。（尤其是基本数据类型，但如果是引用数据类型就另说了。） 实例变量、静态变量可能存在线程安全问题。他们存放在堆中，堆是多线程共享的。 线程同步机制——互斥锁线程排队执行 现有t1和t2线程，t1线程在执行的时候必须等待t2线程执行到某个位置之后，t1线程才能执行。 123synchronized(obj)&#123; // obj为共享对象，在银行取款的例子中，这个共享对象就是账户 // 同步代码块&#125; 假设t1先抢到了CPU时间片，t1线程找到共享对象obj的对象锁后占有这把锁，t2只能在同步代码块之外等待，等t1线程执行完同步代码块之后，才会释放之前占有的对象锁。 synchronized又被称为互斥锁。 synchronized也可以作为标识符直接写在方法（实例方法、静态方法）声明上， 静态方法检测的是类锁，实例方法检测的是对象锁。 线程异步机制线程并发执行 各自执行各自的，谁也不需要等对方。 效率高但可能存在安全隐患。 线程通信涉及到的三个方法：wait()、notify()、notifyAll() 以上三个方法都是Object类的方法。 调用wait方法和notify方法是通过共享对象去调用的。 例如：obj.wait()的效果：在obj对象上活跃的所有线程进入无期限等待，直到调用了该共享对象的notify方法进行唤醒，唤醒后会接着上一次调用wait方法的位置继续执行。 obj.wait() 调用后会释放之前占用的对象锁。 obj.notify() 唤醒优先级最高的等待线程，如果优先级一样，就随机唤醒一个。 obj.notifyAll() 唤醒所有在该共享对象上等待的线程 最完整的生命周期 懒汉式单例模式的线程安全问题123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151class SingletonTest &#123; // 静态变量 private static Singleton s1; private static Singleton s2; public static void main(String[] args) &#123; // 获取某个类。这是反射机制中的内容。 /*Class stringClass = String.class; Class singletonClass = Singleton.class; Class dateClass = java.util.Date.class;*/ // 创建线程对象t1 Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; s1 = Singleton.getSingleton(); &#125; &#125;); // 创建线程对象t2 Thread t2 = new Thread(new Runnable() &#123; @Override public void run() &#123; s2 = Singleton.getSingleton(); &#125; &#125;); // 启动线程 t1.start(); t2.start(); try &#123; t1.join(); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; try &#123; t2.join(); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; // 判断这两个Singleton对象是否一样。 System.out.println(s1); System.out.println(s2); System.out.println(s1 == s2); &#125;&#125;/** * 懒汉式单例模式 */public class Singleton &#123; private static Singleton singleton; private Singleton() &#123; System.out.println(&quot;构造方法执行了！&quot;); &#125; // 非线程安全的。 /*public static Singleton getSingleton() &#123; if (singleton == null) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; singleton = new Singleton(); &#125; return singleton; &#125;*/ // 线程安全的：第一种方案（同步方法），找类锁。 /*public static synchronized Singleton getSingleton() &#123; if (singleton == null) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; singleton = new Singleton(); &#125; return singleton; &#125;*/ // 线程安全的：第二种方案（同步代码块），找的类锁 /*public static Singleton getSingleton() &#123; // 这里有一个知识点是反射机制中的内容。可以获取某个类。 synchronized (Singleton.class)&#123; if (singleton == null) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; singleton = new Singleton(); &#125; &#125; return singleton; &#125;*/ // 线程安全的：这个方案对上一个方案进行优化，提升效率。 /*public static Singleton getSingleton() &#123; if(singleton == null)&#123; synchronized (Singleton.class)&#123; if (singleton == null) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;*/ // 使用Lock来实现线程安全 // Lock是接口，从JDK5开始引入的。 // Lock接口下有一个实现类：可重入锁（ReentrantLock） // 注意：要想使用ReentrantLock达到线程安全，假设要让t1 t2 t3线程同步，就需要让t1 t2 t3共享同一个lock。 // Lock 和 synchronized 哪个好？Lock更好。为什么？因为更加灵活。synchronized代码块的大括号必须包住所有语句，而unlock()可以任意插入到一些语句中，但一定要记得执行unlock() private static final ReentrantLock lock = new ReentrantLock(); public static Singleton getSingleton() &#123; if(singleton == null)&#123; try &#123; // 加锁 lock.lock(); if (singleton == null) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; throw new RuntimeException(e); &#125; singleton = new Singleton(); &#125; &#125; finally &#123; // 解锁（需要100%保证解锁，怎么办？finally） lock.unlock(); &#125; &#125; return singleton; &#125;&#125; Lock 和 synchronized 哪个好？ Lock更好，因为更加灵活。synchronized代码块的大括号必须包住所有语句，而unlock()可以任意插入到一些语句中，但一定要记得执行unlock() 创建线程的第三种方法——未来任务优点：可以拿到线程执行结束的返回值 123456789101112131415161718192021222324252627// 创建“未来任务”对象 FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; // 处理业务...... Thread.sleep(1000 * 5); return 1; &#125; &#125;); // 创建线程对象 Thread t = new Thread(task); t.setName(&quot;t&quot;); // 启动线程 t.start(); try &#123; // 获取“未来任务”线程的返回值 // 阻塞当前线程，等待“未来任务”结束并返回值。 // 拿到返回值，当前线程的阻塞才会解除。继续执行。 Integer i = task.get(); System.out.println(i); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 创建线程的第四种方式——线程池服务器启动时，创建N个线程对象，直接放到线程池中，需要的时候把任务交给线程池即可。 123456789101112131415// 创建一个线程池对象（线程池中有3个线程） ExecutorService executorService = Executors.newFixedThreadPool(3); // 将任务交给线程池（你不需要触碰到这个线程对象，你只需要将要处理的任务交给线程池即可。） executorService.submit(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.println(Thread.currentThread().getName() + &quot;---&gt;&quot; + i); &#125; &#125; &#125;); // 最后记得关闭线程池 executorService.shutdown(); 十、反射 reflect概述 后续学的大量java框架都是基于反射机制实现的。 反射机制可以让程序更加灵活 反射机制最核心的几个类： ​ java.lang.Class : Class类型的实例代表硬盘上某个class文件，或者说代表某一种类型 ​ java.lang.reflect.Filed : 实例代表类中的属性&#x2F;字段 ​ java.lang.reflect.Constructor : 它的实例代表类中的构造方法 ​ java.lang.reflect.Method : 它的实例代表类中的方法 获取Class的四种方式第一种Class c = Class.forName(&quot;完整的全限定类名&quot;); 注： 全限定类名是带有包名的，不可省略 这是个字符串参数 如果这个类根本不存在，会报异常：java.lang.ClassNotFoundException 这个方法的执行会导致类的加载动作的发生 第二种Class c = obj.getClass(); 第三种Class c = 类名.class; 第四种——使用类加载器123ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();Class&lt;?&gt; aClass = systemClassLoader.loadClass(&quot;完整的全限定类名&quot;) Class.forName() 和 classLoader.loadClass() 的区别： ​ Class.forName() ：类加载时会进行初始化（静态变量赋值、静态代码块执行）。 ​ classLoader.loadClass()：类加载时不会进行初始化，直到第一次使用该类。 通过反射机制实例化对象直接对类使用newInstance方法123Class userClass = Class.forName(&quot;test.User&quot;);User user = (User)userClass.newInstance(); 使用反射机制，只要修改属性配置文件就可以完成不同对象的实例化。非常灵活 12345ResourceBundle bundle = ResourceBundle.getBundle(&quot;test.classInfo&quot;);String className = bundle.getString(&quot;className&quot;);Class classObj = Class.forName(className);Object obj = classObj.newInstance(); 使用这种方式必须要有一个无参数构造方法。如果没有会出现异常。 Java9时被标注已过时，不建议使用。 使用构造方法实例化对象无参构造： 12345Class userClass = Class.forName(&quot;test.User&quot;);// 获取无参数构造方法Constructor defaultCon = userClass.getDeclaredConstructor();// 通过无参数构造方法实例化对象Object obj = defaultCon.newInstance(); 有参构造： 1234Class userClass = Class.forName(&quot;test.User&quot;);// 获取有参构造方法Constructor threeArgsCon = userClass.getDeclaredConstructor(String.class, double.class, String.class); // 根据参数的类型，写上对应的类Object obj = threeArgsCon.newInstance(&quot;001215&quot;, 698.5, &quot;未完成&quot;); 通过反射为对象属性赋值123456789101112131415161718192021Class clazz = Class.forName(&quot;com.powernode.javase.reflect.Customer&quot;); // 获取对应的Field Field ageField = clazz.getDeclaredField(&quot;age&quot;); // 调用方法打破封装（原来类里设置的age是private） ageField.setAccessible(true); // 修改属性的值 // 给对象属性赋值三要素：给哪个对象 的 哪个属性 赋什么值 ageField.set(customer, 30); // 读取属性的值 System.out.println(&quot;年龄：&quot; + ageField.get(customer)); // 通过反射机制给name属性赋值，和读取name属性的值 Field nameField = clazz.getDeclaredField(&quot;name&quot;); // 修改属性name的值 nameField.set(customer, &quot;李四&quot;); // 读取属性name的值 System.out.println(nameField.get(customer)); 反射某一个类的方法类加载的过程 虚拟机的三个类加载器 12345678910111213141516171819// 通过自定义的类获取的类加载器是：应用类加载器。ClassLoader appClassLoader = ReflectTest15.class.getClassLoader();System.out.println(&quot;应用类加载器：&quot; + appClassLoader);// 获取应用类加载器ClassLoader appClassLoader2 = ClassLoader.getSystemClassLoader();System.out.println(&quot;应用类加载器：&quot; + appClassLoader2);// 获取应用类加载器ClassLoader appClassLoader3 = Thread.currentThread().getContextClassLoader();System.out.println(&quot;应用类加载器：&quot; + appClassLoader3);// 通过 getParent() 方法可以获取当前类加载器的 “父 类加载器”。// 获取平台类加载器。System.out.println(&quot;平台类加载器：&quot; + appClassLoader.getParent());// 获取启动类加载器。// 注意：启动类加载器负责加载的是JDK核心类库，这个类加载器的名字看不到，直接输出的时候，结果是null。System.out.println(&quot;启动类加载器：&quot; + appClassLoader.getParent().getParent()); 双亲委派机制 某个类加载器接收到加载类的任务时，通常委托给“父 类加载器”进行加载 最大的“父 类加载器”无法加载时，一级一级向下委托加载任务 作用： 保护程序的安全 防止类加载重复 获取泛型获取父类的泛型1234567891011121314151617181920// 获取类 Class&lt;Cat&gt; catClass = Cat.class; // 获取当前类的父类泛型 Type genericSuperclass = catClass.getGenericSuperclass(); //System.out.println(genericSuperclass instanceof Class); //System.out.println(genericSuperclass instanceof ParameterizedType); // 如果父类使用了泛型 if(genericSuperclass instanceof ParameterizedType)&#123; // 转型为参数化类型 ParameterizedType parameterizedType = (ParameterizedType) genericSuperclass; // 获取泛型数组 Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); // 遍历泛型数组 for(Type a : actualTypeArguments)&#123; // 获取泛型的具体类型名 System.out.println(a.getTypeName()); &#125; &#125; 获取接口的泛型123456789101112131415161718192021222324public class Test &#123; public static void main(String[] args) &#123; Class&lt;Mouse&gt; mouseClass = Mouse.class; // 获取接口上的泛型 类可以单继承、多实现，因此实现一个接口算一个Type，实现多个接口就需要数组了。每个接口上的泛型就是一个Type Type[] genericInterfaces = mouseClass.getGenericInterfaces(); for (Type g : genericInterfaces) &#123; // 使用了泛型 if(g instanceof ParameterizedType)&#123; ParameterizedType parameterizedType = (ParameterizedType) g; Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); for(Type a : actualTypeArguments)&#123; System.out.println(a.getTypeName()); &#125; &#125; &#125; &#125;&#125;public class Mouse implements Flyable&lt;String, Integer&gt;, Comparable&lt;Mouse&gt;&#123; @Override public int compareTo(Mouse o) &#123; return 0; &#125;&#125; 获取属性上的泛型12345678910111213141516171819202122public class User &#123; private Map&lt;Integer, String&gt; map;&#125;public class Test &#123; public static void main(String[] args) throws Exception&#123; // 获取这个类 Class&lt;User&gt; userClass = User.class; // 需要先获取属性 Field mapField = userClass.getDeclaredField(&quot;map&quot;); // 获取公开的以及私有的 // 获取属性上的泛型 Type genericType = mapField.getGenericType(); // 用泛型了 if(genericType instanceof ParameterizedType)&#123; ParameterizedType parameterizedType = (ParameterizedType) genericType; Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); for(Type a : actualTypeArguments)&#123; System.out.println(a.getTypeName()); &#125; &#125; &#125;&#125; 获取方法参数、返回值上的泛型12345678910111213141516171819202122232425262728293031323334353637383940public class MyClass &#123; public Map&lt;Integer, Integer&gt; m(List&lt;String&gt; list, List&lt;Integer&gt; list2)&#123; return null; &#125;&#125;public class Test &#123; public static void main(String[] args) throws Exception&#123; // 获取类 Class&lt;MyClass&gt; myClassClass = MyClass.class; // 获取方法 Method mMethod = myClassClass.getDeclaredMethod(&quot;m&quot;, List.class, List.class); // 获取方法参数上的泛型 Type[] genericParameterTypes = mMethod.getGenericParameterTypes(); for(Type g : genericParameterTypes)&#123; // 如果这个参数使用了泛型 if(g instanceof ParameterizedType)&#123; ParameterizedType parameterizedType = (ParameterizedType) g; Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); for(Type a : actualTypeArguments)&#123; System.out.println(a.getTypeName()); &#125; &#125; &#125; // 获取方法返回值上的泛型 Type genericReturnType = mMethod.getGenericReturnType(); if(genericReturnType instanceof ParameterizedType)&#123; ParameterizedType parameterizedType = (ParameterizedType) genericReturnType; Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); for(Type a : actualTypeArguments)&#123; System.out.println(a.getTypeName()); &#125; &#125; &#125;&#125; 获取构造方法函数上的泛型1234567891011121314151617181920212223public class User &#123; public User(Map&lt;String ,Integer&gt; map)&#123; &#125;&#125;public class Test &#123; public static void main(String[] args) throws Exception&#123; Class&lt;User&gt; userClass = User.class; Constructor&lt;User&gt; con = userClass.getDeclaredConstructor(Map.class); Type[] genericParameterTypes = con.getGenericParameterTypes(); for(Type g :genericParameterTypes)&#123; if(g instanceof ParameterizedType)&#123; ParameterizedType parameterizedType = (ParameterizedType) g; Type[] actualTypeArguments = parameterizedType.getActualTypeArguments(); for(Type a : actualTypeArguments)&#123; System.out.println(a.getTypeName()); &#125; &#125; &#125; &#125;&#125; 十一、注解概述什么是注解？ JDK1.5引入 可以标注在类上、方法上、属性上、构造方法上、方法参数上等…… 注解可以做到在不改变代码逻辑的前提下在代码中嵌入补充信息 注解与注释注解：给编译器或者其他程序看的，程序根据注解来决定不同的处理方式 注释：给程序员看 框架框架 &#x3D; 反射 + 注解 + 设计模式 内置的注解@Deprecated用来标记过时的元素，在编译阶段遇到这个注解时会发出提醒警告，告诉开发者正在调用一个过时的元素比如过时的类、过时的方法、过时的属性等。 @Override修饰实例方法，则该方法必须是个重写方法，否则就会编译失败。 @SuppressWarnings（抑制警告的注解）在实际开发中，建议尽量不要忽略警告，而是真正的去解决警告。 @SuppressWarnings(“rawtypes”)：抑制未使用泛型的警告 @SuppressWarnings(“resource”)：抑制未关闭资源的警告 @SuppressWarnings(“deprecation”)：抑制使用了已过时资源时的警告 @SuppressWarnings(“all”)：抑制所有警告 @FunctionalInterface“函数式接口”的注解，这个是 JDK1.8 版本引入的新特性。使用@FunctionalInterface标注的接口，则该接口就有且只能存在一个抽象方法，否则就会发生编译错误。 （注意：接口中的默认方法或静态方法可以有多个。） 自定义注解如何自定义创建一个annotation类型的文件，在文件中写入注解的定义。 12public @interface MyAnnotation &#123;&#125; 注解中定义属性属性的类型只能是： byte，short，int，long，float，double，boolean，char String、Class、枚举类型、注解类型 以上所有类型的一维数组形式 12345678public @interface MyAnnotation &#123; String a; int b default 10; // 可以使用default语句指定默认值 int flag;&#125;//注解的使用@interface(a=&quot;test&quot;,flag=0) //带默认值的属性可以不在此赋值 如果属性只有一个，并且属性名是value，那使用注解的时候可以省略value这个属性名。 1234public @interface MyAnnotation &#123; String value;&#125;@interface(&quot;test&quot;) 如果属性是一个数组，使用注解时，数组值只有一个，数组的大括号可以省略。 12345public @interface MyAnnotation &#123; String[] value;&#125;@interface(&quot;test1&quot;)@interface(&#123;&quot;test1&quot;,&quot;test2&quot;&#125;) 元注解@Retention：设置注解的保持性注解存在阶段是保留在源代码（编译期），字节码（类加载）或者运行时（JVM中运行） @Retention(RetentionPolicy.SOURCE)：注解仅存在于源代码中，在字节码文件中不包含。 @Retention(RetentionPolicy.CLASS)：注解在字节码文件中存在，但运行时无法获得（默认）。 @Retention(RetentionPolicy.RUNTIME)：注解在字节码文件中存在，且运行时可通过反射获取。 @Target：设置注解可以使用的位置 @Target(ElementType.TYPE)：作用于接口、类、枚举、注解 @Target(ElementType.FIELD)：作用于属性、枚举的常量 @Target(ElementType.METHOD)：作用于方法 @Target(ElementType.PARAMETER)：作用于方法参数 @Target(ElementType.CONSTRUCTOR)：作用于构造方法 @Target(ElementType.LOCAL_VARIABLE)：作用于局部变量 @Target(ElementType.ANNOTATION_TYPE)：作用于注解 @Target(ElementType.PACKAGE)：作用于包 @Target(ElementType.TYPE_PARAMETER)：作用于泛型，即泛型方法、泛型类和泛型接口。 @Target(ElementType.TYPE_USE)：作用于任意类型。 @Documented：设置注解会被包含在API文档中使用javadoc.exe工具可以从程序源代码中抽取类、方法、属性等注释形成一个源代码配套的API帮助文档，而该工具抽取时默认不包括注解内容。如果注解被@Documented标注，那么就能被javadoc.exe工具提取到API文档。 @Inherited：被标注的注解支持继承使用后子类会继承父类的注解。 @Repeatable：设置后可以在一个地方重复使用同一注解（java8）@Repeatable(原注解的复数形式) 但是需要再声明一个原来注解的复数形式，并在其中包含原注解类型的数组。 123456789public class Test &#123; @Author(name = &quot;张三&quot;) @Author(name = &quot;李四&quot;) public void doSome()&#123; &#125;&#125; 123456789@Repeatable(Authors.class)public @interface Author &#123; /** * 作者的名字 * @return 作者的名字 */ String name();&#125; 12345public @interface Authors &#123; Author[] value();&#125; 反射注解获取类上的所有注解 ​ Annotation[] annotations = clazz.getAnnotations(); 获取类上指定的某个注解 ​ clazz.isAnnotationPresent(AnnotationTest01.class) ​ AnnotationTest01 an = clazz.getAnnotation(AnnotationTest01.class); 获取属性上的所有注解 ​ Annotation[] annotations = field.getAnnotations(); 获取属性上指定的某个注解 ​ field.isAnnotationPresent(AnnotationTest02.class) ​ AnnotationTest02 an = field.getAnnotation(AnnotationTest02.class); 获取方法上的所有注解 ​ Annotation[] annotations = method.getAnnotations(); 获取方法上指定的某个注解 ​ method.isAnnotationPresent(AnnotationTest02.class) ​ AnnotationTest02 an = method.getAnnotation(AnnotationTest02.class); 十二、网络编程概述网络编程的三个基本要素： IP地址：定位网络中的某台计算机 端口号port：定位计算机上的某个进程（某个应用） 通信协议：通过IP地址和端口号定位后，如何保证数据可靠高效的传输，就需要依靠通信协议。 IP地址 IPv4：4字节，xxx.xxx.xxx.xxx 每个xxx表示8位二进制数，范围是0-255 ​ 前三个字节用于表示网络（省市区），最后一个字节用于表示主机（家门牌号） ​ 一些IP地址被保留或者被私有机构使用，不能用于公网的地址分配；还有一些IP地址被用作多播地址，仅用于特定的应用场景。因此实际可以使用的IPv4地址少于总量。 IPv6：16字节，由8组十六进制数表示，如 3ffe:3201:1401:1280:c8ff:fd54:db39:1984 本机地址：127.0.0.1，主机名：localhost 192.168.0.0-192.168.255.255为私有地址，属于非注册地址，专门为组织、机构内部使用。（用于局域网） 端口号port用两个字节（无符号）表示的，取值范围0-65535，计算机端口号可以分为三大类： 公认端口：0-1023，被预先定义的服务通信占用（如http占用80，FTP占用21，Telnet占用23等） 注册端口：1024~49151。分配给用户进程或应用程序。（如：Tomcat占用端口8080，MySQL占用端口3306，Oracle占用端口1521等）。 动态&#x2F;私有端口：49152~65535。 通常情况下，服务器程序使用固定的端口号来监听客户端的请求，而客户端则使用随机端口连接服务器。 OSI参考模型 TCP&#x2F;IP参考模型 网络编程基础类InetAddress类 java.net.IntAddress类用来封装计算机的IP地址和DNS（没有端口信息），它包括一个主机名和一个IP地址，是java对IP地址的高层表示。大多数其它网络类都要用到这个类，包括Socket、ServerSocket、URL、DatagramSocket、DatagramPacket等 常用静态方法 static InetAddress getLocalHost() 得到本机的InetAddress对象，其中封装了IP地址和主机名 lstatic InetAddress getByName(String host) 传入目标主机的名字或IP地址得到对应的InetAddress对象，其中封装了IP地址和主机名（底层会自动连接DNS服务器进行域名解析） 常用实例方法 lpublic String getHostAddress() 获取IP地址 lpublic String getHostName() 获取主机名&#x2F;域名 URL类 URL是统一资源定位符，是互联网上资源位置和访问方法的一种简介表示。每个文件具有唯一的URL。 URL由4部分组成：协议、存放资源的主机域名、端口号、资源文件名。如果未指定端口号，则使用协议默认的端口。HTTP协议的默认端口为80。 URL的标准格式：&lt;协议&gt;:&#x2F;&#x2F;&lt;域名或IP&gt;:&lt;端口&gt;&#x2F;&lt;路径&gt;，其中端口和路径有时可以省略。 为了方便程序员编程，JDK提供了java.net.URL类，该类封装了大量复杂的涉及从远程站点获取信息的细节，可以使用它的各种方法对URL对象进行分割、合并等处理 构造方法1URL url = new URL(&quot;http://127.0.0.1:8080/oa/index.html?name=zhangsan#tip&quot;); 常用方法获取协议：url.getProtocol() 获取域名：url.getHost() 获取默认端口：url.getDefaultPort() 获取端口：url.getPort() 获取路径：url.getPath() 获取资源：url.getFile() 获取数据：url.getQuery() 获取锚点：url.getRef() openStream()：可以打开到此URL的连接并返回一个用于从该连接读入的InputStream，实现最简单的爬虫。 TCP 与 UDP 协议Socket 套接字 Socket是传输层供给应用层的编程接口。使用Socket编程可以开发客户端和服务器应用程序，可以在本地网络上进行通信，也可以通过互联网在全球范围内通信。 TCP协议和UDP协议是传输层的两种协议。Socket编程分为TCP编程和UDP编程两类。 TCP、UDP协议 TCP 三次握手（通道打开） 客户端发送SYN（同步）数据包，包含客户端的初始序列号（ISN） 服务器收到SYN数据包后，发送SYN-ACK（同步确认）数据包，包含服务器的初始序列号（ISN）和对客户端ISN的确认号（ACK） 客户端收到SYN-ACK数据包后，发送ACK（确认）数据包，包含对服务器ISN的确认号（ACK） 三次握手完成后，客户端和服务器就可以开始交换数据了。 三次握手的意义：不会丢失、重复、乱序，保证数据在两个设备之间可靠地传输。 四次挥手（通道关闭） 客户端发送FIN（结束）数据包，表示客户端已经完成数据传输，希望关闭连接。 服务器收到FIN数据包后，发送ACK（确认）数据包，表示服务器已经收到客户端的FIN数据包，同意关闭连接。 服务器发送FIN数据包，表示服务器已经完成数据传输，希望关闭连接。 客户端收到FIN数据包，发送ACK（确认）数据包。表示客户端已经收到服务器的FIN数据包，并同意关闭连接。 四次挥手完成后，客户端和服务器之间的连接就关闭了。 四次挥手的意义：不会丢失、重复、乱序，保证数据在两个设备之间可靠地传输。 基于TCP协议的编程概述 在网络通讯中，第一次主动发起通讯的程序被称作客户端(Client)，而在第一次通讯中等待连接的程序被称作服务端(Server)。一旦通讯建立，则客户端和服务器端完全一样，没有本质的区别。 套接字与主机地址和端口号相关联，主机地址就是客户端或服务器程序所在的主机的IP地址，端口地址是指客户端或服务器程序使用的主机的通信端口。在客户端和服务器中，分别创建独立的Socket，并通过Socket的属性，将两个Socket进行连接，这样客户端和服务器通过套接字所建立连接并使用IO流进行通信。 Socket类Socket实现客户端套接字。 构造方法： public Socket(InetAddress a, int p) 创建套接字并连接到指定IP地址的指定端口号 Socket类实例方法： public InetAddress getInetAddress() 返回此套接字连接到的远程 IP 地址 public InputStream getInputStream() 返回此套接字的输入流（接收网络消息） public OutputStream getOutputStream() 返回此套接字的输出流（发送网络消息） public void shutdownInput() 禁用此套接字的输入流 public void shutdownOutput() 禁用此套接字的输出流 public synchronized void close() 关闭此套接字（默认会关闭IO流） ServerSocket类ServerSocket类实现服务器套接字。服务器套接字等待请求通过网络传入，基于该请求执行某些操作，然后向请求者返回结果。 构造方法： public ServerSocket(int port) ServerSocket类实例方法： public Socket accept() 侦听要连接到此套接字并接受它 public InetAddress getInetAddress() 返回此服务器套接字的本地地址 public void close() 关闭此套接字 十三、lambda表达式 面向对象的思想 只做一件事情，找一个能解决这个事情的对象，然后调用对象的方法完成这件事情。 函数式编程思想 只要能获得结果，谁去做的，怎么做的都不重要，重视结果，忽略实现过程 Lambda和匿名内部类的区别 所需类型不同 匿名内部类：可以是接口、抽象类、具体类 Lambda表达式：只能是接口 使用限制不同 如果接口中有且仅有一个抽象方法，可以使用Lambda表达式，也可以使用匿名内部类。 如果接口中有多个抽象方法，就只能使用匿名内部类，而不能使用Lambda表达式。 实现原理不同 匿名内部类：编译之后，会生成一个单独的.class字节码文件 Lambda表达式：编译之后，不会生成一个单独的.class字节码文件 Lambda表达式的语法12345(形参列表) -&gt; &#123; 方法体&#125; 例： 123456789101112131415161718List&lt;Integer&gt; list = Arrays.asList(100,200,350,300);// 对其进行排序// 法一Collections.sort(list);// 法二：匿名内部类Collections.sort(list, new Comparator&lt;Integer&gt;()&#123; @Override public int compare(Integer o1, Integer o2)&#123; return o2-o1; &#125;&#125;) // 法三：Lambda表达式Collections.sort(list,(Integer o1, Integer o2) -&gt; &#123;return b-a;&#125;)// 或者Comparator&lt;Integer&gt; comparator = (Integer a, Integer b) -&gt; &#123;return b-a&#125;;Collections.sort(list,comparator); Lambda 表达式的语法精简四种情况： 形参类型可以省略，如果需要省略，则每个形参的类型都要省略。 如果形参列表只有一个形参，那么形参类型和小括号都可以省略。 如果方法体重只有一行语句，那么方法体的大括号也可以省略。 如果方法体中只有一条return语句，那么大括号可以省略，且必须去掉return关键字。 四个基本的函数式接口 名字 接口名 对应的抽象方法 消费 Consumer void accept(T t); 生产 Supplier T get(); 转换 Function&lt;T, R&gt; R apply(T t); 判断 Predicate boolean test(T t); Lambda表达式的方法引用（简化Lambda表达式）方法引用的概述我们在使用Lambda表达式的时候，如果Lambda表达式的方法体中除了调用现有方法之外什么都不做，满足这样的条件就有机会使用方法引用来实现。在以下的代码中，在重写的apply()方法中仅仅只调用了现有Math类round()方法，也就意味着Lambda表达式中仅仅只调用了现有Math类round()方法，那么该Lambda表达式就可以升级为方法引用，案例如下： 1234567891011121314151617// 需求：实现小数取整的操作// 方式一：使用匿名对象来实现Function&lt;Double, Long&gt; function1 = new Function&lt;Double, Long&gt;() &#123; @Override public Long apply(Double aDouble) &#123; return Math.round(aDouble); &#125;&#125;;System.out.println(function1.apply(3.14));// 方式二：使用Lambda表达式来实现Function&lt;Double, Long&gt; function2 = aDouble -&gt; Math.round(aDouble);System.out.println(function2.apply(3.14));// 方式三：使用方法引用来实现Function&lt;Double, Long&gt; function3 = Math :: round;System.out.println(function3.apply(3.14)); 对于方法引用，我们可以看做是Lambda表达式深层次的表达。换句话说，方法引用就是Lambda表达式，也就是函数式接口的一个实例，通过方法的名字来指向一个方法，可以认为是Lambda表达式的一个语法糖。在Lambda表达式的方法引用中，主要有实例方法引用、静态方法引用、特殊方法引用和构造方法引用、数组引用这五种情况，接下来我们就对这五种情况进行讲解。 实例方法引用语法：对象 :: 实例方法特点：在Lambda表达式的方法体中，通过“对象”来调用指定的某个“实例方法”。要求：函数式接口中抽象方法的返回值类型和形参列表 与 内部通过对象调用某个实例方法的返回值类型和形参列表 保持一致。【示例】实例化Consumer接口的实现类对象，并在重写的accept()方法中输出形参的值 12345678910111213141516// 方式一：使用匿名内部类来实现Consumer&lt;String&gt; consumer1 = new Consumer&lt;String&gt;() &#123; @Override public void accept(String str) &#123; System.out.println(str); &#125;&#125;;consumer1.accept(&quot;hello world&quot;);// 方式二：使用Lambda表达式来实现Consumer&lt;String&gt; consumer2 = str -&gt; System.out.println(str);consumer2.accept(&quot;hello world&quot;);// 方式三：使用方法引用来实现Consumer&lt;String&gt; consumer3 = System.out :: println;consumer3.accept(&quot;hello world&quot;); 【示例】实例化Supplier接口的实现类对象，并在重写方法中返回Teacher对象的姓名 1234567891011121314151617Teacher teacher = new Teacher(&quot;ande&quot;, 18);// 方式一：使用匿名内部类来实现Supplier&lt;String&gt; supplier1 = new Supplier&lt;String&gt;() &#123; @Override public String get() &#123; return teacher.getName(); &#125;&#125;;System.out.println(supplier1.get());// 方式二：使用Lambda表达式来实现Supplier&lt;String&gt; supplier2 = () -&gt; teacher.getName();System.out.println(supplier2.get());// 方式三：使用方法引用来实现Supplier&lt;String&gt; supplier3 = teacher :: getName;System.out.println(supplier3.get()); 静态方法引用语法：类 :: 静态方法特点：在Lambda表达式的方法体中，通过“类名”来调用指定的某个“静态方法”。要求：函数式接口中抽象方法的返回值类型和形参列表 与 内部通过类名调用某个静态方法的返回值类型和形参列表保持一致。 【示例】实例化Function接口的实现类对象，并在重写的方法中返回小数取整的结果 12345678910111213141516// 方式一：使用匿名内部类来实现Function&lt;Double, Long&gt; function1 = new Function&lt;Double, Long&gt;() &#123; @Override public Long apply(Double aDouble) &#123; return Math.round(aDouble); &#125;&#125;;System.out.println(function1.apply(3.14));// 方式二：使用Lambda表达式来实现Function&lt;Double, Long&gt; function2 = aDouble -&gt; Math.round(aDouble);System.out.println(function2.apply(3.14));// 方式三：使用方法引用来实现Function&lt;Double, Long&gt; function3 = Math :: round;System.out.println(function3.apply(3.14)); 特殊方法引用语法：类名 :: 实例方法特点：在Lambda表达式的方法体中，通过方法的第一个形参来调用指定的某个“实例方法”。要求：把函数式接口中抽象方法的第一个形参作为方法的调用者对象，并且从第二个形参开始（或无参）可以对应到被调用实例方法的参数列表中，并且返回值类型保持一致。【示例】使用Comparator比较器，来判断两个小数的大小 12345678910111213141516// 方式一：使用匿名内部类来实现Comparator&lt;Double&gt; comparator1 = new Comparator&lt;Double&gt;() &#123; @Override public int compare(Double o1, Double o2) &#123; return o1.compareTo(o2); &#125;&#125;;System.out.println(comparator1.compare(10.0, 20.0));// 方式二：使用Lambda表达式来实现Comparator&lt;Double&gt; comparator2 = (o1, o2) -&gt; o1.compareTo(o2);System.out.println(comparator2.compare(10.0, 20.0));// 方式三：使用方法引用来实现Comparator&lt;Double&gt; comparator3 = Double :: compareTo;System.out.println(comparator3.compare(10.0, 20.0)); 需求：实例化Function接口的实现类对象，然后获得传入Teacher对象的姓名。 1234567891011121314151617// 方式一：使用匿名内部类来实现Teacher teacher = new Teacher(&quot;ande&quot;, 18);Function&lt;Teacher, String&gt; function1 = new Function&lt;Teacher, String&gt;() &#123; @Override public String apply(Teacher teacher) &#123; return teacher.getName(); &#125;&#125;;System.out.println(function1.apply(teacher));// 方式二：使用Lambda表达式来实现Function&lt;Teacher, String&gt; function2 = e -&gt; e.getName();System.out.println(function2.apply(teacher));// 方式三：使用方法引用来实现Function&lt;Teacher, String &gt; function3 = Teacher :: getName;System.out.println(function3.apply(teacher)); 构造方法引用语法：类名 :: new特点：在Lambda表达式的方法体中，返回指定“类名”来创建出来的对象。要求：创建对象所调用构造方法形参列表 和 函数式接口中的方法的形参列表 保持一致，并且方法的返回值类型和创建对象的类型保持一致。【示例】实例化Supplier接口的实现类对象，然后调用重写方法返回Teacher对象 1234567891011121314151617// 方式一：使用匿名内部类来实现Supplier&lt;Teacher&gt; supplier1 = new Supplier&lt;Teacher&gt;() &#123; @Override public Teacher get() &#123; return new Teacher(); &#125;&#125;;System.out.println(supplier1.get());// 方式二：使用Lambda表达式来实现Supplier&lt;Teacher&gt; supplier2 = () -&gt; new Teacher();System.out.println(supplier2.get());// 方式二：使用构造方法引用来实现// 注意：根据重写方法的形参列表，那么此处调用了Teacher类的无参构造方法Supplier&lt;Teacher&gt; supplier3 = Teacher :: new;System.out.println(supplier3.get()); 【示例】实例化Function接口的实现类对象，然后调用重写方法返回Teacher对象 1234567891011121314151617// 方式一：使用匿名内部类来实现Function&lt;String, Teacher&gt; function1 = new Function&lt;String, Teacher&gt;() &#123; @Override public Teacher apply(String name) &#123; return new Teacher(name); &#125;&#125;;System.out.println(function1.apply(&quot;ande&quot;));// 方式二：使用Lambda表达式来实现Function&lt;String, Teacher&gt; function2 = name -&gt; new Teacher(name);System.out.println(function2.apply(&quot;ande&quot;));// 方式二：使用构造方法引用来实现// 注意：根据重写方法的形参列表，那么此处调用了Teacher类name参数的构造方法Function&lt;String, Teacher&gt; function3 = Teacher :: new;System.out.println(function3.apply(&quot;ande&quot;)); 数组引用语法：数组类型 :: new特点：在Lambda表达式的方法体中，创建并返回指定类型的“数组”。要求：重写的方法有且只有一个整数型的参数，并且该参数就是用于设置数组的空间长度，并且重写方法的返回值类型和创建数组的类型保持一致。【示例】实例化Function接口的实现类对象，并在重写方法中返回指定长度的int类型数组 12345678910111213141516// 方式一：使用匿名内部类来实Function&lt;Integer, int[]&gt; function1 = new Function&lt;Integer, int[]&gt;() &#123; @Override public int[] apply(Integer integer) &#123; return new int[integer]; &#125;&#125;;System.out.println(Arrays.toString(function1.apply(10)));// 方式二：使用Lambda表达式来实现Function&lt;Integer, int[]&gt; function2 = num -&gt; new int[num];System.out.println(Arrays.toString(function2.apply(20)));// 方式三：使用方法引用来实现Function&lt;Integer, int[]&gt; function3 = int[] :: new;System.out.println(Arrays.toString(function3.apply(30))); Lambda在集合当中的使用为了能够让Lambda和Java的集合类集更好的一起使用，集合当中也新增了部分方法，以便与Lambda表达式对接，要用Lambda操作集合就一定要看懂源码。 forEach()方法在Collection集合和Map集合中，都提供了forEach()方法用于遍历集合。在Collection集合中，提供的forEach()方法的形参为Consumer接口（消费型接口），通过该方法再配合Lambda表达式就可以遍历List和Set集合中的元素。【示例】遍历List集合中的元素 123456789101112131415161718List&lt;Integer&gt; list = Arrays.asList(11, 22, 33, 44, 55);// 方式一：使用匿名内部类来实现list.forEach(new Consumer&lt;Integer&gt;() &#123; /** * 获得遍历出来的元素 * @param element 遍历出来的元素 */ @Override public void accept(Integer element) &#123; System.out.println(element); &#125;&#125;);// 方式二：使用Lambda表达式来实现list.forEach(element -&gt; System.out.println(element));// 方式三：使用方法引用来实现list.forEach(System.out :: println); 【示例】遍历Set集合中的元素 123456789101112131415161718List&lt;String&gt; list = Arrays.asList(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;, &quot;dd&quot;);HashSet&lt;String&gt; hashSet = new HashSet&lt;&gt;(list);// 方式一：使用匿名内部类来实现hashSet.forEach(new Consumer&lt;String&gt;() &#123; /** * 获得遍历出来的元素 * @param element 遍历出来的元素 */ @Override public void accept(String element) &#123; System.out.println(element); &#125;&#125;);// 方式二：使用Lambda表达式来实现hashSet.forEach(element -&gt; System.out.println(element));// 方式三：使用方法引用来实现hashSet.forEach(System.out :: println); 在Map集合中，提供的forEach()方法的形参为BiConsumer接口，而BiConsumer接口属于两个参数的消费型接口，通过该方法再配合Lambda表达式就可以遍历Map集合中的元素。【示例】遍历Map集合中的元素 12345678910111213141516171819// 实例化Map集合并添加键值对HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put(&quot;张三&quot;, &quot;成都&quot;);map.put(&quot;李四&quot;, &quot;重庆&quot;);map.put(&quot;王五&quot;, &quot;西安&quot;);// 方式一：使用匿名内部类来实现map.forEach(new BiConsumer&lt;String, String&gt;() &#123; /** * 获得遍历出来的key和value * @param key 键 * @param value 值 */ @Override public void accept(String key, String value) &#123; System.out.println(&quot;key：&quot; + key + &quot;，value：&quot; + value); &#125;&#125;);// 方式二：使用Lambda表达式来实现map.forEach((k, v) -&gt; System.out.println(&quot;key：&quot; + k + &quot;，value：&quot; + v)); removeIf()方法在Collection集合中，提供的removeIf()方法的形参为Predicate接口（判断型接口），通过该方法再配合Lambda表达式就可以遍历List和Set集合中的元素。【示例】删除List集合中的某个元素 12345678910111213141516171819// 创建List集合并添加元素List&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;, &quot;dd&quot;));// 方式一：使用匿名内部类来实现list.removeIf(new Predicate&lt;String&gt;() &#123; /** * 删除指定的某个元素 * @param element 用于保存遍历出来的某个元素 * @return 返回true，代表删除；返回false，代表不删除 */ @Override public boolean test(String element) &#123; return &quot;bb&quot;.equals(element); &#125;&#125;);System.out.println(list); // 输出：[aa, cc, dd]// 方式二：使用Lambda表达式来实现list.removeIf(&quot;cc&quot; :: equals);System.out.println(list); // 输出：[aa, dd] 【示例】删除Set集合中的某个元素 12345678910111213141516171819List&lt;String&gt; list = Arrays.asList(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;, &quot;dd&quot;);HashSet&lt;String&gt; hashSet = new HashSet&lt;&gt;(list);// 方式一：使用匿名内部类来实现hashSet.removeIf(new Predicate&lt;String&gt;() &#123; /** * 删除指定的某个元素 * @param element 用于保存遍历出来的某个元素 * @return 返回true，代表删除；返回false，代表不删除 */ @Override public boolean test(String element) &#123; return &quot;bb&quot;.equals(element); &#125;&#125;);System.out.println(hashSet); // 输出：[aa, cc, dd]// 方式二：使用Lambda表达式来实现hashSet.removeIf(&quot;cc&quot; :: equals);System.out.println(hashSet); // 输出：[aa, dd]","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://example.com/tags/javase/"}]},{"title":"javase 面向对象","slug":"javase 面向对象","date":"2025-04-12T16:00:00.000Z","updated":"2025-05-08T06:09:34.828Z","comments":true,"path":"2025/04/13/javase 面向对象/","permalink":"http://example.com/2025/04/13/javase%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"三、面向对象面向对象概述面向过程关注点在实现功能的步骤上 面向对象关注点在实现功能需要哪些对象的参与，可以把问题拆分成几个对象，对象协作起来解决问题。 面向对象开发方式耦合度低，扩展能力强。 面向对象的三大特征 封装 继承 多态 对象的创建1234[修饰符列表] class 类名&#123; //属性 /&#125; JVM内存分析元空间 metaspace元空间中存储的是类的元信息，字节码等。 元空间是java8之后引入的。是JVM规范中方法区的实现。 方法区：JVM规范 的叫法，各个厂商根据这个规范去实现具体的java虚拟机。 总结：方法区是规范，元空间是实现。java8之前使用永久代实现的。 堆内存所有new的对象，都存储在堆内存中。 栈方法被调用时会给该方法分配空间，在VM Stack中压栈。 JVM有自动垃圾回收机制，主要针对堆区。 实例变量和实例方法通常描述一个对象的行为动作时，不加static——称为实例方法 实例方法不能通过类访问，必须通过对象访问。 方法调用传递引用数据类型传的是地址！！！ ！this关键字 this本质是一个引用 this中保存的是当前对象的内存地址 this.大部分情况可以省略，默认是访问当前的类的实例变量。当需要区分局部变量和实例变量时，不能省略。 this存储在栈帧的局部变量表的第0个槽位上。 this不能出现在静态方法中 this 实参 通过这种语法，可以在构造方法中调用本类的其他构造方法 作用：代码复用 this实参只能出现在构造方法的第一行！！！ 封装通过限制外部对对象内部的直接访问和修改，保证数据的安全性，并提高了代码的可维护性和可复用性。 属性私有化：使用private修饰 对外提供接口 *快速创建getter，setter方法 alt + insert 选择getter and setter 选择要创建的内容 构造器（构造方法） 对象的创建 对象的初始化（默认有super();，先对父类的变量进行初始化） 这两个阶段不能颠倒，也不能分割。 构造方法名需与类名一致。 不需要写return，不需要写返回值类型。 如果没有显式定义构造方法，系统会提供一个无参数的构造方法，并且会给属性赋默认值。 定义有参数的构造方法后，可以手动再写一个无参数的构造方法。【方法重载】 如何调用构造方法new 构造方法名（实参） 写了构造方法，为什么还要单独写set方法？构造方法是对象第一次创建时用于初始化的。set方法可以在后期修改属性值。 构造代码块语法格式123&#123; &#125; //直接写在class体里面 //每次new都会运行一次构造代码块中的内容，运行前对象已经创建好，并且完成了初始值的赋值。 //！！！构造代码块是在构造方法执行之前执行的！！！ 作用如果所有的构造方法在最开始的时候有相同的一部分代码，可以将公共的代码放在构造代码块中，达到复用的效果。 流程 new的时候在堆内存中开辟空间，给所有属性赋默认值 执行构造代码块进行初始化 执行构造方法体进行初始化 构造方法执行结束，对象初始化完毕 static 关键字 static修饰静态变量，当所有对象的某个属性的值是相同的，建议将该属性定义为静态变量，来节省内存。 JDK8后，静态变量存储在堆内存中。在类加载时进行初始化。 静态变量可以通过“引用.”来访问，实际运行时和对象无关（不会出现空指针异常），但不建议。会让程序员造成误解。 静态代码块 语法格式： static{ } 在类加载的时候执行，并且只执行一次。 可以有多个静态代码块，自上而下依次执行。 作用：在类加载的时候运行一段代码，可能是进行一些准备工作。 java虚拟机规范运行时数据区的六个内容 PC Register, PC计数器：是一块较小的内存空间，用于存储下一条要执行的字节码指令地址。 java Virtual Machine Stacks, java虚拟机栈：用于存储栈帧，栈帧存储局部变量表、操作数栈、动态链接、方法出口等信息。 Heap, 堆：java虚拟机所管理的最大的一块内存，用于存储java对象实例以及数组。堆是垃圾回收器主要使用区域。 Method Area, 方法区：用于存储已被虚拟机加载的类信息、常量、静态变量（hotspot把这个内容存到堆里去了）、即时编译器编译后的代码等数据。 Run-Time Constant Pool, 常量池：方法区的一部分，用于存放编译期生成的各种字面量与符号引用（类名、方法名、属性名）。 method stacks, 本地方法栈：在本地方法的执行过程中，会使用本地方法栈。 GoF设计模式什么是设计模式可以重复利用的一套方案 GoF设计模式的分类 创建型：主要解决对象的创建问题 结构型：通过设计和构建对象之间的关系，以达到更好的重用性、扩展性和灵活性 行为型：主要用于处理对象之间的算法和责任分配 单例模式属于创造型设计模式，确保一个类只有一个实例，并提供一个全局访问点来访问该实例。 饿汉式单例模式类加载时对象就创建好了，不管这个对象用还是不用 构造方法私有化 定义一个静态变量，在类加载的时候初始化静态变量（只初始化一次） 对外提供一个公开的静态方法，用这个方法获取单个实例 懒汉式单例模式用到这个对象的时候再创建对象，别在类加载的时候创建对象 构造方法私有化 提供一个静态变量，但这个变量的值为NULL 对外提供一个静态方法，通过这个方法可以获取对象 继承作用 代码复用 有了继承，才有了方法覆盖和多态机制 实现123[修饰符列表] class 类名 extends 父类名 &#123;&#125; 特性 只支持单继承，一个类只能继承一个类 不支持多继承，但支持多重继承（多层继承） 子类继承父类的除私有的、构造方法以外的所有内容 一个类没有显式继承任何类时，默认继承java.lang.Object类 方法覆盖（重写） overwrite什么时候使用？当从父类继承过来的方法，无法满足子类的业务需求时。 特性 当子类将父类方法覆盖之后，将来子类对象调用方法的时候，一定会执行重写之后的方法。 注解：@override，在方法前写这个注解，在编译阶段会检查这个方法是否重写了父类的方法。 如果返回值类型是引用数据类型，那么这个返回值类型可以是原类型的子类型。 访问权限不能变低，可以变高。public最高 抛出异常不能变多，可以变少。 方法覆盖针对的是实例方法，和静态方法无关。 多态向上转型和向下转型的基本概念引用数据类型进行类型转换。 向上转型：子–&gt;父 （可以等同看做自动类型转换）父类型引用指向子类型对象，这是多态机制最核心的语法。 如果父类中没有某个方法，而子类中有，那么就需要向下转型。 向下转型：父–&gt;子（可以等同看做强制类型转换）当调用的方法是子类特有的方法，需要向下转型，进行强制转换。 如果两个子类不是同一类，会出现ClassCastException异常 如何避免ClassCastException异常？使用运算符 instanceof 语法格式： 引用 instanceof 类型 在进行向下转型之前，用if语句判断一下是否是要向下转型的类型，不是就不要转换了。 静态方法和多态没有关系，因此静态方法和方法覆盖无关系。软件开发七大原则 多态在开发中的作用 降低程序耦合度，提高程序的扩展力 尽量使用多态，面向抽象编程，不要面向具体编程。 实例变量无法覆盖，根据声明的类型进行赋值抽象类和抽象方法123456public abstract class Name&#123; //父类：所有子类的公共属性+公共方法的集合体 public abstract void functionName();&#125;// 抽象方法必须在抽象类中//public 和 abstract的顺序没有要求// ！！！继承该抽象类的子类必须覆盖这个抽象方法 存在的意义：强制子类重写抽象方法，编译器会报错。如果类中有一些方法无法实现或者没有意义，就可以将方法定义为抽象方法。 abstract 关键字不能和private、final、static关键字共存 super 关键字 当子类和父类有名称相同的属性&#x2F;方法，此时调用父类中继承而来的属性&#x2F;方法需要使用super.属性/方法 super不能在静态方法中使用 this可以单独输出（本质是引用，内容是地址），super不能单独输出（本质不是引用，只是代表了对象父类型特征的那部分） 如何在子类中在使用父类方法的基础上进行方法覆盖？按正常方法覆盖，但是方法体中先写一个super.方法名()调用一下父类的方法，再写需要添加的内容。 在子类中调用父类的构造方法在子类的构造方法中使用super(参数); 通过此方法可以给继承过来的父类特征进行初始化，达到代码复用。 final 关键字 final修饰的类不可以被继承 final修饰的方法无法被覆盖 final修饰的变量一旦赋值，不能重新赋值 final修饰的实例变量必须在构造方法执行完之前手动赋值。这种变量一般和static联用，得到常量（单词全部大写，每个单词用_连接） final修饰的引用一旦指向某个对象，不能再指向其他对象。但指向的对象内部的数据可以修改。 接口要想解耦合，就是多态+接口 接口在Java中表示一种规范或契约，它定义了一组抽象方法和常量，用来描述一些实现这个接口的类应该具有哪些行为和属性。接口和类一样，也是一种引用数据类型。 分类 普通接口 起标志的作用 如何定义[修饰符列表] interface 接口名{} 接口是完全抽象的抽象类是半抽象的（可以定义抽象的方法，也可以定义非抽象的方法） 接口是完全抽象的，没有构造方法，也无法实例化。 JDK8之前的语法规则接口中只能定义：常量+抽象方法 接口中的常量的static final可以省略，抽象方法的abstract可以省略。 所有方法和变量都是public的 接口与接口之间可以多继承类和接口的关系——实现这里的实现可以等同看做继承。（接口是父，类是子） 这个说法仅供理解 使用implements关键字进行接口的实现。 一个非抽象的类实现接口必须将接口中所有抽象方法全部实现（否则编译器报错）一个类可以实现多个接口class 类名 implements 接口A,接口B&#123; &#125; 使用了接口之后，为了降低程序的耦合度，一定要让接口和多态联合起来使用父类型的引用指向子类型的对象。 JDK8后，接口中允许出现默认方法和静态方法默认方法引入默认方法是为了演变接口演变问题。 接口可以定义抽象方法，但不能实现这些方法。所有实现接口的类都必须实现这些抽象方法，这会导致接口升级问题——当我们向接口添加或删除一个抽象方法时，这会破坏该接口的所有实现，所有与它有关的类都需要修改代码。 覆盖会使用静态方法只能通过接口名去调用 通常将接口作为工具使用时，会使用静态方法 JDK9之后允许定义私有实例方法（为默认方法服务）和私有静态方法（为静态方法服务）私有静态方法便于将静态方法拆分为多个方法，免得一个方法中有几千行。便于代码复用 所有接口隐式继承object，因此接口也可以调用object类的相关方法接口的作用 调用者和实现者通过接口达到了解耦合。调用者不需要关心具体的实现者，实现者也不许要关心具体的调用者，双方只要遵循规范，面向接口进行开发。 面向抽象编程，面向接口编程，可以降低程序的耦合度，提高程序的扩展力。 接口和抽象类的选择 抽象类主要用于公共代码的提取。多个类有共同的属性和方法时，提取出一个父类。 接口主要用于功能的扩展。有一些类需要实现某个方法，另一些类不需要，那就将这个方法定义到接口中，需要这个方法的就去实现这个接口。 一个类单继承父类，多实现接口extends在前，implements在后 UML 统一建模语言 类之间的六种关系 聚合关系：整体和部分各自有自己的生命周期 组合关系：整体和部分有相同的生命周期。eg.人死了，四肢也没了。 三个比较重要的关系l 其他的关系聚合关系 组合关系 依赖关系 访问控制权限 类的访问权限只有两种：public和缺省 访问权限控制符不能修饰局部变量 Object类toString ：将java对象转换成字符串型但默认的方法输出的是地址，因此需要自己覆盖方法。 调用print()打印类时，会自动调用类的toString()（和自己调用toString方法有区别，因为它会先判断是否是NULL，再使用toString） equal ：判断两个对象是否相等默认方法是判断地址是否相等，也需要自己重写方法。 hashCode ：返回一个对象的哈希值通常用来在哈希表中查找该对象的键值。 默认实现是根据对象的内存地址生成一个哈希码（将对象的内存地址转换为整数作为哈希值）。 该方法是为了HashMap、Hashtable、HashSet等集合类进行优化而设置的，便于更快地查找和存储对象。 clone 实现对象拷贝。通常在开发中需要保护原对象数据结构，于是克隆出一份新对象，对新对象进行操作。 默认实现：是protected类型，专门给子类使用的。（本地方法，调用C++程序实现的）【浅克隆】 怎么解决克隆方法调用问题？—— 在子类中重写clone方法，并且为了保证clone方法在任何位置都可以调用，建议将其修饰符修改为public 凡是参加克隆的对象，必须实现一个标志接口：java.lang.Cloneable 需要重写变成【深克隆】 就是先完成浅克隆，再单独克隆其中包含的类，然后赋值给克隆出来的东西。 eg. 内部类什么是内部类定义在一个类中的类 什么时候使用内部类 四种内部类 匿名内部类：","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://example.com/tags/javase/"}]},{"title":"javase 引入、基本语法","slug":"javase 引入、基本语法","date":"2025-04-10T16:00:00.000Z","updated":"2025-05-18T11:12:16.696Z","comments":true,"path":"2025/04/11/javase 引入、基本语法/","permalink":"http://example.com/2025/04/11/javase%20%E5%BC%95%E5%85%A5%E3%80%81%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/","excerpt":"","text":"一、引入JAVA语言特性简单性：不像c++支持多继承，无指针。底层由c++实现。 面向对象 可移植性：一次编译，到处运行。在win上编译后可以在Linux上运行。 ​ Java程序在Java虚拟机上运行，JVM : Java virtual machine ​ JDK ：Java开发工具包 多线程 健壮性：产生的垃圾是自动回收的，不需要像c++一样手动回收内存空间。 安全性 JAVA的加载与执行 注：.class文件是字节码文件，不是纯粹的二进制文件，否则操作系统就可以直接运行了。 编译：使用JDK中自带的javac.exe进行编译使用方法： 1javac java源文件的路径 一个源文件可能生成多个.class文件 .class文件生成后，删除.java文件不影响程序的运行，但最好不要删掉，以防后面要修改。 运行：使用java.exe运行使用方法： 磁盘上有一个A.class 1java A JVM会启动类加载器ClassLoader ClassLoader会去硬盘上根据classpath搜索A.class文件，找到该文件则将该字节码文件装载到JVM中 JVM将A.class文件解释成二进制数据 操作系统执行二进制文件，和底层硬件平台交互 三种注释方式123456789101112// 单行注释/* 多行注释 多行注释*//*** 文档注释* 编写在这的信息可以被javadoc命令解析提取并生成到帮助文档中**/ 第一个程序 public class 和class注：公共类与文件名强制绑定 文件名应该改为HelloWorld.java 一个class文件最多只能有一个公共类，也可以没有。 每个类中都可以编写入口main方法，想执行那个就用 java 类名 实际开发中对于一个软件来说一般入口只有1个 二、基本语法标识符 字母（任何一个国家的语言）、数字、下划线、美元符号组成，不能包含其他符号。 数字不能开头 命名规范 加号运算符 求和 字符串拼接（加号两边有任意一边是字符串类型时进行，结果还是一个字符串） 变量数据类型 int 整型 double 浮点型 String 字符串型 …… 变量类型在方法体中定义的变量，是局部变量。 在类体中定义的变量，是成员变量，成员变量又分为静态变量、实例变量。 成员变量如果没有手动赋值，系统会自动赋默认值。 整型自动类型转换如果在整型类型后添加 L 或者 l ，那么这个整型数据就会被当成long类型处理。建议使用L，看的比较清楚。 面试题 强制类型转换大容量无法自动转换成小容量，想让其编译通过，必须手动添加强制类型转换符。如 (int) 需记住： 当一个整型字面量没有超出某类型（byte short char）的取值范围时，可以直接赋值给该类型的变量，不需要强转。 多种数据类型混合运算时，先各自转成容量最大的，再做运算。 byte short char混合运算时，先转成int再运算。 多种数据类型混合运算时，要先转成当前最大的类型再运算 double &gt; float &gt; long &gt; int 12double i = 1; //存在自动类型转换，由整型转换为浮点型。 //如果数值不规定类型，默认为int型 浮点型数值后加F或f表示float类型，否则默认为double型 注：一旦有浮点型数据参与运算得出的结果，不要用“&#x3D;&#x3D;”和别的数字进行相等比较！！！ 一般相减然后小于一个很小的值，就认为相等。 字符型 Java中的char类型统一采用Unicode编码 不允许空字符文字 ‘’ char默认值： \\u0000 空字符（不是空格，空格是\\u0020） 布尔型long , int等类型的数值不能直接赋值给布尔型变量 进制java中规定，0开头的是八进制，0b开头的是二进制，0x开头的是十六进制 接收键盘输入12345678// 创建键盘扫描器对象java.util.Scanner s = new java.util.Scanner(System.in);//获取输入内容int num1 = s.nextInt();double num2 = s.nextDouble();String str = s.next(); //获取第一个空格前的内容String str = s.nextLine(); // 获取一行 注：以上的代码存在问题，nextInt()，nextDouble()，next()在输入时肯定会输入换行符\\r，但是这三个扫描器都不会吸收这个换行符，导致到nextLine()时，直接吸收换行符就完成运行了。 或者在最开始 import scanner对应的包 123456789101112import java.util.Scanner;public class Scan1&#123; public static void main(String[] args)&#123; Scanner s = new Scanner(System.in); int num1 = s.nextInt(); double num2 = s.nextDouble(); String str = s.next(); //获取第一个空格前的内容 String str = s.nextLine(); // 获取一行 &#125;&#125; 逻辑运算符&amp; 逻辑与 |逻辑或 &amp;&amp; 逻辑与（左边是false就短路，不运行右边的内容） ||逻辑或（左边是true就短路，不运行右边的内容） 按位运算符操作数必须是整数 移位运算符 经典面试题：怎么让2快速变成8？左移2位 &gt;&gt;算数右移 &gt;&gt;&gt;逻辑右移 按位或应用：设置某一位的值为1。 如a | (1&lt;&lt;n) 按位异或自反性：a^b^b = a 应用：简单的加密、解密 按位取反应用：对某一位清零 赋值运算符对于扩展的赋值运算符，不会改变变量的数据类型。 自带强制类型转换，把运算符右边的内容强制转换为左边的数据类型。 控制语句字符串的比较不能使用==，因为String是引用数据类型，==此时比较的是两个变量是否指向同一个引用对象，比较的是地址。 比较两个字符串是否相等123String s = &quot;admin&quot;;String t = &quot;adm&quot;;System.out.print(s.equals(t)); switch 语句switch(x){ } 这个x可以是int（byte short char 放进去也可以自动类型转换），字符串，枚举类型。 Java 12 新特性 不需要自己写break了。 方法（C语言中的函数）方法的调用当这个方法修饰符列表有static关键字时，调用的格式为： 类名.方法名（实参列表） 什么时候调用时可以省略类名.？调用者和被调用者在同一个类时，可以省略。 方法重载 overload什么情况构成了方法重载？ 在同一个类中 方法名相同 形参列表不同：类型&#x2F;顺序&#x2F;个数 不同 哪个阶段的机制？编译阶段的。 编译阶段已经完成了方法的绑定，即确定要调用哪个方法了。 什么情况下考虑使用方法重载？功能类似，形参类型不同。 递归递归调用很耗资源能用循环就用循环。在实际开发中，有时候即使结束条件存在且合法，也可能出现栈溢出——递归太深了，栈内存不够导致。 package作用便于文件的管理，不同的类放在不同的包下，好维护。 定义包在代码第一行添加语句 package 包名 包名规范公司域名倒序+项目名+模块名+功能名 所有的包名都是小写 如何带包编译？1javac -d 编译后存放的目录 java源文件路径 有了包机制后的类名包名.类名，在同一个包内不需要写包名，直接写类名即可。 import使用不在同一个包的方法，需要import包 import支持静态导入（最好别用，可读性差）12345import static java.lang.System.*// 下面可以直接用输出的方法。out.print(&quot; &quot;);// 不使用静态导入时： System.out.print(&quot; &quot;) intellij idea 的快捷键 多行注释ctrl shift / 复制一行ctrl D 快速生成创建对象语句类名.new.var getter and setter alt + insert 选择getter and setter 选择要创建的内容 移动一行代码alt shift 上键/下键 快速向下转型变量名.castvar 快速查看方法的参数ctrl + p 返回上一步ctrl + alt + 左方向键 下一步ctrl + alt + 右方向键 代码格式化ctrl + alt + L 查看继承结构ctrl + H 自动代码包裹ctrl + alt + t","categories":[],"tags":[{"name":"javase","slug":"javase","permalink":"http://example.com/tags/javase/"}]},{"title":"C和C++中的易错点","slug":"C和C++中的易错点","date":"2025-03-04T16:00:00.000Z","updated":"2025-03-05T14:19:53.345Z","comments":true,"path":"2025/03/05/C和C++中的易错点/","permalink":"http://example.com/2025/03/05/C%E5%92%8CC++%E4%B8%AD%E7%9A%84%E6%98%93%E9%94%99%E7%82%B9/","excerpt":"","text":"一、”.”和”-&gt;”的区别 对于结构体指针，应该使用”-&gt;” 对于结构体，应该使用”.”‘ 举例： 1234567891011121314struct Student &#123; int age; char name[20];&#125;;// 定义结构体变量struct Student s;s.age = 20; // 直接通过变量访问成员strcpy(s.name, &quot;Alice&quot;);struct Student *ptr;ptr = &amp;s; // ptr指向结构体变量sptr-&gt;age = 21; // 通过指针访问成员// 等价于 (*ptr).age = 21;","categories":[],"tags":[{"name":"C","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"Swin-Unet 复现记录（记第一次复现）","slug":"Swin-Unet-复现记录（记第一次复现）","date":"2025-02-28T06:44:00.000Z","updated":"2025-03-01T07:19:30.381Z","comments":true,"path":"2025/02/28/Swin-Unet-复现记录（记第一次复现）/","permalink":"http://example.com/2025/02/28/Swin-Unet-%E5%A4%8D%E7%8E%B0%E8%AE%B0%E5%BD%95%EF%BC%88%E8%AE%B0%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%A4%8D%E7%8E%B0%EF%BC%89/","excerpt":"","text":"一、train中遇到的问题（一）python、pytorch、cuda版本不对应swin-unet官方仓库上写的使用的是python3.7运行的代码，所以我一开始把环境全部朝python3.7去配置。却一直报错。 经过一番搜索后，发现python3.7对应的环境无法在4060laptop上运行。 在多次尝试不同的环境，并结合b站复现别的论文的视频，选择将python版本改为3.8。 1、新建独立环境12conda create -n py.8 python=3.8 # 明确指定Python 3.8conda activate py.8 2、使用pip绕过conda依赖限制1pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu118 （二）一堆cuda的报错 根据github中issue的讨论，获得修改方法，train.py中的num_classes和n_class都要设置为9 https://github.com/HuCaoFighting/Swin-Unet/issues/121 （三）安装完requirements.txt中的库后仍然缺少部分库根据搜索安装即可 （四）训练集、验证集地址、名称问题对trainer.py中的相关代码进行如下修改 （五）windows中不能使用多线程二、test中遇到的问题（一）找不到best_model.pth.txt文件 （二）文件地址错乱（一）（二）的解决方法相同： 代码中的volum_path统一改为root_path，然后根据报错提示修改对应的地址。 （三）维度出现问题修改utils.py的代码 原代码： 12image, label = image.squeeze(0).cpu().detach().numpy().squeeze(0), label.squeeze(0).cpu().detach().numpy().squeeze(0) 修改后： 12345678910image = image.cpu().detach().numpy() label = label.cpu().detach().numpy() if image.shape[0] == 1: image = image.squeeze(0) if label.shape[0] == 1: label = label.squeeze(0) #image, label = image.squeeze(0).cpu().detach().numpy().squeeze(0), label.squeeze(0).cpu().detach().numpy().squeeze(0) 参考： https://juejin.cn/post/7431728417744175154 三、test结果第六类不知为啥数值都是0… 四、总结这是我第一次尝试复现代码，用时一天半终于把环境配好，第一次成功运行代码。 用时6:16:35训练完成！！！","categories":[],"tags":[{"name":"Swin-Unet","slug":"Swin-Unet","permalink":"http://example.com/tags/Swin-Unet/"},{"name":"pytorch","slug":"pytorch","permalink":"http://example.com/tags/pytorch/"}]},{"title":"动手学深度学习 2","slug":"动手学深度学习 2","date":"2025-01-24T16:00:00.000Z","updated":"2025-02-17T12:59:54.288Z","comments":true,"path":"2025/01/25/动手学深度学习 2/","permalink":"http://example.com/2025/01/25/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%202/","excerpt":"","text":"一、卷积卷积有什么用？ 通过卷积核的不同设置，使得每个输出通道可以识别特定的模式，比如识别边缘、锐化、模糊等操作。 核的参数怎么得到的？ 学出来的，不是自己设置的。 卷积尺寸公式： 输出尺寸*=*[输入尺寸-kernel-size+2*padding+stride]/stride 填充在输入周围添加行&#x2F;列，来控制输出形状的减少量 步幅每次滑动kernal窗口时的行&#x2F;列的步长，可以成倍的减少输出形状 注意： 1、第一个公式里的ph是要上下都加了行，所以要乘以二！！！ 2、padding通常设置为k-1 （核-1） 问题1、为什么通常用3x3或者5x5的卷积核呢？他们的视野不是很小吗？（更常用3x3，计算量更小） 多加几层卷积层，最后的到的层会涵盖初始层中很大范围的内容。 多输入通道 这样只能得到单输出的通道 如何得到多输出通道？输入的三通道数据和多个卷积核进行卷积，得到多通道的输出。 co表示卷积核的个数，ci表示卷积核的维度，第0维的卷积层和第0维的输入进行计算，第1维的卷积层和第1维的输入进行计算…，然后将同一位置不同层的计算结果相加，得到这一块的输出内容，再按此方法进行卷积操作得到第一维度的输出。使用其他的卷积核进行相同操作，最后得到多输出通道。 1x1 卷积层 用于不同通道使用不同权重进行融合。 二、最大&#x2F;平均池化返回滑动窗口中的最大值&#x2F;平均值 缓解卷积层对于位置的敏感性，通常放在卷积层之后。 pytorch中，如果不设置默认：池化窗口&#x3D;步幅，就是保证窗口不重叠 为什么现在池化用的少了？ 现在通常用一个卷积层+stride减少输出 三、LeNet 如何检验层的尺寸有没有搭错： 四、AlexNet在LetNet基础上添加了一些层，效果更好 五、VGG块将AlexNet中的多个卷积层封装成一个块，使用多个VGG块构建深度卷积神经网络，效果更好。 不同的卷积块个数和超参数可以得到不同复杂度的变种。 注：在VGG中，内部卷积层的个数n，通道m是超参数。 六、NiN全连接层的问题： 卷积层后的得到第一个全连接层时的计算量会非常大且容易过拟合 NiN块一个卷积层后跟两个全连接层 为什么用的是两个1x1的卷积层？他们其实相当于没有将输入拍扁的全连接层。 NiN架构 总结Nin块使用卷积层加两个1x1卷积层，后者对每个像素增加了非线性性。 Nin用全局平均池化层来替代VGG和AlexNet中的全连接层——不容易过拟合，更少的参数个数。 七、批量归一化 Batch Normalization——加速收敛、网络训练速度 BN层一般用于深层神经网络，浅层的效果不好。 解释由于学习过程中会调整每个层的超参数，当调整前面的层时，会导致后面的层需要重新进行学习，进而导致最后得到的层很难收敛。所以学习率不能设置太高。 批量归一化将每一层的输出进行归一化，使对下一层的输出相似但不完全相同，这样后面的层就不需要改动太大。因此可以选择较大的学习率，加快了网络的训练。 后有论文指出它可能就是通过在每个小批量里加入噪音来控制模型的复杂度。 因此没必要跟丢弃法混合使用。 分布归一化放在非线性激活前面！ 需要训练的参数增加了γ和β，原来的偏置是定好的不需要学习。所以现在有三个参数需要学习。 调包实现nn.BatchNorm2d(输入的通道数) nn.BatchNorm1d(输入的通道数) 八、ResNet 不断添加层数，得到的模型一定最优吗？ 不一定。反而可能会越来越偏离最优函数。 残差块 f(x)&#x3D;x+g(x) 使得新的模型必须包含之前的模型，因此精度不可能变差。 如果g(x)没什么用，那么系统后面给它的梯度会很小，它对最后的结果影响就很小了。 同时，残差块使得很深的网络更加容易训练。 这样加法的操作使得反向传播计算梯度时，即使g(x)的偏导很小，由于是加法，也可以求出x的偏导，那么f(x)得到的梯度就不至于消失。 解决了深层网络底层比较难以训练的问题。——底层拿到的梯度一般比较小。 九、数据增强增加一个已有的数据集，使其有更多的多样性。 ​ 增加不同的背景噪音 ​ 改变图片的颜色和形状 常见增强方法翻转左右、上下翻转 但不是总是可行。比如建筑之类的翻转不太符合实际。但树叶什么的翻转没关系。 切割从图片中切割一块，然后变形到固定形状 随机高宽比（eg.[3&#x2F;4,4&#x2F;3]） 随机大小（eg.[8%,100%]） 随机位置 颜色改变色调，饱和度，明亮度（当前的情况减少50%或增加50%的范围内） 其他https://github.com/aleju/imgaug 十、微调 fine-tune微调中的权重初始化 源数据集远复杂于目标数据，通常微调的效果更好（速度更快、精度越高）。 使用更小的学习率 使用更少的数据迭代 1、重用分类器权重源数据集可能也有目标数据中的部分标号，可以使用预训练好的模型分类器中对应标号对应的向量来做初始化。 2、固定一些层 神经网络通常学习有层次的特征： 低层次的特征更加通用 高层次的特征更加与数据集有关 可以固定底部一些层的参数，不参与更新。 十一、锚框一类目标检测算法是基于锚框的 提出多个被称为锚框的区域 预测每个锚框里是否含有关注的物体 如果是，预测从这个锚框到真实边缘框的偏移 IoU 交并比 赋予锚框标号 第一步的意思就是使用锚框2去预测边缘框3。 一张图有多少个边缘框，就对应有多少个训练样本。 使用非极大值抑制（NMS）输出 每个锚框预测一个边缘框 NMS可以合并相似的预测 选中是非背景类的最大预测值 去掉其他和它IoU值大于θ的预测 重复上述过程知道所有预测要么被选中，要么被去掉 十二、物体检测算法 R-CNN兴趣区域（RoI）池化层 给定一个锚框，均匀分割成n×m块，输出每块里的最大值 不管锚框多大，总是输出nm个值 强行将图像变成大小一样的。 Fast RCNN 使用CNN对图片抽取特征 再使用RoI池化层对每个锚框生成固定长度特征 在原始图片上搜索到锚框后，把锚框按照比例映射到经过CNN层的特征层。 Faster R-CNN Mask R-CNN如果有像素级别的标号，使用FCN来利用这些信息。 总结 十三、单发多框检测 SSD生成锚框 SSD模型 十四、YOLO: you only look once在SSD的基础上进行改进，避免大量SSD重叠。 十五、语义分割语义分割可以识别并理解图像中每一个像素的内容：其语义区域的标注和预测是像素级的。 即每一个像素都有其对应的类别。 列举RGB值和类名12345678910111213#@saveVOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128], [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128]]#@saveVOC_CLASSES = [&#x27;background&#x27;, &#x27;aeroplane&#x27;, &#x27;bicycle&#x27;, &#x27;bird&#x27;, &#x27;boat&#x27;, &#x27;bottle&#x27;, &#x27;bus&#x27;, &#x27;car&#x27;, &#x27;cat&#x27;, &#x27;chair&#x27;, &#x27;cow&#x27;, &#x27;diningtable&#x27;, &#x27;dog&#x27;, &#x27;horse&#x27;, &#x27;motorbike&#x27;, &#x27;person&#x27;, &#x27;potted plant&#x27;, &#x27;sheep&#x27;, &#x27;sofa&#x27;, &#x27;train&#x27;, &#x27;tv/monitor&#x27;] 构建从RGB到VOC类别索引的映射12345678910111213141516171819#@savedef voc_colormap2label(): &quot;&quot;&quot;构建从RGB到VOC类别索引的映射&quot;&quot;&quot; colormap2label = torch.zeros(256 ** 3, dtype=torch.long) for i, colormap in enumerate(VOC_COLORMAP): colormap2label[ (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i # 把RGB三通道的数值当做256进制的数（因为像素最多从0-255）每个像素值算出对应10进制数存入tensor 这样可以对应到每个像素所属类别。 # i表示这个颜色对应类别的序号 return colormap2label#@savedef voc_label_indices(colormap, colormap2label): &quot;&quot;&quot;将VOC标签中的RGB值映射到它们的类别索引&quot;&quot;&quot; colormap = colormap.permute(1, 2, 0).numpy().astype(&#x27;int32&#x27;) # 将输入的彩色标签图像的维度从（通道，高度，宽度）重排为（高度，宽度，通道），然后将其转换为NumPy数组，并将数据类型转换为32位整数，以便进行后续计算。 idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256 + colormap[:, :, 2]) # 计算RGB值对应的类别的索引 return colormap2label[idx] #返回对应类别的序号 十六、转置卷积卷积不会增大输入的高宽，通常要么不变、要么减半。 而转置卷积则可以用来增大输入的高宽。 12345678X = torch.tensor([[0.0, 1.0], [2.0, 3.0]])K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])trans_conv(X, K)X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2)#调用api实现转置卷积tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False) #输入通道数，输出通道数，核的大小，是否有偏移tconv.weight.data = Ktconv(X) 填充、步幅和多通道转置卷积的填充（padding）是加在输出上的。 如上图的转置卷积过程，如果padding&#x3D;1，则最后的结果为4。（删除第一和最后的行和列） 对于多个输入和输出通道，转置卷积与常规卷积以相同方式运作。假设输入有$c_i$个通道，且转置卷积为每个输入通道分配了一个$k_h\\times k_w$的卷积核张量。当指定多个输出通道时，每个输出通道将有一个$c_i\\times k_h\\times k_w$的卷积核。 如果我们将$\\mathsf{X}$代入卷积层$f$来输出$\\mathsf{Y}&#x3D;f(\\mathsf{X})$，并创建一个与$f$具有相同的超参数、但输出通道数量是$\\mathsf{X}$中通道数的转置卷积层$g$，那么$g(Y)$的形状将与$\\mathsf{X}$相同。 转置卷积与卷积的转换 十七、全连接卷积神经网络 FCN用转置卷积层来替换CNN最后的全连接层，从而实现每个像素的预测 最后的通道数 &#x3D; 类别数 十八、序列模型时序模型中，当前数据和之间观察到的数据相关。 常见的两种方案 十九、注意力机制卷积、全连接、池化层都只考虑不随意线索。 注意力机制则考虑随意线索 随意线索被称之为查询（query） 每个输入是一个值（value）和不随意线索（key）的对 通过注意力池化层来有偏向性的选择某些输入 注意力机制的本质：https://www.bilibili.com/video/BV1dt4y1J7ov/?share_source=copy_web&amp;spm_id_from=333.788.comment.all.click&amp;vd_source=c675206b339487e9755eec554de241a9 非参的注意力池化层 1、一般情况 2、Nadaraya-Watson 核回归 参数化的注意力机制在之前的基础上引入可以学习的w 注意力分数 加性注意力 additive attention12345678910111213141516171819202122232425#@saveclass AdditiveAttention(nn.Module): &quot;&quot;&quot;加性注意力&quot;&quot;&quot; def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs): super(AdditiveAttention, self).__init__(**kwargs) self.W_k = nn.Linear(key_size, num_hiddens, bias=False) self.W_q = nn.Linear(query_size, num_hiddens, bias=False) self.w_v = nn.Linear(num_hiddens, 1, bias=False) self.dropout = nn.Dropout(dropout) def forward(self, queries, keys, values, valid_lens): queries, keys = self.W_q(queries), self.W_k(keys) # 在维度扩展后， # queries的形状：(batch_size，查询的个数，1，num_hidden) # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens) # 使用广播方式进行求和 —— 广播规则：维度大小为1的轴会自动扩展以匹配另一张量的形状。 # 18行feature的形状：(batch_size，查询的个数，“键－值”对的个数，num_hiddens) features = queries.unsqueeze(2) + keys.unsqueeze(1) features = torch.tanh(features) # self.w_v仅有一个输出，因此从形状中移除最后那个维度。 # scores的形状：(batch_size，查询的个数，“键-值”对的个数) scores = self.w_v(features).squeeze(-1) self.attention_weights = masked_softmax(scores, valid_lens) # 注意力权重 # values的形状：(batch_size，“键－值”对的个数，值的维度) return torch.bmm(self.dropout(self.attention_weights), values) # 将注意力权重与值进行矩阵乘法 为什么要采用广播机制？通过广播机制，一次性生成所有 (query, key) 对的组合特征，避免逐对计算的低效循环。 示例说明假设： 批量大小 batch_size=2 查询数量 num_queries=3 键值对数量 num_kv_pairs=4 隐藏维度 num_hiddens=5 经过 unsqueeze 和广播后： queries 形状：(2, 3, 1, 5) keys 形状：(2, 1, 4, 5) 相加结果 features 形状：(2, 3, 4, 5) 这表示： 对于批量中的每个样本（2个样本）， 每个查询（3个查询）与每个键（4个键）都进行了逐元素相加， 最终得到 3×4=12 个查询-键对的交互特征。 为什么要用masked_softmax？在处理文本数据集时，为了提高计算效率，可能会采用填充的方式使每个文本序列具有相同的长度，便于以相同形状的小批量进行加载，因此可能会存在一些文本序列被填充了没有意义的特殊词源（比如“”词元）。 使用masked_softmax可以过滤掉超出指定范围的位置，不让填充的无意义内容影响结果。 缩放点积注意力见书P290 自注意力完全并行、最长序列为1、但对长序列计算复杂度高 李宏毅：https://www.bilibili.com/video/BV1v3411r78R?spm_id_from=333.788.videopod.episodes&amp;vd_source=ff957cd8fbaeb55d52afc75fbcc87dfd&amp;p=2 一、如何得到b1 二、矩阵表示1整体理解 2具体表示 三、位置编码在输入中加入位置信息 二十、编码器-解码器编码器处理输入，解码器生成输出（其实就是把功能集成到一起，然后起了个新名字） 二十一、Transformer 多头注意力 每个注意力池化层都是不同的weight 有掩码的多头注意力解码器对序列中一个元素输出时，不应该考虑该元素之后的元素。 通过掩码实现 计算xi的输出时，假装当前序列长度为i 基于位置的前馈网络 n是序列的长度，不同数据n会变，不能作为特征处理，即n的变化不能影响模型。 层归一化 信息传递 预测 总结 Transformer是一个纯使用注意力的编码-阶码器 编码器和解码器都有n个transformer块 每个块里使用多头（自）注意力、基于位置的前馈网络、 层归一化","categories":[],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"http://example.com/tags/pytorch/"},{"name":"李沐","slug":"李沐","permalink":"http://example.com/tags/%E6%9D%8E%E6%B2%90/"}]},{"title":"动手学深度学习 1","slug":"动手学深度学习 1","date":"2024-12-02T16:00:00.000Z","updated":"2025-02-11T05:05:36.507Z","comments":true,"path":"2024/12/03/动手学深度学习 1/","permalink":"http://example.com/2024/12/03/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%201/","excerpt":"","text":"一、数据操作+预处理N维数组N维数组是机器学习和神经网络的主要数据结构 0-d 标量：一个数字 1-d 向量：一个特征向量 2-d 矩阵：一个样本-特征矩阵 3-d RGB图片（宽×高×通道） 4-d 一个RGB图片的批量（批量大小batch×宽×高×通道） 创建数组需要： 形状 每个元素的数据类型 每个元素的值 访问元素 左下角子区域：1:3表示[1,3) 第二个子区域： ::3表示行是每3行一跳 ​ ::2表示列是每两列一跳 关于内存x +&#x3D; y 就是直接在原来的x上加上y，与加法的形式不一样 x &#x3D; x + y 本质上是将值给了一个新的x，开辟了个新的内存 矩阵乘法 特征向量：不被矩阵改变方向的向量 矩阵范数的求法： https://www.bilibili.com/video/BV1HD4y1u7yD/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bbecda1ec31c9852a00a62b75b7a6154 矩阵按列求和axis&#x3D;0 行 axis&#x3D;1 列 就是照着那个轴拍扁（全相加） 按单个axis求和比如shape [5,4] axis &#x3D; 1 ,sum:[5] 我不要列了–&gt; 按列向右拍扁 按多个axis求和shape [2,5,4] axis&#x3D;[1,2] sum:[2] 如果 keepdims&#x3D;True 那对应的那个维度就不拍扁shape [2,5,4] axis&#x3D;1， sum：[2,1,4] 二、线性回归是对n维输入的加权，外加偏差$$y&#x3D;w_1x_1+w_2x_2+…+w_nx_n+b$$向量版本：y&#x3D;&lt;w,x&gt;+b 可以看做单层神经网络 衡量预估质量 —— 平方损失 L2 Loss$$l &#x3D; \\frac{1}{2}（y-\\hat{y}）^2$$ 缺点：y‘和y相差很多时梯度太大 -》 使用L1 Loss 参数学习 显示解 基础优化方法梯度下降 选择批量大小 batch_size 小的话可能会引入噪声，但这个噪声可能会使模型预测不走偏，因此准确度可能更高 随机梯度下降（SGD）梯度下降是根据所有样本的平均损失进行计算，需要将所有样本重新计算一遍，非常浪费时间。 因此通常采用小批量随机梯度下降（SGD）进行求解。 三、softmax 回归（多类分类模型）得到每个类的预测置信度 使用交叉熵来衡量预测和真实情况的区别，作为损失函数 回归和分类的区别 无校验比例希望预测出的类的置信度和别的类的置信度的差最大 校验比例 作指数是为了将数值变为非负。并且经过操作后使得加起来和为1 交叉熵损失常用来衡量两个概率的区别 损失函数L1 Loss 缺点：原点处不可导；y’和y离得很近的时候不稳定 -》结合L1和L2 Loss得到下面这个损失函数 Huber’s Robust Loss 鲁棒性 robustness系统的健壮性——系统在特殊情况下的稳定性 四、感知机感知机 只输出一个离散的类，因此只能用于二分类 最早的AI模型之一 求解算法等价于使用批量大小为1的梯度下降 不能拟合XOR函数 多层感知机 MLP（Multilayer Perceptron） 这样得到的结果还是线性的，和单一的线性模型没什么区别（只是加权偏移，限制了对复杂任务的处理能力，只能解决线性问题），因此需要加入非线性激活函数 神经网络为什么working？将同一个输入给不同的神经元，每个神经元学习不同的特性，在最后线性计算合并这些特性，输出结果。 https://www.bilibili.com/video/BV1YD4y1f7p6/?spm_id_from=333.337.search-card.all.click&amp;vd_source=bbecda1ec31c9852a00a62b75b7a6154 非线性激活函数激活函数的本质就是引入非线性性 用relu就好了，用其他的区别也不大。而且relu计算更快 nn.ReLU(inplace=True)中的inplace表示直接原地修改内容，而不是新开内存进行修改，可以节省一点内存。 多隐藏层多隐藏层一般是先扩展再压缩，先压缩的话会损失很多信息。 最后一层不要加非线性激活函数，加了会造成层数的塌陷。 为什么是多层而不是一层很宽？ 一层很宽，即让很多神经元在一起学习，不一定会有很好的效果，可能会导致过拟合。而多层的话相当于一次学一点。—&gt;深度学习 五、模型选择训练误差、泛化误差训练误差：模型在训练数据上的误差 泛化误差：模型在新数据上的误差 验证数据集、测试数据集验证数据集：一个用来评估模型好坏的数据集 例如拿出50%的训练数据 不要跟训练数据混在一起！！ 测试数据集：只用一次的数据集 例如： 未来的考试 房子的实际成交价 K-则交叉验证在没有足够多数据时使用 最后选择最好的那一次的参数作为模型的参数 过拟合、欠拟合 过拟合：数据很简单，模型容量很高，模型可能记住这些数据，但别的数据拟合程度不高。 模型容量拟合各种函数的能力 低容量的模型难以拟合训练数据 高容量的模型可以记住所有的训练数据 首先模型要大，再考虑怎么降低泛化误差 估计模型容量 数据复杂度 样本个数 每个样本的元素个数 时间、空间结构 多样性 六、权重衰退范数高维空间中一点到原点的距离 L1范数 —— 曼哈顿距离各坐标值绝对值相加 L2范数 —— 欧几里得距离高维中的勾股定理 LP范数 正则化 —— 权重衰退每一次会缩小w的取值范围 如果模型很复杂，权重衰退也不会带来很好的效果。 为什么需要正则化？模型可能会过度拟合训练数据，过于依赖训练数据中的噪声和细节。正则化通过降低模型的复杂度来防止过度拟合。 正则化会在损失函数中加入一个正则化项，它会使模型中的某些参数不能太大，因此模型会更倾向于选择那些对预测结果有更大影响的参数，减少对其他参数的依赖。 L1正则化L1正则化可能带来稀疏性，某些特征就不起作用了（去耦合，减少过拟合） L2正则化只缩小了W的权重 如何操作1、手动如果是手动加的话，就是在loss函数中加一个正则化的式子 λ自己试，看看什么时候好 2、在trainer中加参数加一个weight_decay的参数，一般设置成1e-3 这里使用的是L2范数的平方 七、丢弃法 dropout在层之间加噪音 只在训练中使用，在预测中不使用。在测试时，Dropout层仅传递数据 动机一个好的模型需要对输入数据的扰动鲁棒robust 无偏差的加入噪音 一定概率变成0，一定概率x值变大，但期望不变 使用丢弃法通常将丢弃法作用在隐藏全连接层的输出上 全连接层——每一个结点都与上一层的所有结点相连 八、数值稳定性数值爆炸 值超出值域，对于16位浮点数尤为严重 对学习率敏感 ​ 如果学习率太大-&gt;参数值会大-&gt;更大的梯度 ​ 如果学习率太小-&gt;训练无法进展 ​ 需要再训练中不断调整学习率 梯度消失 梯度值变成0 对16位浮点数尤为严重 训练无进展 对底部层尤为严重 仅仅顶部层训练的较好 无法让神经网络更深 让训练更稳定 合理的权重初始值和激活函数的选取可以提升数值稳定性 每一层的输出E&#x3D;0，D&#x3D;一个常数 九、kaggle 房价预测标准化数据预处理标准化数据","categories":[],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"http://example.com/tags/pytorch/"},{"name":"李沐","slug":"李沐","permalink":"http://example.com/tags/%E6%9D%8E%E6%B2%90/"}]},{"title":"小土堆pytorch 第三天","slug":"小土堆pytorch 第三天","date":"2024-11-26T16:00:00.000Z","updated":"2024-12-02T11:44:15.559Z","comments":true,"path":"2024/11/27/小土堆pytorch 第三天/","permalink":"http://example.com/2024/11/27/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%20%E7%AC%AC%E4%B8%89%E5%A4%A9/","excerpt":"","text":"一、最大池化的使用池化——压缩特征 最大池化——取当前池化核中的最大的数 12345678910111213141516171819202122232425import torchfrom torch import nnfrom torch.nn import MaxPool2dinput = torch.tensor([[1, 2, 0, 3, 1], [0, 1, 2, 3, 1], [1, 2, 1, 0, 0], [5, 2, 3, 1, 1], [2, 1, 0, 1, 1]])input = torch.reshape(input, (-1, 1, 5, 5))class Test(nn.Module): def __init__(self): super(Test,self).__init__() self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=True) def forward(self,input): output = self.maxpool1(input) return outputtest = Test()output = test(input)print(output) 二、非线性激活层Relu sigmoid 三、线性层和其他层dropout用于防止过拟合（过于关注噪点之类的，捡了芝麻丢了西瓜） 四、小实战和sequential的使用 sequential作用：类似compose，可以序列化执行操作，使代码更简洁 五、loss1、计算实际输出和目标之间的差距 2、为更新输出提供一定的依据（反向传播，从loss反向修正参数） 这里backward()函数可以反向传播计算梯度（grad），将这个梯度给合适的优化器，可以对神经网络的参数进行更新。 六、优化器 TIPS1、如果某一步的参数不会算，可以先让程序运行到上一步，然后print(output.size)查看对应属性的值 2、要将数据变为浮点数，后面写dtype=torch,float32","categories":[],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"http://example.com/tags/pytorch/"},{"name":"小土堆","slug":"小土堆","permalink":"http://example.com/tags/%E5%B0%8F%E5%9C%9F%E5%A0%86/"}]},{"title":"小土堆pytorch 第四天","slug":"小土堆pytorch 第四天","date":"2024-11-26T16:00:00.000Z","updated":"2024-12-03T08:42:29.318Z","comments":true,"path":"2024/11/27/小土堆pytorch 第四天/","permalink":"http://example.com/2024/11/27/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%20%E7%AC%AC%E5%9B%9B%E5%A4%A9/","excerpt":"","text":"一、现有模型的加载、修改、添加123456789101112131415import torchvisionfrom torch import nnvgg16_false = torchvision.models.vgg16(pretrained=False)vgg16_true = torchvision.models.vgg16(pretrained=True)print(vgg16_true)train_data = torchvision.datasets.CIFAR10(&quot;dataset&quot;, train=True, transform=torchvision.transforms.ToTensor(),download=True)vgg16_true.classifier.add_module(&#x27;add_linear&#x27;, nn.Linear(1000, 10)) # 添加 层print(vgg16_true)print(vgg16_false)vgg16_false.classifier[6] = nn.Linear(4096, 10) # 修改层的内容print(vgg16_false) 二、网络模型的保存和读取保存123456789import torchimport torchvisionvgg16 = torchvision.models.vgg16()# 保存方式1 模型结构+模型参数torch.save(vgg16, &quot;vgg16_method1.pth&quot;)# 保存方式2 模型参数 （将模型中的参数保存为字典）[官方推荐，存储量小]torch.save(vgg16.state_dict(), &quot;vgg16_method2.pth&quot;) 读取123456789101112131415161718192021222324252627import torchimport torchvisionfrom torch import nn# 方式1 对应保存方式1model = torch.load(&quot;vgg16_method1.pth&quot;)print(model)# 方式2vgg16 = torchvision.models.vgg16()vgg16.load_state_dict(torch.load(&quot;vgg16_method2.pth&quot;))print(vgg16)class Test(nn.Module): def __init__(self): super(Test, self).__init__() self.conv1 = nn.Conv2d(3, 64, 3) def forward(self, x): x = self.conv1(x) return x# 陷阱1 需要引入自己的模型，要么在开头from model_save import *,要么在这个文件中把模型复制过来model = torch.load(&#x27;test_method1.pth&#x27;)print(model) 三、完整模型的训练两种类型分类的模型 模型预测得到的outputs&#x3D;[0.3,0.5] (第一张图) ​ [0.5,0.2] (第二张图) 使用argmax（1）方法可以得到该行最大数的位置，即对应的那个类型 argmax（0）是得到列最大数的位置 这里argmax(1)=[2][1] 将模型预测的结果和真实情况进行比较： 123preds = torch.argmax(1)print((preds == targets).sum) # 得到正确率 yourmodel.train()、yourmodel.eval()对某些特定的层有影响，比如dropout层，详见pytorch官网 四、使用gpu训练法一：改动的地方： 网络模型 数据（输入、检测） 损失函数 改动方法:data = data.cuda() 法二：先在开头定义：device = torch.device(&quot;cuda&quot;) ​ 语法糖写法：device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;) 接着像法一一样修改： 12test = Test()test = test.to(device) 五、查看开源项目修改参数时有些参数有required = True,可以把这个参数删掉，然后改成default=&#39;data的地址&#39; TIPSctrl + D 可以复制本行内容","categories":[],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"http://example.com/tags/pytorch/"},{"name":"小土堆","slug":"小土堆","permalink":"http://example.com/tags/%E5%B0%8F%E5%9C%9F%E5%A0%86/"}]},{"title":"小土堆pytorch 第二天","slug":"小土堆pytorch 第二天","date":"2024-11-25T16:00:00.000Z","updated":"2024-11-27T10:56:58.064Z","comments":true,"path":"2024/11/26/小土堆pytorch 第二天/","permalink":"http://example.com/2024/11/26/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%20%E7%AC%AC%E4%BA%8C%E5%A4%A9/","excerpt":"","text":"一、DataLoader 的使用12345678910111213141516171819import torchvisionfrom torch.utils.data import DataLoaderfrom torch.utils.tensorboard import SummaryWritertest_data = torchvision.datasets.CIFAR10(&quot;./dataset&quot;, train=False, transform=torchvision.transforms.ToTensor())test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True, num_workers=0, drop_last=True) # 每次取的个数 取完后是否打乱 最后如果因为数量无法分配是否舍去writer = SummaryWriter(&quot;dataloader&quot;)for epoch in range(2): step = 0 for data in test_loader: imgs, target = data writer.add_images(f&quot;Epoch:&#123;epoch&#125;&quot;, imgs, step) step = step + 1writer.close() ！！二、python补充： call函数__call__ 可以将类名变为可执行函数 比如在下面的代码中，nn.Module 中包含了__call__函数，使得test(x)直接调用forward函数并得到返回值 call函数举例： 12345678910111213141516class Test(): # def __init__(self): 没内容时可省略不写 def forward(self, input): output = input + 1 return output def __call__(self, input): return self.forward(input) # 在类的方法内部调用另一个方法时，需使用 self 关键字来指向它test = Test()x = 1output = test(x)print(output) 三、神经网络的基本骨架 nn.Module 的使用1234567891011121314151617import torchfrom torch import nnclass Test(nn.Module): # 表示Test继承于Module，它为所有神经网络提供基本的骨架 def __init__(self): super().__init__() def forward(self, input): output = input + 1 return outputtest = Test()x = torch.tensor(1.0)output = test(x)print(output) *四、卷积操作 CONV2D （convolution）（nn.functional.conv2d 为具体方法）12345678910111213141516171819202122import torchimport torch.nn.functional as Finput = torch.tensor([[1, 2, 0, 3, 1], [0, 1, 2, 3, 1], [1, 2, 1, 0, 0], [5, 2, 3, 1, 1], [2, 1, 0, 1, 1]])kernel = torch.tensor([[1, 2, 1], [0, 1, 0], [2, 1, 0]])print(input.shape)input = torch.reshape(input, (1, 1, 5, 5)) # conv2d中要求输入和卷积层的尺寸中有4个属性，而tensor创建出来的只有2个，因此需要reshape增加他们的属性。四个属性分别为：batch_size（每次喂给神经网络多少个数据）填-1的话可以让系统根据后面三个数自动计算，通道数（1为灰度图像，rgb通道数为3），高度，宽度。kernel = torch.reshape(kernel, (1, 1, 3, 3))print(input.shape)output = F.conv2d(input, kernel, stride=1)print(output) Tips: num_workers &gt;0 时可能会出现broken pipe error ，此时把它设置为0试试 举例 padding 举例 stride举例 动图： https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md 五、卷积操作 CONV2D （nn.convv2d 为封装后的函数）（实际使用）123456789101112131415161718192021222324252627import torchimport torchvisionfrom torch import nnfrom torch.nn import Conv2dfrom torch.utils.data import DataLoaderdataset = torchvision.datasets.CIFAR10(&quot;dataset&quot;, train=False, transform=torchvision.transforms.ToTensor(),download=True)DataLoader = DataLoader(dataset, batch_size=64)class Test(nn.Module): def __init__(self): super(Test, self).__init__() self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0) def forward(self, x): x=self.conv1(x) return xtest = Test()for data in DataLoader: imgs, targets = data output = test(imgs) print(imgs.shape) print(output.shape) in_channels=3: imput的通道为3 out_channels=6：output的通道为6 &#x3D;卷积核的个数 kernel_size=3：卷积核的高和宽为3 深度由系统自动计算 stride=1：步径为1 padding=0：边缘不需要加行&#x2F;列 注：卷积核中的数值应是自动生成的 训练模型就是训练卷积核中自动生成的数值 *找到的资源对知名模型的代码进行逐行解读的网站 https://nn.labml.ai/ 图神经网络的实现基本都有 Deep Graph Library https://www.dgl.ai","categories":[],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"http://example.com/tags/pytorch/"},{"name":"小土堆","slug":"小土堆","permalink":"http://example.com/tags/%E5%B0%8F%E5%9C%9F%E5%A0%86/"}]},{"title":"小土堆pytorch 第一天","slug":"小土堆pytorch 第一天","date":"2024-11-23T16:00:00.000Z","updated":"2024-11-24T14:57:18.659Z","comments":true,"path":"2024/11/24/小土堆pytorch 第一天/","permalink":"http://example.com/2024/11/24/%E5%B0%8F%E5%9C%9F%E5%A0%86pytorch%20%E7%AC%AC%E4%B8%80%E5%A4%A9/","excerpt":"","text":"一、两大法宝函数1、dir()打开，看见 2、help()查看说明书 二、三个运行方式的区别 三、如何导入数据两种数据形式：Dataset、Dataloader Dataset1、如何获取每一个数据及其label？ 2、总共有多少条数据？ 12345678910111213141516171819202122232425262728293031from torch.utils.data import Datasetfrom PIL import Imageimport os # 用于获取图片的地址class MyData(Dataset): def __init__(self, root_dir, label_dir): self.root_dir = root_dir self.label_dir = label_dir self.path = str(os.path.join(self.root_dir, self.label_dir)) # 拼接地址 self.img_path = os.listdir(self.path) # 获取当前目录中文件的地址列表 def __getitem__(self, idx): img_name = self.img_path[idx] # 获取文件名 img_item_path = os.path.join(self.root_dir,self.label_dir,img_name) # 拼接地址 img = Image.open(img_item_path) label = self.label_dir return img, label def __len__(self): return len(self.img_path)root_dir = &quot;dataset/train&quot;ants_label_dir = &quot;ants&quot;bees_label_dir = &quot;bees&quot;ants_dataset = MyData(root_dir, ants_label_dir)bees_dataset = MyData(root_dir, bees_label_dir)train_dataset = ants_dataset + bees_dataset 四、Tensorboard的使用12345678from torch.utils.tensorboard import SummaryWriterwriter = SummaryWriter(&quot;logs&quot;) # 文件存放在logs文件夹中for i in range(100): writer.add_scalar(&quot;y=2x&quot;, 2*i, i) # tag 纵轴 横轴writer.close() 如何打开tensorboard界面？终端中： tensorboard –logdir&#x3D;”D:\\pycharm\\learn_pytorch\\learn_pytorch\\logs” 如何切换打开的端口（避免服务器训练时与别人冲突）tensorboard –logdir&#x3D;”D:\\pycharm\\learn_pytorch\\learn_pytorch\\logs” –port&#x3D;6007（修改端口地址） 导入自己的图片123456789101112from torch.utils.tensorboard import SummaryWriterimport numpy as npfrom PIL import Imagewriter = SummaryWriter(&quot;logs&quot;)image_path = &quot;dataset/train/ants/0013035.jpg&quot;img_PIL = Image.open(image_path)img_array = np.array(img_PIL) # 将图片转为numpy格式writer.add_image(&quot;test&quot;, img_array, 1, dataformats=&#x27;HWC&#x27;)# 从PIL到numpy，需要在add_image()中指定shape中每一个数字、维度表示的含义writer.close() 如果改变image的地址并且将writer.add_image(&quot;test&quot;, img_array, 1（横轴）, dataformats=&#39;HWC&#39;)中的横轴改为2，则tensorboard会在之前的图片上显示拖动条，向右拖动即为第二张图片 五、transform的使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344from PIL import Imagefrom torch.utils.tensorboard import SummaryWriterfrom torchvision import transformswriter = SummaryWriter(&quot;logs&quot;)img = Image.open(&quot;dataset/train/ants/0013035.jpg&quot;)print(img)# ToTensor (transforms的一种工具)trans_totensor = transforms.ToTensor() # 打开并配置工具img_totensor = trans_totensor(img) # 使用工具writer.add_image(&quot;ToTensor&quot;, img_totensor)# Normalize 归一化 (预处理，确保输入模型的数据在相同的尺度上。将数据缩放到一个小范围)trans_norm = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])img_norm = trans_norm(img_totensor)writer.add_image(&quot;Normalize&quot;, img_norm)# Resizeprint(img.size)trans_resize = transforms.Resize((512, 512))img_resize = trans_resize(img) # 得到的仍然是PIL类型img_resize = trans_totensor(img_resize) # 得到tensor类型的图片writer.add_image(&quot;Resize&quot;, img_resize, 0)print(img_resize)# 方法2 Compose - resize 相当于打包处理的过程trans_resize_2 = transforms.Resize(512)trans_compose = transforms.Compose([trans_resize_2, trans_totensor])# 将resize和转换为tensor的操作用compose打包,第一个操作的输出是第二个操作的输入img_resize2 = trans_compose(img)writer.add_image(&quot;Resize&quot;, img_resize2, 1)# RandomCrop 随机裁剪trans_randomCrop = transforms.RandomCrop((500, 1000)) # 只写一个数就是按正方形裁剪trans_compose2 = transforms.Compose([trans_randomCrop, trans_totensor])for i in range(10): img_crop = trans_compose2(img) writer.add_image(&quot;RandomCropHW&quot;, img_crop, i)writer.close() transforms.Normalize(mean, std)注：需要传递tensor类型图片 将图像的每个通道（RGB，共3个通道）按特定的均值和标准差进行归一化 Resize()注：需要传递PIL类型图片 括号中只给一个数值，那么就将图片短的那个边匹配这个数值进行等比缩放 括号中给两个数值，就将长宽设置为这两个数值 Tips关注输入和输出类型 关注方法需要什么参数 不知道返回值的时候，可以print()或print(type())或debug","categories":[],"tags":[{"name":"pytorch","slug":"pytorch","permalink":"http://example.com/tags/pytorch/"},{"name":"小土堆","slug":"小土堆","permalink":"http://example.com/tags/%E5%B0%8F%E5%9C%9F%E5%A0%86/"}]}],"categories":[],"tags":[{"name":"大学课程","slug":"大学课程","permalink":"http://example.com/tags/%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"JDBC","slug":"JDBC","permalink":"http://example.com/tags/JDBC/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"javase","slug":"javase","permalink":"http://example.com/tags/javase/"},{"name":"C","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"Swin-Unet","slug":"Swin-Unet","permalink":"http://example.com/tags/Swin-Unet/"},{"name":"pytorch","slug":"pytorch","permalink":"http://example.com/tags/pytorch/"},{"name":"李沐","slug":"李沐","permalink":"http://example.com/tags/%E6%9D%8E%E6%B2%90/"},{"name":"小土堆","slug":"小土堆","permalink":"http://example.com/tags/%E5%B0%8F%E5%9C%9F%E5%A0%86/"}]}